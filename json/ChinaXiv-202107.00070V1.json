[
    {
        "type": "text",
        "text": "A Note on the High-dimensional Sparse Fourier Transform in the Continuous Setting ",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Liang Chen\\* ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Abstract ",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "In this paper, we theoretically propose a new hashing scheme to establish the sparse Fourier transform in high-dimensional space. The estimation of the algorithm complexity shows that this sparse Fourier transform can overcome the curse of dimensionality. To the best of our knowledge, this is the first polynomial-time algorithm to recover the high-dimensional continuous frequencies. Keywords: Curse of dimensionality, Frequency estimation, Runtime complexity, Sparse Fourier transform. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "1 Introduction ",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Discrete Fourier transform (DFT） plays a fundamental role in signal processing, scientific computing and other fields. Its runtime complexity can reach $N l o g ( N )$ (where $N$ represents the signal size) by the fast Fourier transform algorithm.This runtime complexity is stilltoo high for the ultrawide bandwidth signals or high-dimensional signals. If we increase the prior information of the signals,that is,assuming the sparsity of the frequencies,then the sparse discrete Fourier transform (SFT) [1] will have more advantages than the DFT.The sample complexity and runtime complexity of the SFT are mainly affected by the sparsity，,and less affected by the bandwidth. The SFT originated from the work on the Hadamard transform [2] and has received continuous attention from applied mathematics [3,4,5,6,7,8],signal processing [9,10,11,12,13,14],and theoreticalcomputer science communities [15,16,17,18,19,20] over the last two decades.Most of the relevant works deals with the discrete case where the frequencies are on the grid. Under such condition,the SFT can overcome the curse of dimensionality [20,21,22,23].However,this condition that the frequencies are on the grid is so strong. It is natural for people to consider the case that the frequencies are in a continuous region. This has led researchers to establish the sparse Fourier transform in the one-dimensional continuous setting [18, 24, 25]. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Recently,[26] initiates the study on the SFT in the high-dimensional continuous setting. Unfortunately, their SFT method is stillsubject to the curse of dimensionality, namely,its runtime complexity is greater than $2 ^ { O ( d ) }$ ( $d$ stands for the dimension). The main difficulty in estimating high-dimensional continuous frequencies is that when we fix a set of discrete orthogonal bases whose frequencies are located on the grid,there is always a single-frequency signal with the frequency located in a continuous region, which is not sparse under the discrete Fourier transform (see “the windowing efect” in [11]), and as the dimension increases,the $L _ { 1 }$ norm of the frequency coefficients increases exponentially. On the other hand, in a physical sense,the single-frequency signals should obviously be sparse. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "In this paper, we present a new hashing scheme to transform the high-dimensional SFT into the one-dimensional SFT. The computational complexity of this algorithm is polynomial, which means that the algorithm can break the curse of dimensionality. To the best of our knowledge,this is the first polynomial-time algorithm to recover the of-grid high-dimensional frequencies. ",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "Formally, we consider the signal $f$ of the following form ",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\nf ( t ) = \\sum _ { j = 1 } ^ { k } f _ { j } ( t ) \\triangleq \\sum _ { j = 1 } ^ { k } a _ { j } \\exp ( 2 \\pi i w _ { j } \\cdot t ) ,\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "where $t \\in \\mathbb { R } ^ { d } , w _ { j } \\in [ - M , M ] ^ { d }$ ， $a _ { j } \\in \\mathbb { C }$ ， $0 < A ^ { \\prime } \\leq | a _ { j } | \\leq A$ for all $j = 1 , 2 , \\ldots , k$ and $\\scriptstyle \\operatorname* { m i n } _ { 1 \\leq i < j \\leq k } | w _ { i } -$ （20 $w _ { j } | > \\eta$ ：",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "Our goal is to recover $w _ { j } , a _ { j } , j = 1 , 2 , \\ldots , k$ ",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "2 Main Result ",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "We first give some symbols and notions. Let $\\operatorname { s g n } \\left( x \\right) = 1$ ,when $x \\geq 0$ ; otherwise, $\\operatorname { s g n } \\left( x \\right) = - 1$ .Let （204号 $J ^ { * }$ denote the transpose of the matrix $J$ . Denote for each $t \\in \\mathbb R$ by $\\lfloor t \\rfloor$ the largest integer not bigger than $t$ . Let us say that $U \\subset E$ is the $\\epsilon$ -support set of the function $\\hat { f }$ 进 $\\textstyle \\int _ { E \\setminus U } | \\hat { f } | ^ { 2 } \\leq \\epsilon ^ { 2 }$ ，where $E$ is the domain of $\\hat { f }$ . Let ",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\n\\qquad ,\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "and ",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\n\\Gamma _ { 2 } \\triangleq \\Bigg \\{ \\Bigg ( \\frac { \\xi _ { 1 } } { T } , . . . , \\frac { \\xi _ { d } } { T } \\Bigg ) : \\xi _ { i } \\in \\mathbb { Z } \\cap \\Bigg [ \\frac { - T F } { 2 } , \\frac { T F } { 2 } \\Bigg ) , 1 \\leq i \\leq d \\Bigg \\} .\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "The discrete Fourier transform of the function $g$ takes the following form ",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\n\\mathcal { F } [ g ] ( \\xi ) = \\frac { 1 } { ( \\sqrt { T } F ) ^ { d } } \\sum _ { x \\in \\Gamma _ { 1 } } g ( x ) \\exp ( - 2 \\pi i x \\cdot \\xi ) , \\quad \\xi \\in \\Gamma _ { 2 } ,\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "and the inverse discrete Fourier transform of the function $g$ is defined by ",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\n\\mathcal { F } ^ { - 1 } [ g ] ( \\boldsymbol { x } ) = \\frac { 1 } { ( \\sqrt { T } ) ^ { d } } \\sum _ { \\boldsymbol { \\xi } \\in \\Gamma _ { 2 } } g ( \\boldsymbol { \\xi } ) \\exp ( 2 \\pi i \\boldsymbol { x } \\cdot \\boldsymbol { \\xi } ) , \\quad \\boldsymbol { x } \\in \\Gamma _ { 1 } .\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "For $x , y \\in \\Gamma _ { 1 }$ ， $x \\pm y \\triangleq x \\pm y ( { \\mathrm { m o d T } } ) \\in \\Gamma _ { 1 }$ .For $x , y \\in \\Gamma _ { 2 }$ ， $x \\pm y \\triangleq x \\pm y ( { \\mathrm { m o d F } } ) \\in \\Gamma _ { 2 }$ ",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "The “bucket”in the frequency domain is defined by ",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\nB _ { j } \\triangleq \\left\\{ ( \\xi _ { 1 } / T , \\dots , \\xi _ { d } / T ) \\in \\Gamma _ { 2 } : \\xi _ { d } \\in \\left[ \\frac { T F ( j - 1 ) } { s } - \\frac { F T } { 2 } , \\frac { T F j } { s } - \\frac { F T } { 2 } \\right) \\right\\} , \\quad 1 \\leq j \\leq s .\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "The hashing transform (in the frequency domain) is defined by $H ( \\xi ) \\triangleq h \\xi - ( 0 , \\dots , 0 , b / T ) ^ { * }$ ，where ",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\nh = \\left[ \\begin{array} { c c } { \\mathbf { I } _ { d - 1 } } & { 0 } \\\\ { V _ { h } } & { h _ { d } } \\end{array} \\right] ,\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "here ${ \\bf { I } } _ { d - 1 }$ is the identity matrix of order $d - 1$ ， $V _ { h } = ( h _ { 1 } , \\ldots , h _ { d - 1 } )$ and $\\{ h _ { 1 } , \\ldots , h _ { d } \\}$ are independent draws from the uniform distribution on the set $\\{ 2 n + 1 : n \\in \\mathbb { Z } \\} \\cap [ - \\sqrt { d } F / ( \\eta ) , \\sqrt { d } F / ( \\eta ) ]$ .The random variable $b$ obeys theuifoistibutionotheset $\\mathbb { Z } \\cap \\{ [ - \\frac { T F } { 2 s } , \\frac { T F } { 2 s } ) \\}$ . ",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "In this paper,we assume that $T , F , s$ are powers of 2 and $1 < s < F$ . Next, we give a key lemma. ",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "Lemma 2.1 Suppose $\\textstyle 0 < \\delta < { \\frac { 1 } { 2 } }$ ，m $\\begin{array} { r } { 0 < \\epsilon < \\operatorname* { m i n } \\lbrace 1 , \\eta , \\frac { A ^ { ' } } { 4 } , \\frac { 1 } { 4 A ^ { 2 } } \\rbrace } \\end{array}$ ，m $\\begin{array} { r } { s = \\mathcal { O } ( \\frac { k ^ { 2 } } { \\delta } ) } \\end{array}$ ， $T = \\mathcal { O } ( k ^ { 5 } s d ^ { 7 / 2 } / ( \\epsilon ^ { 2 } \\eta \\delta ^ { 3 } ) )$ $F = s M$ .With probability at least $1 - \\delta / 4$ over the randomness of $\\{ h _ { 1 } , \\ldots , h _ { d } , b \\}$ ，for each $j \\in$ $\\{ 1 , \\ldots , s \\}$ ，either ",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\nI _ { j , 1 } \\triangleq \\frac { 1 } { ( T F ) ^ { d } } \\sum _ { x \\in \\Gamma _ { 1 } } \\big | e ^ { \\frac { 2 \\pi i b ( h _ { d } ) ^ { - 1 } x _ { d } } { T F } } \\mathcal { F } ^ { - 1 } [ \\mathcal { X } _ { B _ { j } } \\cdot \\mathcal { F } [ f _ { H } ] ] ( ( h ^ { - 1 } ) ^ { * } x ) \\big | ^ { 2 } \\leq A ^ { 2 } \\epsilon ^ { 2 } \\delta / ( d s ) .\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "or there exists a unique $j _ { k } \\in \\left\\{ 1 , 2 , \\ldots , k \\right\\}$ such that ",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\nI _ { j , 2 } \\triangleq \\frac { 1 } { ( T F ) ^ { d } } \\sum _ { \\substack { x \\in \\Gamma _ { 1 } } } \\big | f _ { j _ { k } } ( x ) - e ^ { \\frac { 2 \\pi i b ( h _ { d } ) ^ { - 1 } x _ { d } } { T F } } \\mathcal { F } ^ { - 1 } [ \\mathcal { X } _ { B _ { j } } \\cdot \\mathcal { F } [ f _ { H } ] ] ( ( h ^ { - 1 } ) ^ { * } x ) \\big | ^ { 2 } \\leq A ^ { 2 } \\epsilon ^ { 2 } \\delta / ( d s ) .\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "Where ",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\nf _ { H } ( x ) \\triangleq f ( h ^ { * } x ) \\exp ( - \\frac { 2 \\pi i b x _ { d } } { T F } ) ,\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "and ",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\n\\begin{array} { r } { \\mathcal { X } _ { B _ { j } } ( \\xi ) \\triangleq \\left\\{ \\begin{array} { l l } { 1 } & { \\xi \\in B _ { j } } \\\\ { 0 } & { \\xi \\not \\in B _ { j } } \\end{array} \\right. , \\quad j = 1 , 2 , \\ldots , s . } \\end{array}\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "By Markov's inequality, we have a corollary. ",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "Corollary 2.2 All parameters are set as Lemma 2.1. For any $l \\in \\{ 1 , 2 , \\ldots , d \\}$ ， choosing the random vector $X _ { l } \\triangleq ( x _ { 1 } , \\ldots , x _ { l - 1 } , x _ { l + 1 } , \\ldots , x _ { d } )$ which obeys the uniform distribution on the set $\\mathbb { Z } ^ { d - 1 } \\cap$ （20 [=TE,TE)d-1,then with probabilityat least1-δ/(4ds) over the randomness of(x1,..,xl-1,i+1,...,xd), we have ",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\n\\sum _ { \\substack { x _ { l } \\in \\mathbb { Z } \\cap [ \\frac { - T F } { 2 } , \\frac { T F } { 2 } ) } } \\frac { 1 } { T F } | e ^ { \\frac { 2 \\pi i b ( h _ { d } ) ^ { - 1 } x _ { d } } { T F } } \\mathcal { F } ^ { - 1 } [ \\mathcal { X } _ { B _ { j } } \\cdot \\mathcal { F } [ f _ { H } ] ] ( h ^ { * } ( x ) ) | ^ { 2 } \\leq d s I _ { j , 1 } / \\delta\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "or ",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\n\\sum _ { \\substack { x _ { l } \\in \\mathbb { Z } \\cap [ \\frac { - T F } { 2 } , \\frac { T F } { 2 } ) } } \\frac { 1 } { T F } \\big | f _ { j _ { k } } ( x ) - e ^ { \\frac { 2 \\pi i b ( h _ { d } ) ^ { - 1 } x _ { d } } { T F } } \\mathcal { F } ^ { - 1 } [ \\mathcal { X } _ { B _ { j } } \\cdot \\mathcal { F } [ f _ { H } ] ] ( h ^ { \\ast } ( x ) ) \\big | ^ { 2 } \\leq d s I _ { j , 2 } / \\delta .\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "Where $x = ( x _ { 1 } / F , \\ldots , x _ { l - 1 } / F , x _ { l } / F , x _ { l + 1 } / F , \\ldots , x _ { d } / F ) ^ { * } .$ ",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "We explain Lemma 2.1 at a high level. It is well known that for the discrete Fourier transform, enlarge the sampling interval can enhance the frequency concentration (the frequency resolution) of each component $f _ { j }$ ， and the frequency gap between different components is greater than a constant of the value $\\eta$ $\\epsilon$ . Therefore,with the expanding of the sampling interval, -support set (let $\\frac { d ^ { 3 / 2 } A ^ { 2 } } { T \\beta _ { \\epsilon } } = \\epsilon ^ { 2 } / k ^ { 2 }$ inLemma3.1)foreachsignalcomponentinthefrequency will be greater than the radius $\\beta _ { \\epsilon }$ domain. And the hashing transform we defined can transform the gap between frequencies to the gap between the last coordinates of the frequencies (see Lemma 3.2). When $\\eta > \\mathcal { O } ( d k ^ { 3 } \\beta _ { \\epsilon } / \\delta ^ { 2 } )$ ，this hashing transform can keep the main frequencies $\\phi _ { j , \\beta _ { \\epsilon } }$ (defined in Lemma 3.1) of the same component into the same bucket, and different components' $\\epsilon$ -support sets $\\phi _ { i , \\beta _ { \\epsilon } }$ ， $\\phi _ { j , \\beta _ { \\epsilon } } , i \\neq j$ can be isolated into different buckets (see Corollary 3.3). The figure 2.1 shows how the frequencies of the two-dimensional signal is transformed under the hashing operator (2.3). ",
        "page_idx": 2
    },
    {
        "type": "image",
        "img_path": "images/93c51854fe6a52bab3609bb452d51841f346c69edc3c25993ff95486767505de.jpg",
        "img_caption": [
            "Figure 2.1: The left side of the figure shows the spectrogram of the two-dimensional signal $\\exp ( i 2 \\pi w _ { 1 } \\cdot$ （204号 （204号 $t ) + \\exp ( i 2 \\pi w _ { 2 } \\cdot t )$ under the discrete Fourier transform,where $\\beta _ { \\epsilon }$ is the radius of the $\\epsilon$ -support set （20 $\\phi _ { 1 , \\beta _ { \\epsilon } }$ ， $\\phi _ { 2 , \\beta _ { \\epsilon } }$ in the frequency domain. The right side of the figure is the spectrogram after hashing transform,by Lemma 3.2, we have $| ( h ( w _ { 1 } - w _ { 2 } ) ) _ { 2 } | > 2 F / s$ . By increasing the sampling interval $T$ ，we can make $\\begin{array} { r } { \\mathcal { O } \\big ( \\frac { A ^ { 2 } F } { T \\eta \\epsilon ^ { 2 } } \\big ) < \\mathcal { O } ( F / s ) } \\end{array}$ . "
        ],
        "img_footnote": [],
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "When the different components of the signal are isolated, we only need to recover the frequency and amplitude in each bucket. By Lemma 2.1, there are only two cases of such amplitude and frequency, one is that they are close to the amplitude and frequency of a certain component (up to the hashing transformation),and the other is that the amplitude is less than $\\mathcal { O } ( \\epsilon )$ ： ",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "Specifically, for $1 \\le j \\le s$ ， $1 \\leq l \\leq d$ ，set ",
        "page_idx": 3
    },
    {
        "type": "equation",
        "text": "$$\n\\qquad ,\n$$",
        "text_format": "latex",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "where $\\begin{array} { r } { \\rho _ { l } \\left( \\frac { \\lfloor t F \\rfloor } { T F } \\right) = \\frac { \\lfloor t F \\rfloor } { T F } } \\end{array}$ ， when $l = d$ ; otherwise, $\\begin{array} { r } { \\rho _ { l } \\big ( \\frac { \\lfloor t F \\rfloor } { T F } \\big ) = \\frac { x _ { d } } { T F } } \\end{array}$ and",
        "page_idx": 3
    },
    {
        "type": "equation",
        "text": "$$\nx _ { l , t } = ( x _ { 1 } , \\ldots , x _ { l - 1 } , \\lfloor t F \\rfloor / F , x _ { l + 1 } , \\ldots , x _ { d } ) .\n$$",
        "text_format": "latex",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "Here $( x _ { 1 } , \\ldots , x _ { l - 1 } , x _ { l + 1 } , \\ldots , x _ { d } )$ is the random vector obeys the uniform distribution on the set $\\mathbb { Z } ^ { d - 1 } \\cap$ （20 $[ \\frac { - T F } { 2 } , \\frac { T F } { 2 } ) ^ { d - 1 }$ The sample valueof the function ${ { g } _ { j , l } }$ is calculated by themethodinLemma4.1. Let $F \\ge \\mathcal { O } ( \\sqrt { d } M / \\epsilon )$ , by Lemma 2.1 and Corollary 2.2, either there is a signal component $f _ { j _ { k } }$ with frequency $w _ { j _ { k } }$ such that ",
        "page_idx": 3
    },
    {
        "type": "equation",
        "text": "$$\n\\frac { 1 } { T } \\int _ { - T / 2 < t < T / 2 } | g _ { j , l } ( t ) - a _ { j _ { k } } \\theta _ { j _ { k } , l } e ^ { 2 \\pi i w _ { j _ { k } , l } t } | ^ { 2 } d t \\leq \\mathcal { O } ( A ^ { 2 } \\epsilon ^ { 2 } ) ,\n$$",
        "text_format": "latex",
        "page_idx": 3
    },
    {
        "type": "equation",
        "text": "$$\n\\frac { 1 } { T } \\int _ { - T / 2 < t < T / 2 } | g _ { j , l } ( t ) | ^ { 2 } d t \\leq \\mathcal { O } ( A ^ { 2 } \\epsilon ^ { 2 } ) ,\n$$",
        "text_format": "latex",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "where $w _ { j _ { k } , l }$ denotes $l$ -th component of the vector $w _ { j _ { k } }$ and ",
        "page_idx": 4
    },
    {
        "type": "equation",
        "text": "$$\n\\theta _ { j _ { k } , l } = \\exp { \\left( \\frac { 2 \\pi i } { F } ( w _ { j _ { k } , 1 } x _ { 1 } + \\cdot \\cdot \\cdot + w _ { j _ { k } , l - 1 } x _ { l - 1 } + w _ { j _ { k } , l + 1 } x _ { l + 1 } + \\cdot \\cdot \\cdot w _ { j _ { k } , d } x _ { d } ) \\right) } .\n$$",
        "text_format": "latex",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "We have the following algorithm: For each $j \\in \\{ 1 , 2 , \\dots , s \\}$ ，we first use the algorithm in [24] to recover the amplitude and frequency of $g _ { j , 1 } ( t )$ . If the absolute value of the output amplitude less than $A ^ { ' } / 2$ , we turn to recover the amplitude and frequency of $g _ { j + 1 , 1 } ( t )$ ；otherwise, we keep $w _ { j _ { k } , 1 } ^ { o }$ （204号 and continue to use the algorithm in [24] to recover the frequencies of $g _ { j , 2 } ( t ) , . . . , g _ { j , d } ( t )$ .Finally, （20 $\\{ w _ { j _ { k } , 1 } ^ { o } , \\dotsc , w _ { j _ { k } , l } ^ { o } , \\dotsc , w _ { j _ { k } , d } ^ { o } \\}$ can be recovered element-wisely. ",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "\" Note: From Theorem 1.1 in [24], it takes at most $\\mathcal { O } ( d s \\log ( T F ) \\log ( d s / ( \\delta \\epsilon ) ) / \\delta )$ samples of the function ${ { g } _ { j , l } }$ to recover the frequency $w _ { j _ { k } , l }$ (up to the accuracy $A ^ { 2 } \\epsilon / ( T A ^ { \\prime } ) )$ with probability at least $1 - \\delta / ( 4 d s )$ . By Lemma 4.1, in order to get $\\mathcal { O } ( d s \\log ( T F ) \\log ( d s / ( \\delta \\epsilon ) ) )$ samples (up to the accuracy $A ^ { 2 } \\epsilon )$ of ${ { g } _ { j , l } }$ with probability at least $1 - \\delta$ , we need a total of ",
        "page_idx": 4
    },
    {
        "type": "equation",
        "text": "$$\n\\mathcal { O } ( k ^ { 2 } d s \\ln ^ { 2 } ( T F + 1 ) \\log ( T F ) \\log ( T F d s / ( \\delta \\epsilon ) ) \\ln ^ { 2 } ( 1 / \\delta ) / ( \\delta \\epsilon ^ { 2 } ) )\n$$",
        "text_format": "latex",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "samples and running time. Therefore,we have the following result. ",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "Theorem 2.3 All parameters are set as Lemma 2.1, besides, $F \\geq \\mathcal { O } ( \\sqrt { d } M / \\epsilon )$ . The above algorithm can output $\\{ w _ { 1 } ^ { o } , \\ldots , w _ { k } ^ { o } \\}$ such that ",
        "page_idx": 4
    },
    {
        "type": "equation",
        "text": "$$\n| w _ { j } ^ { o } - w _ { j } | < \\mathcal { O } ( \\frac { \\epsilon A ^ { 2 } \\sqrt { d } } { A ^ { \\prime } T } ) < \\mathcal { O } ( \\frac { A ^ { 2 } \\epsilon ^ { 3 } / A ^ { \\prime } } { \\sqrt { d } k ^ { 4 } } ) , \\quad i = 1 , 2 , \\ldots , k .\n$$",
        "text_format": "latex",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "holds with probability at least $1 - \\delta$ over the randomness of $\\{ h _ { 1 } , \\ldots , h _ { d } , b \\}$ ， $\\{ X _ { l } \\} _ { l = 1 } ^ { d }$ (see Corollary 2.2), $\\tau$ (see Lemma 4.1) and the algorithm in [24]. The runtime complexity and sample complexity are at most ",
        "page_idx": 4
    },
    {
        "type": "equation",
        "text": "$$\n\\mathcal { O } ( k ^ { 2 } d ^ { 2 } s ^ { 2 } \\ln ^ { 2 } ( T F + 1 ) \\log ( T F ) \\log ( T F d s / ( \\delta \\epsilon ) ) \\ln ^ { 2 } ( 1 / \\delta ) / ( \\epsilon ^ { 2 } \\delta ) ) .\n$$",
        "text_format": "latex",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "The success probability can be boosted to 1 by repeatedly restarting (as indicated in ([15, 24]) ",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "Next, we consider restoring the amplitudes. Notice that $\\begin{array} { r } { | w _ { j } ^ { o } - w _ { j } | < \\mathcal { O } ( \\frac { A ^ { 2 } \\epsilon ^ { 3 } / A ^ { \\prime } } { \\sqrt { d } k ^ { 4 } } ) } \\end{array}$ and $\\epsilon < \\eta$ .As the sampling interval increases, the different signal components $f _ { j }$ are nearly orthogonal, that is ",
        "page_idx": 4
    },
    {
        "type": "equation",
        "text": "$$\n\\begin{array} { r l } & { ( \\epsilon ^ { 2 } / k ) ^ { d } \\int _ { t \\in [ 0 , k / \\epsilon ^ { 2 } ] ^ { d } } f ( t ) e ^ { - 2 \\pi i w _ { j } ^ { o } \\cdot t } d t } \\\\ { = } & { a _ { j } ( \\epsilon ^ { 2 } / k ) ^ { d } \\int _ { t \\in [ 0 , k / \\epsilon ^ { 2 } ] ^ { d } } e ^ { 2 \\pi i ( w _ { j } - w _ { j } ^ { o } ) \\cdot t } d t + \\sum _ { l \\neq 1 } ^ { k } ( \\epsilon ^ { 2 } / k ) ^ { d } \\int _ { t \\in [ 0 , k / \\epsilon ^ { 2 } ] ^ { d } } a _ { l } e ^ { 2 \\pi i ( w _ { l } - w _ { j } ^ { o } ) \\cdot t } d t } \\\\ { = } & { a _ { j } ( 1 + \\mathcal { O } ( \\frac { A ^ { 2 } \\epsilon / A ^ { \\prime } } { k ^ { 3 } } ) ) + \\sum _ { l \\neq 1 } ^ { k } ( \\epsilon ^ { 2 } / k ) ^ { d } \\int _ { t \\in [ 0 , k / \\epsilon ^ { 2 } ] ^ { d } } a _ { l } e ^ { 2 \\pi i ( w _ { l } - w _ { j } ^ { o } ) \\cdot t } d t } \\\\ { \\leq } & { a _ { j } ( 1 + \\mathcal { O } ( \\frac { A ^ { 2 } \\epsilon / A ^ { \\prime } } { k ^ { 3 } } ) ) + ( k - 1 ) A \\mathcal { O } ( \\epsilon ^ { 2 } / \\eta k ) . } \\end{array}\n$$",
        "text_format": "latex",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "Then ",
        "page_idx": 4
    },
    {
        "type": "equation",
        "text": "$$\na _ { j } = ( \\epsilon ^ { 2 } / k ) ^ { d } \\int _ { t \\in [ 0 , k / \\epsilon ^ { 2 } ] ^ { d } } f ( t ) e ^ { - 2 \\pi i w _ { j } ^ { o } \\cdot t } d t + { \\cal O } ( A ^ { 2 } \\epsilon / ( A ^ { \\prime } ) ) .\n$$",
        "text_format": "latex",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "We can use the Monte Carlo method to compute the integral ",
        "page_idx": 4
    },
    {
        "type": "equation",
        "text": "$$\n( { \\epsilon ^ { 2 } } / { k } ) ^ { d } \\int _ { t \\in [ 0 , k / { \\epsilon ^ { 2 } } ] ^ { d } } f ( t ) e ^ { - 2 \\pi i w _ { j } ^ { o } \\cdot t } d t .\n$$",
        "text_format": "latex",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "Choosing the random samples $\\{ f ( t _ { i } ) e ^ { - 2 \\pi i w _ { j } ^ { o } \\cdot t _ { i } } \\} _ { i = 1 } ^ { N _ { \\epsilon } }$ obeying the uniform distribution on $[ 0 , k / \\epsilon ^ { 2 } ] ^ { d }$ , where $N _ { \\epsilon } = \\mathcal { O } ( \\log ( 1 / \\delta ) A ^ { \\prime 2 } / ( A \\epsilon ) ^ { 2 } )$ . By Hoeffding's inequality, with probability at least $1 - \\delta$ ， ",
        "page_idx": 5
    },
    {
        "type": "equation",
        "text": "$$\n\\left| \\frac { 1 } { N _ { \\epsilon } } \\sum _ { i = 1 } ^ { N _ { \\epsilon } } f ( t _ { i } ) e ^ { - 2 \\pi i w _ { j } ^ { o } \\cdot t _ { i } } - ( \\epsilon ^ { 2 } / k ) ^ { d } \\int _ { t \\in [ 0 , k / \\epsilon ^ { 2 } ] ^ { d } } f ( t ) e ^ { - 2 \\pi i w _ { j } ^ { o } \\cdot t } d t \\right| < A ^ { 2 } \\epsilon / A ^ { \\prime }\n$$",
        "text_format": "latex",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "Therefore, the amplitude $a _ { j }$ can be recovered (up to $\\mathcal { O } ( A ^ { 2 } \\epsilon / A ^ { \\prime } ) )$ ",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "3 Proof of Lemma 2.1 ",
        "text_level": 1,
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "To prove Lemma 2.1, we need some technical lemmas. ",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "Lemma 3.1 Let $0 < \\beta < F / 2$ ， for each $f _ { j }$ ， the following inequalities ",
        "page_idx": 5
    },
    {
        "type": "equation",
        "text": "$$\n\\frac { 1 } { T ^ { d } } \\sum _ { \\xi \\in \\Gamma _ { 2 } } | \\mathcal { X } _ { \\phi _ { j , \\beta } } ( \\xi ) \\cdot \\mathcal { F } [ f _ { j } ] ( \\xi ) - \\mathcal { F } ( f _ { j } ) ( \\xi ) | ^ { 2 } \\leq \\mathcal { O } ( \\frac { d ^ { 3 / 2 } A ^ { 2 } } { T \\beta } ) ,\n$$",
        "text_format": "latex",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "holds for any $j \\in \\{ 1 , 2 , \\ldots , k \\}$ . Where ",
        "page_idx": 5
    },
    {
        "type": "equation",
        "text": "$$\n\\begin{array} { r } { \\mathcal { X } _ { \\phi _ { j , \\beta } } ( \\xi ) \\triangleq \\left\\{ \\begin{array} { l l } { 1 } & { \\xi \\in \\phi _ { j , \\beta } \\triangleq \\{ \\xi : | \\xi - w _ { j } | \\leq \\beta / 2 \\} } \\\\ { 0 } & { o t h e r w i s e } \\end{array} \\right. , j = 1 , \\dots , k . } \\end{array}\n$$",
        "text_format": "latex",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "Proof: For any $\\_$ and any $n \\in \\mathbb { Z } \\cap ( [ 2 , F T / 2 ) \\cup [ - F T / 2 , - 2 ] )$ ， we have ",
        "page_idx": 5
    },
    {
        "type": "equation",
        "text": "$$\n\\sum _ { j \\in \\mathbb { Z } \\cap \\left[ - \\frac { T F } { 2 } , \\frac { T F } { 2 } \\right) } \\exp ( 2 \\pi i \\alpha j / F ) \\exp \\left( \\left( - \\frac { 2 \\pi i j } { F } \\right) \\left( \\frac { n } { T } \\right) \\right) \\bigg | \\le \\frac { 2 } { T F | 1 - \\exp ( 2 \\pi i ( 1 / F ) ( \\alpha - \\frac { n } { T } ) } \n$$",
        "text_format": "latex",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "Since $| a _ { j } | \\le A$ , by (3.11), using Parseval's identity, we have ",
        "page_idx": 5
    },
    {
        "type": "equation",
        "text": "$$\n\\frac { 1 } { T ^ { d } } \\sum _ { \\xi \\in \\Gamma _ { 2 } } | \\mathcal { X } _ { \\phi _ { j , \\beta } } ( \\xi ) \\cdot \\mathcal { F } [ f _ { j } ] ( \\xi ) - \\mathcal { F } ( f _ { j } ) ( \\xi ) | ^ { 2 } \\leq \\mathcal { O } ( \\frac { d ^ { 3 / 2 } A ^ { 2 } } { T \\beta } ) ,\n$$",
        "text_format": "latex",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "which completes the proof. ",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "Lemma 3.2 Let $s = \\mathcal { O } ( k ^ { 2 } / \\delta )$ ， $F = s M$ . For any vector $w ^ { ' } \\in [ - 2 M , 2 M ] ^ { d }$ with $| w ^ { ' } | \\geq \\eta$ , the inequality （202 $| ( h ( w ^ { ' } ) ) _ { d } | > 2 F / s$ holds with probability at least $1 - \\delta / ( 8 k ^ { 2 } )$ over the randomness of $h _ { 1 } , h _ { 2 } , \\ldots , h _ { d }$ ， where $( h ( w ^ { ' } ) ) _ { d }$ denotes $d$ -th component of the vector $h ( w ^ { ' } )$ ， $w _ { i } ^ { ' }$ denotes $i$ -th component of the vector w， $\\{ h _ { 1 } , \\ldots , h _ { d } \\}$ are independent draw from the uniform distribution on the set $\\{ 2 n + 1 : n \\in \\mathbb { Z } \\} \\cap$ （20 （204号 $[ - \\sqrt { d } F / ( \\eta ) , \\sqrt { d } F / ( \\eta ) ]$ ： ",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "Proof: Without loss of generality, let us assume that the $d$ -th component $\\boldsymbol { w _ { d } ^ { ' } }$ of $w$ is greater than $\\eta / \\sqrt { d }$ Fix arbitrary $h _ { 1 } , \\ldots , h _ { d - 1 }$ , since $\\eta / \\sqrt { d } \\leq | w _ { d } ^ { ' } | \\leq 2 M$ , with probability at most $\\mathcal { O } ( 1 / s )$ (no greater than the ratio of the width of the set $[ - 2 F / s , 2 F / s ]$ to ${ \\mathcal { O } } ( F )$ , see the figure 3.2) over the randomness of $h _ { d }$ ， we have $\\begin{array} { r } { \\sum _ { i = 1 } ^ { d } h _ { i } w _ { i } ^ { ' } \\in [ - 2 F / s , 2 \\bar { F } / s ] ) } \\end{array}$ , which complete the proof. □ ",
        "page_idx": 5
    },
    {
        "type": "image",
        "img_path": "images/e463019bd3c225efb89ab54861678e5fa8439e9ea6df76018ba8934abab167dd.jpg",
        "img_caption": [
            "Figure 3.2: Let us assume $w _ { d } ^ { ' } > \\eta / \\sqrt { d }$ .Fix arbitrary $h _ { 1 } , \\ldots , h _ { d - 1 }$ .Without loss of generality, suppose $( h _ { 1 } , \\hdots , h _ { d - 1 } , 1 ) ^ { * } \\cdot w \\in [ - 2 F / s , 2 F / s ]$ . The red region represents the range of $h _ { d }$ such that （20 $\\textstyle \\sum _ { i = 1 } ^ { d } h _ { i } w _ { i } ^ { ' } \\in [ - 2 F / s , 2 F / s ]$ As $h _ { d }$ traverses the set $\\{ 2 n + 1 : n \\in \\mathbb { Z } \\} \\cap [ - \\sqrt { d } F / ( \\eta ) , \\sqrt { d } F / ( \\eta ) ]$ ，the ratio of the area of the red region to the total area (the sum of the red region and the blue region) is $\\mathcal { O } ( 1 / s )$ ， which is approximately equal to the success probability for $\\textstyle \\sum _ { i = 1 } ^ { d } h _ { i } w _ { i } ^ { \\prime } \\in [ - 2 F / s , 2 F / s ]$ . "
        ],
        "img_footnote": [],
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "Notice that the number of vectors $\\{ w _ { i } - w _ { j } : 1 \\leq i < j \\leq k \\}$ is $k ( k - 1 ) / 2$ . From Lemma 3.2, the probability of the union of the collision events (namely, $( h ( w _ { i } - w _ { j } ) ) _ { d } \\in ( - 2 F / s , 2 F / s ) )$ is at most ",
        "page_idx": 6
    },
    {
        "type": "equation",
        "text": "$$\n\\frac { \\frac { k ( k - 1 ) } { 2 } \\times ( \\frac { \\delta } { 8 k ^ { 2 } } \\times \\bar { H } ) } { \\bar { H } } = \\frac { k ( k - 1 ) \\delta } { 1 6 k ^ { 2 } } ,\n$$",
        "text_format": "latex",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "where $H$ denotes the number of elements in the set $\\{ 2 n + 1 : n \\in \\mathbb { Z } \\} ^ { d } \\cap [ - \\sqrt { d } F / ( \\eta ) , \\sqrt { d } F / ( \\eta ) ] ^ { d } .$ （204号 Therefore, we have a following consequence. ",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "Corollary 3.3 All parameters are set as above lemma. Suppose the vectors $w _ { 1 } , \\ldots , w _ { k } \\in [ - M , M ] ^ { d }$ satisfy ",
        "page_idx": 6
    },
    {
        "type": "equation",
        "text": "$$\n\\operatorname* { m i n } _ { i \\neq j } | w _ { i } - w _ { j } | > \\eta ,\n$$",
        "text_format": "latex",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "then ",
        "page_idx": 6
    },
    {
        "type": "equation",
        "text": "$$\n\\operatorname* { m i n } _ { 1 \\leq i < j \\leq k } | ( h ( w _ { i } - w _ { j } ) ) _ { d } | > 2 F / s\n$$",
        "text_format": "latex",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "holds with probability at least $1 - \\delta / 8$ over the randomness of $h _ { 1 } , h _ { 2 } , \\ldots , h _ { d }$ ",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "Suppose $d F \\beta / \\eta \\le F \\delta / ( 8 k s )$ . For any $\\xi _ { 1 } , \\xi _ { 2 } \\in \\phi _ { j , \\beta }$ ，we have $| ( h ( \\xi _ { 1 } ) - h ( \\xi _ { 2 } ) ) _ { d } | \\le \\delta F / ( 8 k s ) < F / s$ However, this does not mean that there is a bucket $B _ { j _ { s } }$ such that $h ( \\phi _ { j , \\beta } ) \\subset B _ { j _ { s } }$ . It is possible that $h ( \\phi _ { j , \\beta } )$ intersects on the boundary of some bucket. Obviously,after adding random translation, with a certain probability (the ratio of the total “width” of the sets $\\phi _ { j , \\beta } , j = 1 , 2 , \\ldots , k$ to the“width” of the bucket)， there exists a bucket $B _ { j _ { s } }$ such that $H ( \\phi _ { j , \\beta } )$ is completely inside it, that is, the following conclusion holds. ",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "Lemma 3.4 Suppose $d F \\beta / \\eta \\le F \\delta / ( 8 k s )$ ， with probability at least $1 - \\delta / 8$ over the randomness of $b$ ， there exists a bucket $B _ { j _ { s } }$ such that $H ( \\phi _ { j , \\beta } ) \\subset B _ { j _ { s } }$ for $j { = } 1 , 2 , \\ldots , k$ ",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "Now we give the proof of Lemma 2.1. Choosing $s = \\mathcal { O } ( ( k ^ { 2 } / \\delta ) )$ ， $\\beta = \\eta \\delta / ( 8 d k s )$ ， $F = s M$ and $\\begin{array} { r } { T = \\mathcal { O } ( k ^ { 5 } d ^ { 5 / 2 } / ( ( \\frac { \\epsilon \\sqrt { \\delta } } { \\sqrt { d s } } ) ^ { 2 } \\eta \\delta ^ { 2 } ) ) } \\end{array}$ .Bytheineqait(.)h ",
        "page_idx": 7
    },
    {
        "type": "equation",
        "text": "$$\n\\frac { 1 } { T ^ { d } } \\sum _ { \\xi \\in \\Gamma _ { 2 } } | \\mathcal { X } _ { \\phi _ { j , \\beta } } ( \\xi ) \\cdot \\mathcal { F } [ f _ { j } ] ( \\xi ) - \\mathcal { F } ( f _ { j } ) ( \\xi ) | ^ { 2 } \\le { \\cal O } ( A ^ { 2 } \\epsilon ^ { 2 } \\delta / ( d s k ^ { 2 } ) ) .\n$$",
        "text_format": "latex",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "From Corollary 3.3,Lemma 3.4 we know that for each bucket $B _ { j }$ ， there is at most one set $\\phi _ { j _ { k } , \\beta }$ （204 such that $H ( \\phi _ { j _ { k } , \\beta } ) \\subset B _ { j }$ . Using the inequality (3.13), since $\\chi _ { \\phi _ { j , \\beta } } ( H ^ { - 1 } ( \\xi ) ) = \\chi _ { H ( \\phi _ { j , \\beta } ) } ( \\xi )$ ，then with probability at least $1 - \\delta / 4$ over the randomness of $\\{ h _ { 1 } , \\ldots , h _ { d } , b \\}$ ， for each bucket $B _ { j }$ ，either ",
        "page_idx": 7
    },
    {
        "type": "equation",
        "text": "$$\n\\frac { 1 } { T ^ { d } } \\sum _ { \\xi \\in \\Gamma _ { 2 } } | \\mathcal { X } _ { B _ { j } } ( \\xi ) \\cdot \\mathcal { F } [ f ] ( H ^ { - 1 } ( \\xi ) ) - \\mathcal { F } ( f _ { j _ { k } } ) ( H ^ { - 1 } ( \\xi ) ) | ^ { 2 } \\le \\mathcal { O } ( A ^ { 2 } \\epsilon ^ { 2 } \\delta / ( d s ) ) ,\n$$",
        "text_format": "latex",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "or ",
        "page_idx": 7
    },
    {
        "type": "equation",
        "text": "$$\n\\frac { 1 } { T ^ { d } } \\sum _ { \\xi \\in \\Gamma _ { 2 } } | \\mathcal { X } _ { B _ { j } } ( \\xi ) \\cdot \\mathcal { F } [ f ] ( H ^ { - 1 } ( \\xi ) ) | ^ { 2 } \\leq \\mathcal { O } ( A ^ { 2 } \\epsilon ^ { 2 } \\delta / ( d s ) ) .\n$$",
        "text_format": "latex",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Since $\\mathcal { F } [ f _ { H } ] ( \\xi ) = \\mathcal { F } [ f ] ( H ^ { - 1 } \\xi )$ , we complete the proof by Parseval's identity. ",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "4Proof of Lemma 4.1 ",
        "text_level": 1,
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "The following lemma reduces the computational complexity of the convolution operation. The classical method to reduce the computational complexity (from $P o l y ( T F )$ to $P o l y ( L o g ( T F ) )$ is to select an appropriate window, such as the $S i n c \\times G a u s s i a n$ window [17],which can approximate the indicative function in the frequency domain and rapidly decay in the time domain. In this paper, we do not add windows for brevity, instead, we choose the appropriate sampling method. ",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Lemma 4.1 For any $0 < \\epsilon < 1 / 2$ ， $1 \\le j \\le s$ ， suppose ",
        "page_idx": 7
    },
    {
        "type": "equation",
        "text": "$$\nN = \\mathcal { O } \\bigg ( \\frac { k ^ { 2 } A ^ { 2 } \\ln ^ { 2 } ( T F ) \\ln ^ { 2 } ( 1 / \\delta ) } { \\epsilon ^ { 2 } } \\bigg ) ,\n$$",
        "text_format": "latex",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "then with probability at least $1 - \\delta / 4$ over the randomness $\\tau$ ， the following inequality holds ",
        "page_idx": 7
    },
    {
        "type": "equation",
        "text": "$$\n-\n$$",
        "text_format": "latex",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "where $\\mathcal { T } \\triangleq \\{ t _ { 1 } , \\dots , t _ { N } \\}$ are independent draws from the uniform distribution on $( - 1 / 2 , 1 / 2 )$ ， ",
        "page_idx": 7
    },
    {
        "type": "equation",
        "text": "$$\nv _ { j } ( t ) = 2 \\ln { \\left( \\frac { T F } { 2 } + 1 \\right) } \\left( \\frac { T F } { 2 } + 1 \\right) ^ { 2 t } v _ { 2 , j } \\left( \\left\\lfloor \\mathrm { ~ s g n ~ } ( t ) \\left( \\left( \\frac { T F } { 2 } + 1 \\right) ^ { 2 \\left| t \\right| } - 1 \\right) \\right\\rfloor \\right) ,\n$$",
        "text_format": "latex",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "and ",
        "page_idx": 7
    },
    {
        "type": "equation",
        "text": "$$\nv _ { 2 , j } ( y ) \\triangleq \\left\\{ \\begin{array} { l l } { \\frac { \\exp ( - \\pi i y ) ( \\exp ( \\frac { 2 \\pi i y ( j - 1 ) } { s } ) - \\exp ( \\frac { 2 \\pi i y j } { s } ) ) } { T F ( 1 - \\exp ( 2 \\pi i y / T F ) ) } ~ } & { y \\neq 0 } \\\\ { 1 / s ~ } & { y = 0 } \\end{array} \\right. .\n$$",
        "text_format": "latex",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Proof: Observe that ",
        "page_idx": 8
    },
    {
        "type": "equation",
        "text": "$$\n\\sum _ { w \\in \\mathbb { Z } \\cap \\left[ - T F / 2 , T F / 2 \\right) } \\exp \\left( \\frac { 2 \\pi i n w } { T F } \\right) = 0 \\quad \\mathrm { f o r } \\quad n \\in \\mathbb { N } ^ { + } \\cup \\mathbb { N } ^ { - } ,\n$$",
        "text_format": "latex",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "then ",
        "page_idx": 8
    },
    {
        "type": "equation",
        "text": "$$\n\\begin{array} { r l } & { \\mathcal { F } ^ { - 1 } [ \\mathcal { X } _ { B _ { j } } \\cdot \\mathcal { F } [ f _ { H } ] ] ( x ) = \\sum _ { y \\in \\Gamma _ { 1 } } \\frac { f _ { H } ( x - y ) \\mathcal { F } ^ { - 1 } ( \\mathcal { X } _ { j } ) ( y ) } { ( \\sqrt { T } F ) ^ { d } } } \\\\ { = } & { \\sum _ { z \\in \\mathbb { Z } \\cap \\{ \\frac { - T F } { 2 } , \\frac { T F } { 2 } \\} } f _ { H } ( x - ( 0 , \\ldots , 0 , \\frac { z } { F } ) ^ { * } ) v _ { 2 , j } ( z ) } \\\\ { = } & { \\int _ { 0 } ^ { T F / 2 } f _ { H } ( x - ( 0 , \\ldots , 0 , \\frac { | z | } { F } ) ^ { * } ) ( z + 1 ) 2 \\ln ( 1 + T F / 2 ) v _ { 2 , j } ( z ) d \\big ( \\frac { \\ln ( z + 1 ) } { 2 \\ln ( 1 + T F / 2 ) } \\big ) } \\\\ { + } & { \\int _ { - T F / 2 } ^ { 0 } f _ { H } ( x - ( 0 , \\ldots , 0 , \\frac { | z | } { F } ) ^ { * } ) ( - z + 1 ) 2 \\ln ( 1 + T F / 2 ) v _ { 2 , j } ( z ) d \\big ( \\frac { \\ln ( - z + 1 ) } { 2 \\ln ( 1 + T F / 2 ) } \\big ) } \\\\ { = } & { \\int _ { - 1 / 2 } ^ { 1 / 2 } f _ { H } ( x - ( 0 , \\ldots , 0 , \\frac { \\left| \\mathrm { s g n } ( t ) ( ( \\frac { T F } { 2 } + 1 ) ^ { 2 } | t | - 1 ) \\right| } { F } ) ^ { * } ) v _ { j } ( t ) d t , } \\end{array}\n$$",
        "text_format": "latex",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "where $\\operatorname { s u p } _ { t \\in [ - 1 / 2 , 1 / 2 ] }$ $| v ( t ) | \\leq \\mathcal { O } ( \\ln ( T F ) )$ ",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "When we fix $x$ , the above integral can be calculated by Monte Carlo method, and the error can be estimated by Hoefding's inequality. However, when we want to obtain the uniform error for all $x$ in $\\Gamma _ { 1 }$ ， we need to use the Rademacher complexity [27, 28]. We consider the Rademacher complexity of the following function spaces ",
        "page_idx": 8
    },
    {
        "type": "equation",
        "text": "$$\nQ _ { w , u , C _ { 0 } } \\triangleq \\{ q _ { x } ( t ) \\triangleq u ( t ) \\sin ( 2 \\pi w ( \\frac { x - \\lfloor \\mathrm { ~ s g n ~ } ( t ) ( ( \\frac { T F } { 2 } + 1 ) ^ { 2 \\lvert t \\rvert } - 1 ) \\rfloor } { F } ) \\} ,\n$$",
        "text_format": "latex",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "and ",
        "page_idx": 8
    },
    {
        "type": "equation",
        "text": "$$\nQ _ { w , u , C _ { 0 } } ^ { ' } \\triangleq \\{ q _ { x } ^ { ' } ( t ) \\triangleq u ( t ) \\cos ( 2 \\pi w ( \\frac { x - \\lfloor \\mathrm { s g n } ( t ) ( ( \\frac { T F } { 2 } + 1 ) ^ { 2 \\lvert t \\rvert } - 1 ) \\rfloor } { F } ) \\} ,\n$$",
        "text_format": "latex",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "where $w , x , t \\in \\mathbb { R }$ and $u ( t )$ is any real-valued function satisfying $| u | \\leq C _ { 0 }$ .Let $\\widehat { \\mathrm { R e } } ( \\mathcal { T } ; Q _ { w , u , C _ { 0 } } )$ denote the empirical Rademacher complexity for $Q _ { w , u , C _ { 0 } }$ and $\\tau$ ，then ",
        "page_idx": 8
    },
    {
        "type": "equation",
        "text": "$$\n\\begin{array} { r l } & { \\widehat { \\mathrm { R e } } ( \\mathcal { T } ; Q _ { w , u , C _ { 0 } } ) = \\mathbb { E } _ { \\xi \\sim \\{ \\pm 1 \\} ^ { N } } \\left[ \\operatorname* { s u p } _ { x \\in \\mathbb { R } } \\sum _ { i = 1 } ^ { N } \\frac { \\xi _ { i } q _ { x } ( t _ { i } ) } { N } \\right] } \\\\ & { \\leq \\mathbb { E } _ { \\xi \\sim \\{ \\pm 1 \\} ^ { N } } \\bigg [ \\operatorname* { s u p } _ { ( z _ { 1 } , z _ { 2 } ) \\in [ - 1 , 1 ] ^ { 2 } } \\sum _ { i = 1 } ^ { N } \\frac { \\xi _ { i } ( z _ { 1 } y _ { i , 1 } - z _ { 2 } y _ { i , 2 } ) } { N } \\bigg ] \\leq \\frac { 2 C _ { 0 } } { \\sqrt { N } } , } \\end{array}\n$$",
        "text_format": "latex",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "where ",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "Yi,1 = cos( $\\cos ( \\frac { 2 \\pi w \\lfloor \\operatorname { s g n } { \\left( t _ { i } \\right) } { \\left( \\big ( \\frac { T F } { 2 } + 1 \\big ) ^ { 2 \\lfloor t _ { i } \\rfloor } - 1 \\right) } } { F } ) u ( t _ { i } ) , \\quad y _ { i , 2 } = \\sin ( \\frac { 2 \\pi w \\lfloor \\operatorname { s g n } { \\left( t _ { i } \\right) } { \\left( \\big ( \\frac { T F } { 2 } + 1 \\big ) ^ { 2 \\lfloor t _ { i } \\rfloor } - 1 \\right) } } { F } )$ 2wsg(t the last inequality in (4.19) is obtained by Lemma 26.10 in[27]. Similarly, we have $\\widehat { \\mathrm { R e } } ( \\mathcal { T } ; Q _ { w , u , C _ { 0 } } ^ { ' } ) \\leq$ 2CQ （204号 $\\frac { 2 C _ { 0 } } { \\sqrt { N } }$ 1 ",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "Combining the last equality in (4.18) and Lemma A.1O in [28] proves Lemma 4.1. ",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "5 Conclusion ",
        "text_level": 1,
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "The hashing transform we construct is also applicable to the case of latice (as considered in [20, 21, 22,23l),which we have not covered in this paper.We do not consider the case of noise, so it is an issue that need to be discussed later. In addition, whether the high-dimensional signal without frequency gap can be effctively reconstructed (just like one-dimensional case [25])? In terms of application, it is worthy to optimize the algorithm and the complexity estimation to make it more applicable to practice. ",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "References ",
        "text_level": 1,
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "[1] A.C. Gilbert,P.Indyk,M. Iwen,and L. Schmidt,“Recent developments in the sparse fourier transform: A compressed fourier transform for big data,” IEEE Signal Processng Magazine, vol.31, no.5, pp.91-100, 2014.   \n[2] E. Kushilevitz and Y. Mansour,“Learning decision tres using the fourier spectrum,” SIAM Journal on Computing,vol. 22,no.6,pp.1331-1348,1993.   \n[3] M.A.Iwen,“Combinatorial sublinear-time fourier algorithms,” Foundations of Computational Mathematics,pp.303-338,2010.   \n[4] -,“Improved approximation guarantees for sublinear-time fourier algorithms,” Applied And Computational Harmonic Analysis, vol. 34, no. 1, pp. 57-82, 2013.   \n[5] D.Pots and T. Volkmer，“Sparse high-dimensional fft based on rank-1 lattice sampling,” Applied and Computational Harmonic Analysis, vol. 41,no.3, pp.713-748, 2016.   \n[6] S. Merhi,R. Zhang,M.A.Iwen,and A. Christlieb,“A new class of fully discrete sparse fourier transforms: Faster stable implementations with guarantees,” Journal of Fourier Analysis and Applications, no. 1, pp. 1-34, 2017.   \n[7] S.Bittens,R. Zhang,and M.A. Iwen,“A deterministic sparse ft for functions with structured fourier sparsity,” Advances in Computational Mathematics, vol. 45, no. 2, pp. 519-561, 2019.   \n[8] B. Choi, M.A. Iwen,and F.Krahmer，“Sparse harmonic transforms: A new class of sublinear-time algorithms for learning functions of many variables,” Foundations of Computational Mathematics, pp. 1-55，2020.   \n[9] S.-H. Hsieh,C.-S.Lu,and S.-C.Pei,“Sparse fast fourier transform by downsampling,” in 2013 IEEE International Conference on Acoustics， Speech and Signal Processing. IEEE, 20l3, pp. 5637-5641.   \n[10] S.Liu,T.Shan, R. Tao, Y.D. Zhang,and Y. Wang,“Sparse discrete fractional fourier transform and its applications,” IEEE Transactions on Signal Processing, vol. 62, no. 24, p. 6582C6595, 2014.   \n[11] L.Shi, H. Hassanieh,A. Davis,D.Katabi,F. Durand.“Light feld reconstruction using sparsity in the continuous fourier domain,” ACM Transactions on Graphics, pp.1-13,2014.   \n[12] S.Pawar and K. Ramchandran,“FFAST: An algorithm for computing an exactly $k$ -sparse DFT in $\\mathcal { O } ( k l o g k )$ （20 time,” IEEE Transactions on Information Theory, vol. 64, no.1, pp. 429-450, 2017.   \n[13] S. Wang, V.M. Patel,and A. Petropulu,“The robust sparse fourier transform (rsft)and its application in radar signal procesing,” IEEE Transactions on Aerospace and Electronic Systems, pp. 2735-2755, 2017.   \n[14]- ，“Multidimensional sparse fourier transform based on the fourier projection-slice theorem,” IEEE Transactions on Signal Processing, vol. 67, no. 1, pp. 54-69, 2018.   \n[15] A. C.Gilbert,S. Guha,P.Indyk, S.Muthukrishnan,and M. Strauss,“Near-optimal sparse fourier representations via sampling,” in Proceedings of the thiry-fourth annual ACM symposium on Theory of computing, 2002,pp.152-161.   \n[16]A.C. Gilbert, S. Muthukrishnan,and M. Strauss,“Improved time bounds for near-optimal sparse fourier representations,” in Wavelets XI, vol. 5914.International Society for Optics and Photonics, 2005,p. 59141A.   \n[17] H.Hassanieh,P.Indyk,D.Katabi,and E.Price,“Simple and practical algorithm for sparse fourier transform, in Proceedings of the twenty-third annual ACM-SIAM symposium on Discrete Algorithms. SIAM, 2012, pp. 1183-1194.   \n[18]P.Boufounos, V. Cevher，A. C. Gilbert，Y.Li,and M. J. Strauss,“Whats the frequency, kenneth?: Sublinear fourier sampling off the grid,” Algorithmica, vol. 73, no. 2, pp. 261-288, 2015.   \n[19]M.Kapralov,“Sparse fourier transform in any constant dimension with nearly-optimal sample complexity in sublinear time,” in Proceedings of the forty-eighth annual ACM symposium on Theory of Computing, 2016, pp. 264-277.   \n[20]M.Kapralov,A. Velingker,and A.Zandieh,“Dimension-independent sparse fourier transform,” in Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms. SIAM,2019, pp. 2709-2728.   \n[21] L.Kämmerer, D.Pots,and T. Volkmer,“High-dimensional sparse FFT based on sampling along multiple rank-1 latices,” Applied and Computational Harmonic Analysis, vol. 51, pp. 225-257, 2020.   \n[2] B.Choi,A. Christlieb,and Y. Wang,“Multiscale high-dimensional sparse fourier algorithms for noisy data,” arXiv preprint arXiv:1907.03692, 2019.   \n[23] -,“High-dimensional sparse fourier algorithms,” Numerical Algorithms, pp. 1-26, 2020.   \n[24] E.Price and Z. Song,“A robust sparse fourier transform in the continuous setting,” in 2015 IEEE 56th Annual Symposium on Foundations of Computer Science. IEEE, 2015, pp. 583-600.   \n[25] X.Chen, D. M. Kane,E. Price,and Z. Song,“Fourier-sparse interpolation without a frequency gap,” in 2016 IEEE 57th Annual Symposium on Foundations of Computer Science. IEEE, 2016,pp.741-750.   \n[26] Y.Jin,D.Liu, and Z. Song,“A robust multi-dimensional sparse fourier transform in the continuous setting,” arXiv preprint arXiv:2005.06156,2020.   \n[27] S.Shalev-Shwartz and S.Ben-David, Understanding machine learning: From theory to algorithms.Cambridge university press, 2014.   \n[28] Z. Allen-Zhu, Y. Li,and Y. Liang,“Learning and generalization in overparameterized neural networks, going beyond two layers,” in Aduances in neural information processing systems, 2019, pp. 6158-6169. ",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 10
    }
]