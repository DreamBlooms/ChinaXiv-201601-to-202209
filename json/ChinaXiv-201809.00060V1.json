[
    {
        "type": "text",
        "text": "基于生成对抗网络的遮挡表情识别",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "王素琴，高宇豆，张加其(华北电力大学 控制与计算机工程学院，北京 102206)",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "摘要：针对实际应用中局部遮挡会影响人脸表情识别，提出一种基于生成对抗网络（GAN）的表情识别算法，先对遮挡人脸图像填补修复，再进行表情识别。其中GAN的生成器由卷积自动编码机构成，与鉴别器的对抗学习使得生成的人脸图像更加逼真。由卷积神经网络构成的鉴别器具有良好的特征提取能力，添加多分类层构成了表情分类器，避免了重新计算图像特征。为了解决训练样本不足的问题，将celebA人脸数据集用于训练人脸填补修复，同时表情分类器的特征提取部分得到了预训练。在 $\\mathrm { C K ^ { + } }$ 数据集上的实验证明，填补后的人脸图像真实连贯，并取得了较高的表情识别率，尤其提高了人脸大面积遮挡的识别率。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "关键词：人脸表情识别；局部遮挡；人脸修复；生成对抗网络；卷积神经网络中图分类号：TP391.4 doi:10.3969/j.issn.1001-3695.2018.06.0360",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Occluded facial expression recognition based on generative adversarial networks ",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Wang Suqin, Gao Yudou, Zhang Jiaqi (SchoolofControl& ComputerEngineering,North China Electric Power University,Beijing102206,China) ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Abstract:Aimingatthefactthatpartialolusionaffectsfacialexpressonrcogniioninpracticalappications,anexpsion recognition methodbasedongenerativeadversarial networks (GAN)is proposed.Firstly,theocclusionfaceimagesarefille andrepaired,and thentheexpresionrecognitionisperformed.ThegeneratorofGANiscomposedofaconvolutionalAuto encoder,the face images generated byadversarial learning between generatorand discriminatorare more vivid.The discriminatoriscomposedoftheconvolutional neural networkand ithasgood feature extractionability,andamulticlasificationlayerisaddedtoconstructtheexpresionclasifier,which avoids featurere-calulation.Inordertosolvethe problemof insufcient training samples,thecelebA face dataset is used to train face flingand repairing,and the feature extraction part of the expression classfier is pre-trained. Experiments on the $\\mathrm { C K ^ { + } }$ dataset show that the face images after filling areealadcoherent,andaigherxpressonrecognitionrateishved,specialltheecognitionateoflarge-areaion of the face is improved. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Key words:facial expressionrecognition;partialoclusion;facecompletion;generativeadversarial network;convolutional neural network ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "0 引言",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "人类情感多借助于面部表情进行传递[I]，利用图像处理技术对人脸面部表情进行识别具有重要意义。随着计算机技术的进步以及GPU等电脑硬件的发展，表情识别得到了长足的发展。文献[2\\~4]使用卷积神经网络CNN在标准的表情数据集上取得了很好的识别准确率。除了常见的7种基本表情，微表情持续时间很短，却饱含了人们隐藏的真实情感，对其进行识别是表情识别领域的一个研究热点，将微表情识别用于测谎，对公共安全、侦察破案等具有十分重要的作用[5]。但在实际应用中，拍摄到的人脸图像往往存在局部遮挡，常见的遮挡物有手、眼镜、口罩等，这些遮挡会干扰表情特征的提取，影响表情判别的准确性。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "目前对局部遮挡的人脸进行表情识别一般采用非深度学习的方法，其主要思路总体上分为舍弃法和填补法两种。舍弃法是通过稀疏表示等方法将遮挡部分的信息简化或者丢弃，主要根据未遮挡部位进行表情识别。文献[6,7]基于稀疏表示提出了遮挡人脸表情识别方法，利用未遮挡部分构建字典，通过稀疏求解得到稀疏表示系数，最终实现待测人脸图像的表情判别。由于人的嘴巴、眼睛、鼻子等含有大量的表情信息，当这些部位被遮挡时，直接舍弃明显不合理。填补法则是先对遮挡部分进行填补，尽可能还原人脸未遮挡的状态，再进行表情识别。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "薛雨丽等人[8采用鲁棒主成分分析法和显著性检测法重构被遮挡像素，然后由权值更新的AdaBoost分类器对去除遮挡的人脸图像进行表情识别。由于其使用的信息较为局限，难以保证填补效果，同时人工特征的设计繁琐，难以应对复杂的场景变化，鲁棒性较差。文献[9,10]利用卷积神经网络直接进行有遮挡的人脸表情识别，提高了识别的鲁棒性，但当遮挡区域较大时，准确率迅速下降。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "因此，对于有遮挡特别是大面积遮挡的人脸图像，考虑先将其遮挡区域进行填补，使整幅图像看上去真实连贯，有利于表情判别。本文基于生成对抗网络构建一个遮挡表情识别模型，充分利用图像中未遮挡区域的像素信息，输入到由卷积自动编码机构建的生成器中进行人脸遮挡图像的填补修复，鉴别器在大量对抗训练中可以学习到人脸图像的特征表示，基于该特征表示添加多分类层构成分类器可以对填补后的图像进行表情识别。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "1 相关工作",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "生成对抗网络（generative adversarial networks,GAN）[1]是当前人工智能领域的一大研究热点，是一种生成式模型，由生成器（generator，G）和鉴别器（discriminator，D）共同组成。生成器通过学习真实样本数据的分布规律来生成尽可能真实的伪数据，而鉴别器本质上为一个二分类器，它需要甄别出输入数据是真实样本还是生成器的输出。受二人零和博弈思想的启发，提出让生成器和鉴别器之间相互对抗，在对抗中迭代优化，不断提升各自的生成能力和鉴别能力，使生成器能够估测到数据样本的分布，生成的样本效果逼真。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "GAN模型在图像生成、图像修补以及图像去噪等领域应用广泛，同时衍生出许多改进的模型。文献[12]将GAN和卷积神经网络（CNN)结合起来得到深度卷积生成对抗网络（DCGAN），生成器和鉴别器均为卷积神经网络，在各个数据集上进行训练都得到了不错的结果，其特征表达能力强，使用得到的特征表示进行图像分类，效果较好。BrandonAmos等人[13]直接使用该模型在人脸数据集上进行了图像填补实验，从模型生成的人脸图像中找到与原始图像最相似的一幅，然后根据其遮挡区域的位置掩码来替代填补原始图像，该方法可以填补得到一张内容上完整的人脸图像，但存在图像整体连贯性较差，适用性受限等问题。文献[14]提出了一个基于深度生成模型的人脸修复算法，它使用了两个鉴别器，分别判断整个图像区域和缺失区域的真假，最后使用一个解析网络进一步完善缺失区域的生成图像，该算法能够生成比较逼真的人脸图像，但将其结果直接用于表情识别存在诸多不适应，因为本文的目的是为了得到正确的表情类别，其填补内容需要在不误导表情判别的基础上，合理地增加表情信息。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "除了生成视觉逼真的图像，GAN还可以用于分类。深度神经网络在图像识别、对象分类等领域取得的成功很大程度上取决于大量的手动标注的训练数据集，然而在许多应用中，这样带标签的数据量往往不能满足深度模型训练的需要，将无标签的样本数据加入训练可进行半监督分类。文献[15,16]提出了将GAN的鉴别器由原来的二分类改为一个多分类器，此时生成器输出样本可用于训练分类器，作为N分类问题的第 $\\mathbf { N } { + } \\mathbf { l }$ 类。该模型不仅利用有标签的训练样本，而且从无标签的生成样本中学习特征。本文对人脸进行填补修复以后还要完成一个表情多分类问题，因此基于这种半监督分类的思想，考虑将GAN的鉴别器和表情分类器结合起来，若使用深度卷积神经网络来构造GAN模型的鉴别器，其本身就具有很强的特征提取能力，可以用于多分类任务，同时生成器的输出样本也发挥了扩充样本数量的作用，提高分类模型的泛化能力。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "2 本文模型",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "本文基于GAN 构建了一个鲁棒的遮挡表情识别模型，对于一幅遮挡的人脸图像，首先要合成其遮挡区域的内容得到填补图像，进而正确地判断表情类别。模型的总体架构如图1所示，图中以黑色矩形框模拟遮挡物。",
        "page_idx": 1
    },
    {
        "type": "image",
        "img_path": "images/dc11760ab5651a1e18ea2d83cf35732e0db852ee5de48e0757e6fd17c57f0a0e.jpg",
        "img_caption": [
            "图1模型的总体架构"
        ],
        "img_footnote": [],
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "模型主要由生成器G、鉴别器D和分类器C三个部分构成，功能上则可分为人脸填补和表情识别两个模块。人脸填补模块由生成器和鉴别器组成，将遮挡人脸图像输入到生成器中得到填补后的人脸图像，为了使填补效果更真实合理，通过鉴别器来判断图像为真实无遮挡人脸（真）还是生成器填补图像(假)。表情识别模块在鉴别器的基础上，使用了其部分卷积层和池化层，将其作为特征提取器，额外加入两层全连接层和Softmax层构成了表情分类器。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "2.1生成器G ",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "不同于原始GAN，本文生成器G的输入不再是随机噪声，而是遮挡人脸图像。其本质上是一个卷积自动编码机，由编码器和解码器组成，首先编码器通过多次卷积池化操作将模型输入映射到一个隐藏层表示，其中包含了原遮挡图像中已知区域和待填补区域之间的隐含关系，解码器利用这些隐含信息生成填补内容。生成器的网络结构如图2所示，其中编码器和解码器网络结构对称，互为逆操作。编码器参考VGG[17]的模型结构，由卷积层Conv(和池化层Pooling(组成，其中 $\\mathrm { C o n v } ( 6 4 , 3 \\times 3$ ，$1 \\times 1 \\AA ^ { \\cdot }$ 表示该卷积层由64个大小为 $3 \\times 3$ ，步长为1的卷积核组成，在每个卷积层后都紧接一个LeakyReLU激活层和一个Batchnormalization归一化层，在池化层中进行最大池化操作，pooling $( 2 \\times 2 )$ 表示窗口大小为 $2 \\times 2$ 的池化层，负责下采样。相应地，解码器通过卷积层Conv(和上采样层UpsamplingO逐步恢复人脸图像，在编码器和解码器之间采用了两层神经元个数为1024 的全连接层Dense(1024)作为中间层。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "2.2 鉴别器D ",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "鉴别器D对输入图像进行真假二分类。鉴别器的输入维度和生成器的输出维度一致，都为 $1 2 8 \\times 1 2 8$ 。在DCGAN中鉴别器为卷积核大小为 $5 \\times 5$ 的全卷积网络，由于卷积核较大、网络层次不深导致其特征提取能力有限，若仅用于一般意义上的二分类是足够的，但为了将其特征提取部分和后续表情分类器的特征提取部分整合起来，需要一个网络更深、结构更好的深度卷积神经网络。其中VGG16的卷积核大小为 $3 \\times 3$ ，一共有16层，包括13个卷积层和3个全连接层，多个卷积层与非线性的激活层交替的结构使得其特征提取能力较强，同时模型深度、性能等方面也较适合，因此本文基于VGG16构建了鉴别器。",
        "page_idx": 2
    },
    {
        "type": "image",
        "img_path": "images/dd0eb46b62d3e71fd8c1319aa88d6af584f462c21f45e693d531f95aba129a62.jpg",
        "img_caption": [
            "图2生成器网络结构"
        ],
        "img_footnote": [],
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "2.3分类器C",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "计算机为了完成表情识别任务，需要大量的带表情标签的训练数据，然而现有的表情数据集的数据有限，特别是将深度卷积神经网络引入后，更是需要大量的数据支撑，如果数据太少模型在训练中会很容易达到过拟合不能发挥模型本身的能力。$\\mathrm { C K + } ^ { [ 1 8 ] }$ 数据集 (The Extended Cohn-Kanade AU-Coded Database)是标准的人脸表情数据集，其中仅含有327个带标签的峰值表情图像，即使将部分非峰值表情图像也加入训练仍然不够。不过在人脸填补模块，模型的训练并不需要表情标签，因此可以利用现有的大量的人脸图像数据进行训练，鉴别器在训练过程不断加强人脸特征提取能力，利用鉴别器得到的特征表示可进行表情分类。因此分类器共享了鉴别器的部分卷积层和池化层来提取特征，总体上由特征提取层、两层全连接层和Softmax分类层构成，本质上是一个卷积神经网络。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "2.4损失函数",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "首先为生成器定义了重构损失函数 $l _ { r }$ ，它是通过计算生成网络输出结果 $\\mathrm { G } ( \\boldsymbol { z } )$ 和原始未遮挡图像y对应位置像素点i的像素差值来得到的，本文通过L2范数来衡量，值越小说明相似度越高。 $l _ { r }$ 定义为",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\nl _ { r } { = } \\sum _ { i = 0 } ^ { \\mathrm { m } } ( y ^ { i } - G ( z ) ^ { i } ) ^ { 2 }\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "为了让生成的图像尽可能真实，本文引入了对抗损失 $l _ { a }$ ，生成器G希望输出图像 $\\mathrm { G } ( \\boldsymbol { z } )$ 能够迷惑鉴别器D，而鉴别器则希望能准确判断输入图像的真假。和原始GAN对抗损失的定义一样， $l _ { a }$ 定义为如式（2）所示，Pdata为标准人脸图像的数据分布， $\\displaystyle { \\mathfrak { p } } _ { z }$ 是遮挡的人脸图像的数据分布。",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\n\\begin{array} { l } { { l _ { a } = \\displaystyle \\operatorname* { m i n } _ { G } \\operatorname* { m a x } _ { D } \\varepsilon _ { \\mathrm { x } \\sim \\mathsf { p } _ { d a t a } ( x ) } [ \\log D ( x ) ] + } } \\\\ { { \\varepsilon _ { \\mathrm { x } \\sim \\mathsf { p } _ { z } ( z ) } [ \\log ( 1 - D ( G ( z ) ) ) ] } } \\end{array}\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "在分类器中，采用交叉熵损失 $l _ { c }$ 来训练表情多分类，交叉熵描述了预测的概率分布 ${ \\bf q } ( { \\bf x } )$ 和真实概率分布 $\\mathfrak { p } ( \\mathbf { x } )$ 之间的距离。$l _ { c }$ 定义为",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\nl _ { \\mathrm { c } } { = } { - } \\sum _ { x } p ( x ) \\log q ( x )\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "模型的总体损失函数 $\\mathrm { ~ L ~ }$ 由 $l _ { r } \\cdot l _ { a }$ 和 $l _ { c }$ 三部分构成，定义为",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\n\\mathbf { L } = l _ { r } + \\lambda _ { 1 } l _ { a } + \\lambda _ { 2 } l _ { c }\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "其中: $\\lambda _ { 1 }$ 和 $\\lambda _ { 2 }$ 是权重因子，用于平衡二分类和多分类损失的比重。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "3 遮挡表情识别 ",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "本文实验在16GB内存的NVIDIAGeForceGTX1080Ti的GPU工作站上进行，基于标准人脸表情数据集 $\\mathrm { C K ^ { + } }$ 来衡量模型对遮挡人脸的表情识别能力。由于 $\\mathrm { C K ^ { + } }$ 数据量较小，需先利用CelebA[19]人脸数据集对人脸填补模块生成器和鉴别器进行预训练，再加入分类器在 $\\mathrm { C K ^ { + } }$ 数据集上进一步微调。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "3.1数据集处理",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "$\\mathrm { C K ^ { + } }$ 数据集包括123个人共595例的表情序列，包含从中性到表情峰值的所有图像帧，其中仅有327例图像序列有明确的标签，共分为7种表情（悲伤、快乐、愤怒、厌恶、惊讶、蔑视和恐惧)。为了扩大样本量，同时考虑实用性，加入非峰值表情以增强模型的泛化能力。将每例图像序列的开始图像作为中性表情样本，将图像序列中接近表情峰值的若干张图像作为该表情图像样本。共得到3559张表情样本，其中876张中性表情，260 张悲伤表情，627张快乐表情，482张愤怒表情，417张厌恶表情，640张惊讶表情，257张恐惧表情。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "为了进一步扩大样本量，并解决各类表情样本数量不均衡的问题，对数据集中的数据进行镜像翻转、旋转等操作，扩展后共有10537张表情图像，各类表情图像的数量在1200张左右。随机选择其中的1/5作为测试集，其余4/5为训练集，同时满足测试集和训练集的人物信息不交叉。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "CelebA人脸数据集来源于香港中文大学，包含10177个名人的202599张人脸图像。选取裁剪出人脸部分的图像作为本文基础训练数据集，随机选择其中的4/5作为训练集，剩余的1/5数据用于测试模型生成器的填补能力以及鉴别器的真假判别能力。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "3.2图像预处理及遮挡模拟",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "为了尽量避免光照和姿态变换等因素对表情识别的干扰，需要做图像预处理。首先对人脸图像进行归一化处理，采用加权平均法对彩色人脸图像进行灰度化处理，随后进行直方图均衡化处理，在不损失图像信息的基础上，降低图像数据大小，减少光照因素的干扰。根据检测出的人脸关键点(通常在眼角、鼻子、嘴巴、脸轮廓的位置）进行人脸对齐校准，可消除头部姿势不同对后续操作带来的误差，同时人脸各个器官部位在相对固定的位置将有助于特征的提取和分析。本文使用了OpenFace[20]的人脸对齐算法，采用集成回归树（ERT）[21]估计面部特征点来对齐人脸图像，最终校准后统一将图像的大小调整为 $1 2 8 \\times 1 2 8$ 。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "现实生活中一般存在两种遮挡，一种是由于手或者头部运动产生的临时遮挡，另一种则是由墨镜、口罩、围币等引起的系统遮挡[22]。由于目前没有一个通用的、成熟的遮挡人脸表情数据集，因此本文通过在人脸图像的不同位置添加黑色矩形框来模拟眼部、嘴部和随机遮挡，分别对应眼镜、口罩引起的系统遮挡和临时遮挡。经过图像预处理和遮挡模拟后的人脸图像如图3所示。经过人脸对齐操作，图像中的面部器官基本在同一位置，对图像中固定位置进行遮挡即可简单模拟系统遮挡，其中眼部遮挡面积大约为整个图像的 $1 5 \\%$ ，嘴巴遮挡面积大约为整个图像的 $2 5 \\%$ 。另外随机遮挡 $10 \\%$ 、 $20 \\%$ 、 $30 \\%$ 、 $40 \\%$ ，$50 \\%$ 、 $60 \\%$ 用于模拟位置不固定的临时遮挡，本文认为遮挡面积超过 $60 \\%$ 时，表情识别意义不大，故不作分析。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "3.3未填补前表情分类器的对比实验 ",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "为了进一步说明对遮挡人脸图像进行填补的意义以及和本文模型进行对比，本文在填补修复遮挡人脸图像前，直接使用了卷积神经网络对遮挡人脸图像进行了实验，同样采用了VGG16。但可供训练的数据量较少、网络较深导致模型从头训练难以达到很好的效果。VGGface的权重是在LFW（labeledfaces inthewild）数据集[23]上训练得到的，可用于与人脸图像相关的训练。基于迁移学习的思想，本文使用了VGGface的权重，在 $\\mathrm { C K ^ { + } }$ 数据集上进行微调，能够快速收敛且不需要很大的数据量。实验中采用了两种方法来训练卷积神经网络，方法1仅使用了标准的人脸图像进行训练，方法2则将遮挡的人脸图像也加入了模型的训练。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 3
    },
    {
        "type": "image",
        "img_path": "images/09f23ac73266882198466244e059e87f40bc00b8d85fecd48b679d9ef22d4d20.jpg",
        "img_caption": [
            "图3图像预处理和遮挡模拟"
        ],
        "img_footnote": [],
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "3.4本文模型训练 ",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "为了有效地训练模型，将整个模型的训练过程分为两大部分，分别是对人脸填补网络和表情分类网络的训练。模型首先在celebA数据集上训练人脸填补网络，先使用重构损失训练生成器使其得到一个模糊的填补内容，接着加入鉴别器对抗损失（即二分类损失）来联合训练，模型使用Adam优化器，初始学习率为0.0002，剩余的Adam超参数设置为默认值，50次迭代后学习率下降一个量级。当GAN 模型接近纳什均衡，二分类准确率大约0.5时，鉴别器几乎不能判断输入样本的真假，此时不再使用CelebA数据集，而是在 $\\mathrm { C K ^ { + } }$ 数据集上进行微调，同时加入了表情分类器的训练，起初通过设置样本权重，让模型使用填补图像和无遮挡图像各一半训练二分类器，而仅使用无遮挡图像训练多分类器，经过30次迭代后，将填补图像也加入到多分类器的训练。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "4 实验结果及分析",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "4.1未填补前表情分类器的实验结果",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "经4.3中两种方式训练VGGface后，对不同类型的遮挡人脸图像都进行了测试，结果如表1所示。",
        "page_idx": 4
    },
    {
        "type": "table",
        "img_path": "images/ace26ac98779068982a4c2e1690c39d9893cada54734bf88c6ff506a56e127d4.jpg",
        "table_caption": [
            "表1基于VGGface 的表情识别实验结果"
        ],
        "table_footnote": [],
        "table_body": "<html><body><table><tr><td>遮挡类型</td><td>遮挡面积</td><td>方法1</td><td>方法2</td></tr><tr><td>无遮挡</td><td>0</td><td>97.23</td><td>97.57</td></tr><tr><td>随机遮挡10%</td><td>40×40</td><td>80.46</td><td>94.98</td></tr><tr><td>随机遮挡20%</td><td>60×60</td><td>59.93</td><td>92.75</td></tr><tr><td>随机遮挡30%</td><td>70×70</td><td>49.71</td><td>89.69</td></tr><tr><td>随机遮挡40%</td><td>81×81</td><td>42.56</td><td>77.51</td></tr><tr><td>随机遮挡 50%</td><td>90×90</td><td>25.69</td><td>67.57</td></tr><tr><td>随机遮挡60%</td><td>99×99</td><td>15.53</td><td>51.40</td></tr><tr><td>眼部遮挡 (15%)</td><td>25×95</td><td>89.90</td><td>92.69</td></tr><tr><td>嘴部遮挡 (25%)</td><td>40×100</td><td>48.24</td><td>87.34</td></tr></table></body></html>",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "可以看出，对于无遮挡的人脸图像，卷积神经网络能够很好地提取特征并进行分类，但随着人脸遮挡面积的增加，表情识别准确率锐减。将遮挡人脸加入训练，实验发现将遮挡面积较小的人脸图像加入训练，相当于进行了数据增强，模型整体的识别准确率上升，但当将大面积遮挡的人脸图像也加入训练时，遮挡面积较小的人脸图像的表情识别准确率会有所下降，因此，本文仅使用了遮挡面积小于等于 $30 \\%$ 的人脸图像用于训练，最终遮挡人脸图像的测试准确率有所上升，但与无遮挡的表情识别准确率有较大差距，仍需进一步提高，尤其是遮挡面积大于 $30 \\%$ 的时候。",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "4.2本文方法实验结果分析",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "本文模型的填补效果如图3所示。遮挡类型从左到右分别是随机遮挡 $10 \\%$ ，随机遮挡 $20 \\%$ ，随机遮挡 $40 \\%$ ，眼部遮挡以及嘴部遮挡，第1列和第4列是中性表情，第2、3、5列依次是蔑视、惊讶和高兴的表情。其中第一行是遮挡前的原始图像，第二行是遮挡后的人脸图像，第三行是人脸填补修复后的结果。",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "判别，实验结果如图4所示。为了对比填补前后人脸表情识别效果，在填补前采用了4.1节中的方法2直接对遮挡人脸图像进行了表情识别。可以看出，人脸填补模型整体上提升了遮挡表情识别的准确率，当遮挡面积小于 $60 \\%$ 时，模型整体识别率还在 $80 \\%$ 以上，较方法2直接使用卷积神经网络提升了 $2 8 . 9 6 \\%$ ，而在遮挡面积较小的情况下，模型的识别准确率提升幅度较小。考虑模型的处理时间、系统资源等方面因素，在遮挡面积小于面部面积 $10 \\%$ 时，可不进行填补，直接使用卷积神经网络进行识别。",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "100 80 山 60 40 20 0 随机遮挡10% 随机遮挡20% 随机遮挡30% 随机遮挡40% 随机遮挡50% 随机遮挡60% 眼部遮挡 嘴部遮挡 ■填补前 ■填补后 ",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "由图3可以看出，经过人脸填补修复，整个人脸图像看上去真实连贯，未遮挡区域可能发生细微变化，但一般不会影响人脸图像的表情类别。",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "4.3 对比其他方法",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "本文选取了文献[24]的 $\\mathrm { P C A ^ { + } S V M }$ 方法、文献[6]的稀疏表示方法（sparse representation based classification,SRC)以及 CNN、DCGAN $^ { [ 1 3 ] } { + } \\mathrm { C N N }$ 方法来进行对比，其中CNN的方法即4.1中的方法2， $\\mathrm { D C G A N + C N N }$ 方法中DCGAN用于填补遮挡人脸图像，CNN同为微调的VGGface 模型，用于人脸表情分类。所有方法都在 $\\mathrm { C K ^ { + } }$ 数据集上进行了实验，结果如表2所示。可以看出，无论人脸图像是否存在遮挡，本文方法的表情识别准确率都较高，深度学习方法中DCGAN+CNN方法虽然也对人脸图像进行了填补，但得到的图像连贯性较差，影响了表情识别的准确率，尤其是遮挡面积小于 $40 \\%$ ，该方法的表情识别准确率甚至小于仅用CNN的准确率。而本文的方法避免了图像不连贯对表情识别的影响，在人脸遮挡面积 $60 \\%$ 时，仍能达到 $80 \\%$ 以上的识别准确率。",
        "page_idx": 4
    },
    {
        "type": "image",
        "img_path": "images/e21d0e73d10efc7cfbb9a83b1281af442293e3bf98bffe133baac729d751be0d.jpg",
        "img_caption": [
            "图4遮挡人脸表情识别的对比实验结果",
            "图3遮挡人脸填补结果"
        ],
        "img_footnote": [],
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "将填补后的人脸图像输入到表情分类网络中，对表情进行",
        "page_idx": 4
    },
    {
        "type": "table",
        "img_path": "images/fdb0e2113c61213d0de158d7333fa17ff2f073d2351ee4fe775d5d10a64e5fed.jpg",
        "table_caption": [
            "表2与其他方法对比实验结果"
        ],
        "table_footnote": [],
        "table_body": "<html><body><table><tr><td rowspan=\"2\">方法</td><td rowspan=\"2\">无遮挡</td><td colspan=\"6\">随机遮挡 随机遮挡 随机遮挡 随机遮挡随机遮挡 随机遮挡</td></tr><tr><td>10%</td><td>20%</td><td>30%</td><td>40%</td><td>50%</td><td>60%</td></tr><tr><td>PCA+SVM</td><td>91.23</td><td>89.32</td><td>85.93</td><td>84.13</td><td>79.23</td><td>68.87</td><td>54.97</td></tr><tr><td>SRC</td><td>92.79</td><td>90.23</td><td>88.69</td><td>85.97</td><td>80.00</td><td>70.23</td><td>55.78</td></tr><tr><td>CNN</td><td>97.57</td><td>94.98</td><td>92.75</td><td>89.69</td><td>77.51</td><td>67.57</td><td>51.40</td></tr><tr><td>DCGAN+CNN</td><td>97.57</td><td>89.30</td><td>86.33</td><td>83.93</td><td>78.94</td><td>70.91</td><td>61.92</td></tr><tr><td>本文模型</td><td>97.57</td><td>96.45</td><td>95.11</td><td>93.34</td><td>92.02</td><td>85.89</td><td>80.34</td></tr></table></body></html>",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "5 结束语",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "实际应用中局部遮挡问题导致表情识别的准确率不够理想，与在标准人脸表情数据集上取得的高识别率差距明显。本文提出了一种基于GAN的遮挡表情识别模型，对人脸图像中遮挡缺失的部分先进行填补修复，再基于卷积神经网络进行表情识别。将遮挡人脸图像作为输入条件，由卷积自动编码机构成的生成器输出一张完整的人脸图像，在与鉴别器的相互对抗中，生成的人脸图像更加逼真自然。将鉴别器和分类器的特征提取部分整合在一起，利用常规的人脸图像数据集celebA对其权重参数进行预训练，最后在 $\\mathrm { C K ^ { + } }$ 数据集上进行微调得到了很好的分类结果。经实验，本文方法填补的人脸图像直观上真实连贯，填补后的表情识别率较其他方法更高。模型尤其提高了大面积遮挡人脸图像的表情识别准确率。",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "参考文献：   \n[1] Mehrabian Albert，Russell James A.An approach to environmental psychology [M]. Cambridge: MIT Press,1980: 222-253.   \n[2]孙晓，潘汀，任福继．基于ROI-KNN 卷积神经网络的面部表情识别[J]. 自动化学报,2016,42(6):883-891.(Sun Xiao,Pan Ting,RenFuji.Facial expression recognition using ROI-KNN deep convolutional neural networks [J].Acta Automatica Sinica,2016,42 (6): 883-891.)   \n[3]李江，冉君军，张克非．一种基于降噪自编码器的人脸表情识别方法 [J].计算机应用研究,2016,33(12):3843-3846.(Li Jiang,Ran Junjun, Zhang Kefei. Method of facial expression recognition based on denoising autoencoders[J].Application Research of Computers,2016,33 (12): 3843- 3846.)   \n[4]Lopes A T,De Aguiar E, Oliveira-Santos T.A facial expression recognition system using convolutional networks [C]// Proc of the 28th SIBGRAPI Conference on Graphics,Paterns and Images.2015: 273-280.   \n[5]贵睨烨，杨明强，张鹏，等．微表情自动识别综述[J].计算机辅助设 计与图形学学报,2014,26(9):1385-1395.(Ben Xian ye,Yang Mingqiang, Zhang Peng,et al. Survey on automatic micro expression recognition methods [J]. Journal of Computer-Aided Design & Computer Graphics, 2014,26 (9): 1385-1395. )   \n[6]朱明旱，李树涛，叶华．基于稀疏表示的遮挡人脸表情识别方法[J]. 模式识别与人工智能,2014,27(8):708-712.(Zhu Minghan,LiShutao,Ye Hua.An occluded facial expression recognition method based on sparse representation [J].PR&AI,2014,27 (8): 708-712.)   \n[7]Cotter S F.Recognition of occluded facial expressions using a fusion of localized sparse representation classifiers [C]// Proc of Digital Signal Processing Workshop and IEEE Signal Processing Education Workshop. 2011: 437-442.   \n[8]薛雨丽，毛峡，Catalin-DanielC，等．遮挡条件下的鲁棒表情识别方法 [J].北京航空航天大学学报,2010,36(4):429-433.(Xue Yuli,Mao xia, Catalin-Daniel C，et al.Robust facial expression recognition under occlusion condition. Journal of Beijing University of Aeronautics and Astronautics,2010,36 (4): 429-433.)   \n[9]王军，夏利民．基于深度学习的痛苦表情识别[J].计算机工程与设计, 2016,37(6):1617-1620.(Wang Jun, Xia Limin.Pain expression recognition based on deep learning[J].Computer Engineering and Design,2016,37 (6): 1617-1620. )   \n[10]王剑示李小雷一种其干深度学习的表悟识别方法「 计算却与现 ",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "代化,2015(1):84-87.(Wang Jianyun,Li Xiaoxia.A facial expression recognition method based on deep learning [J].Computerand Modernization,2015 (1): 84-87.) ",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "[11] Goodfellow l,Pouget-Abadie J,Mirza M,et al. Generativeadversarialnets [C]//Proc of Intermational Conference on Neural InformationProcessing Systems.Cambridge:MIT Press,2014:2672-2680.   \n[12] Radford A,Metz L,Chintala S. Unsupervised representation learning with deep convolutional generative adversarial networks [EB/OL]. (2016-01-07) . https://arxiv.org/abs/1511. 06434.   \n[13] Yeh R,Chen Chen,Lim T Y,et al.Semantic Image Inpainting with Perceptual and Contextual Losses [Cl// Proc of IEEE Conference on Computer Vision and Pattern Recognition. 2017: 6882-6890.   \n[14] Li Yijun,Liu Sifei,Yang Jimei,etal. Generative facecompletion [C]//Proc of IEEE Conference on Computer Vision and Pattern Recognition. 2017: 5892-5900.   \n[15] Salimans T,Goodfellow I, Zaremba W,et al.Improved techniques for training GANs [C]// Proc of Neural Information Processing Systems Conference. 2016.   \n[16] Denton E,Gross S,Fergus R.Semi-supervised learning with context conditional generative adversarial networks [EB/OL]. (2016-11-19）. https://arxiv. org/abs/1611. 06430.   \n[17] Simonyan K,Zisserman A. Very deep convolutional networks for large-scale image recognition [EB/OL].(2015-04-10).htps://arxiv.org/abs/1409.1556   \n[18] Lucey P, Cohn JF, Kanade T,et al. The extended Cohn-Kanade dataset （204 $( \\mathrm { C k ^ { + } } ,$ : a complete dataset for action unit and emotion-specified expression [C]//Proc of IEEE Computer Society Conference on Computer Vision and Pattern Recognition. Washington DC: IEEE Computer Society, 2010: 94- 101.   \n[19] Yang Shuo,Luo Ping,Loy C C,etal.From facial parts responses to face detection: a deep learning approach [C]// Proc of IEEE International Conference on Computer Vision.2015: 3676-3684.   \n[20] Baltrusaitis T,Robinson P, Morency L P. Openface: an open source facial behavior analysis toolkit [C]//Proc of IEEE Winter Conference on Applications of Computer Vision. Piscataway,NJ: IEEE Press,2016: 2016: 1-10.   \n[21] Kazemi V, Sullivan J. One milisecond face alignment with an ensemble of regression trees [C]// Proc of IEEE Conference on Computer Vision and Pattern Recognition. Washington DC: IEEE Computer Society,2014: 1867- 1874.   \n[22] Towner H, Slater M.Reconstruction and Recognition of occluded facial expressionsusing PCA [M]// Affective Computing and Intelligent Interaction. Berlin: Springer,2007: 36-47.   \n[23] Huang GB,MattarM,Berg T,et al.Labeled faces in the wild: a database for studying face recognition in unconstrained environments [R]. University of Massachusetts Amherst Technical Report, 2008: 07-49.   \n[24]罗元，吴彩明，张毅．基于PCA与 SVM结合的面部表情识别的智能轮 ",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "椅控制[J].计算机应用研究,2012,29(8):3166-3168.(Luo Yuan,Wu Caiming，Zhang Yi.Facial expression recognition based on principal component analysis and support vector machine applied in intelligent wheelchair [J].Application Research of Computers,2012,29(8):3166- 3168.) ",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 6
    }
]