[
    {
        "type": "text",
        "text": "算法歧视比人类歧视引起更少道德惩罚欲 ",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "许丽颖」 喻丰 2\\*彭凯平1(1清华大学社科学院心理学系，北京100084)(²武汉大学哲学学院心理学系，武汉 430072)",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "摘 要算法歧视屡见不鲜，人们对其有何反应值得关注。六个递进实验比较了不同类型歧视情境下人们对算法歧视和人类歧视的道德惩罚欲，并探讨其潜在机制和边界条件。结果发现：相对于人类歧视，人们对算法歧视的道德惩罚欲更少（实验1\\~6），潜在机制是人们认为算法（与人类相比）更缺乏自由意志（实验2\\~4），且个体拟人化倾向越强或者算法越拟人化，人们对算法的道德惩罚欲越强（实验5\\~6）。研究结果有助于更好地理解人们对算法歧视的反应，并为算法犯错后的道德惩罚提供启示。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "关键词算法，算法歧视，道德惩罚，自由意志信念，拟人化",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "1前言",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "歧视普遍存在，性别、学历、种族、年龄之歧视常引发社会热议。面对歧视者，大众倾向于道德谴责，并希望其得到惩罚。在传统歧视事件中，做出歧视的主体是人类。然而，随着人工智能的发展和应用，算法也成为了新的歧视主体。算法因其远超人类的计算能力和较低的成本而备受青睐，并且已经逐步进入人类生活的各重要领域代替人类做出关键决策，例如在医疗领域决定谁能够先得到器官捐赠（Freedman et al.,2020）、在金融领域决定投资者应该投资哪支基金（Harvey etal.,2017)，甚至在司法领域决定罪犯的风险等级并做出量刑(Hao,2019)。不仅如此，算法也因其能在一定程度上避免人类的主观性而被认为比人类决策者更准确公正（Grove etal.,2000)。然而，算法虽然看似比人类更理性、更中立，但算法决策也可能因训练数据集等问题而导致歧视（Borgesius,2018）。如 Northpointe 公司所开发的对罪犯进行重复犯罪风险评估的COMPAS 算法被发现存在种族歧视，它会增加黑人被标记为累犯的可能性（Angwin et al.,2016)。谷歌的定向广告投放中也存在算法性别歧视，与将用户的性别设置为男性相比，将用户的性别设置为女性会导致高薪工作相关广告出现的次数更少（Datta etal.,2015)，类似的性别歧视也发生在科学、技术、工程和数学（STEM）领域的招聘广告投放算法中（Lambrecht& Tucker,2019)。人们原本以为算法能够有助于减少乃至消除偏见，但实际上相关的算法歧视案例不胜枚举，在教育（Ferrero&Barujel,2019）、医疗（Obermeyer etal.,2019）、消费（Angwin et al.,2015）等与人们生活息息相关的重要领域都有涉及。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "面对人类歧视，人们迫切地希望其受到道德惩罚，那面对新型算法歧视，人们是希望其受到同样惩罚吗？为了回答这一问题，本研究试图考察人们对人类歧视和算法歧视在道德惩罚欲上是否存在差异，并且在此基础上进一步探讨造成其差异的潜在原因和边界条件。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "1.1人类歧视与算法歧视 ",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "歧视是指针对特定类别群体或其成员的无理负面行为（AlRamiah etal.,2010)，这种行为不是由于群体及其成员应得或出于互惠，而仅是由于其属于特定类别(Correlletal.,2010)。与之类似，算法歧视也与类别相关。当算法产生与受法律保护的类别变量（如种族和性别)相关的系统性差异时，就被认为具有歧视行为（Bonezzi&Ostinelli,2021)，比如亚马逊的招聘算法对女性简历评分更低（Dastin,2018)。面对歧视这种有违公平、造成伤害的不道德行为(Haidt＆ Graham,2007)，人们会产生道德反应，即情感上的道德义愤（moraloutrage; Batsonet al.,2007）及行为倾向上的道德惩罚欲（desire for moral punishment; Hofmann et al.,2018）。道德惩罚是对不道德行为的制裁，能够在一定程度上矫正已有的不道德行为并阻止未来的不道德行为，因此在维持和加强道德体系上具有重要作用（Hofmann etal.,2018)。看到职场女性受上司歧视，看到新冠疫情初期武汉人受到外地人歧视，看到老年人在商店由于不会手机支付而受到店员歧视，我们会愤怒，意欲惩罚施加歧视者。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "如果这些歧视行为的主体不是人类，而是算法呢？相对于人类歧视，人们对算法歧视会产生较少的道德义愤，这是由于人们会将较少的负面动机归因于算法（Bigman etal.,2020)。实际上，如果从人类歧视和算法歧视所造成的后果来看，算法歧视比人类歧视所造成的后果可能更为严重（Bigman etal.,2020)。以亚马逊公司的招聘为例，可能有一定比例的人事经理会外显或内隐地歧视女性应聘者，但个人影响毕竟有限；若算法一旦应用，则歧视所影响的应聘者可能成倍增长。因此如果单从后果上来看，相对于人类歧视，人们似乎可能会更想惩罚算法歧视。但本文试图从更本质的视角，即人们对算法本身的知觉来探讨对算法歧视的反应。换句话说，在歧视后果对等的情况下，由于人们对算法和人类心智知觉的差异，即认为算法相对于人类具有更少的自由意志，因此人们对算法歧视的道德惩罚欲小于对人类歧视的道德惩罚欲。据此，本文提出假设1：相较于人类歧视，人们对算法歧视的道德惩罚欲更小。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "1.2自由意志信念与道德惩罚",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "面对不道德行为，究竟是什么决定了我们是否想要对行为者进行道德惩罚？当然，自由意志（free will）是行为者对自身行为承担道德责任的必要条件（Nichols&Knobe,2007）。简单来说，自由意志就是自由行动的能力，而自由行动意味着一个人可以在相同的情况下做出不同的选择和行为（Baumeister,2014)。当一个人由于没有别的选择而只能做出不道德行为时，对其进行谴责和惩罚显然是不合理的（Shariffetal.,2014)，因此道德惩罚会相应减少(Clark et al.,2014)；而如果人们要遣责和惩罚做出不道德行为的人，则需要其至少有一定程度的自由意志。这也是为什么当违规者试图降低自身的负罪感并逃脱惩罚时，常见的策略就是将其行为描述为无能为力且无法避免的选择（Baumeisteretal.,1990)。心理学家不甚关心自由意志是否真实存在，反而更关心人们是否相信自由意志存在，即自由意志信念（beliefin free will）（Baumeister,2008)。自由意志信念薄弱会造成负面后果，例如减少助人行为且攻击性增强（Baumeister etal.,2009）、增加欺骗行为（Vohs＆ Schooler,2008）以及降低自控力（Rigoni et al.,2012）等。更重要的是，削弱人们的自由意志信念或者提供关于违规者缺乏自由行动能力的相关证据，会影响人们对道德责任信念的推脱，进而导致人们做出更多不道德的行为（Shariff etal.,2014)，也会导致人们对违规者道德惩罚的减少（e.g.,Aspinwall etal., 2012)。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "实际上，大多数人都相信人类有自由意志（Nahmias etal.,2005)，因此当歧视的行为者是人类时，人们更有可能认为歧视行为是出于其自由意志的结果，从而产生较强的道德惩罚欲。那算法呢？虽然现阶段的算法缺乏完全的自由意志和自主性，但与“客观\"自主性（即人工智能是否有自主性）相比，“主观\"自主性（即人们是否认为人工智能具有自主性）对于其道德责任的影响似乎更加重要（Wegner&Gray,2017)。因此，歧视作为一种不道德行为会引发道德惩罚欲，而道德惩罚欲的大小则受到人们认为歧视者在多大程度上拥有自由意志的影响。现有研究表明，人们对人类和算法等人工智能的心智知觉（mind perception）不同。与人类相比，人工智能具有中等程度的能动性（agency；即自主计划行动等心理能力)，并且具有较低程度的体验性（experience；即能够体验情绪等心理能力）（Bigman& Gray,2018;",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "Gray etal.,2007)。也就是说，算法虽然具有一定程度的自主行为能力，但并不会被视为与人类具有同等程度的自由意志（Weisman et al.,2017; Shariff etal.,2014)。总之，与人类相比，人们认为算法具有较少的自由意志。基于上文所述，本文认为人们对算法歧视比对人类歧视有更少的道德惩罚欲，这是由于认为算法比人类具有更少的自由意志。据此，本文的假设 2为：自由意志信念在歧视主体（人类vs.算法）对道德惩罚欲的影响中起中介作用。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "当然，需要说明的是，本文所提出的自由意志信念并非人们对不同歧视主体（人类 vs.算法）产生不同道德惩罚欲的唯一解释机制。例如，算法没有人一样的不良动机（Bigman etal.,2020）、算法本身应承担的责任较小（多数责任可归于编制算法者）、算法受惩罚并不能促使其进步等，这些都能够在一定程度上作为解释机制。但本文之所以重点关注自由意志，主要是由于上述可能的解释机制均与自由意志密切相关。第一，具有自由意志的个体作出不道德行为可能说明其具有不道德的动机（该个体是“坏”的)，即判断个体具有自由意志可能是我们推测其动机的必要条件（e.g.,Laming,2004)。第二，具有自由意志的个体能够自主选择，也应当自主承担责任，即自由意志是个体承担责任的必要条件（e.g.,Sinnott-Armstrong,2014)。第三，具有自由意志的个体可能能够理解惩罚并反思，对其不道德行为进行惩罚更可能促使其产生积极变化，因此或许个体在一定程度上具有自由意志亦是惩罚能够对个体产生积极促进作用的必要条件。于是，我们认为自由意志与动机、责任和惩罚效果等因素密切相关，并且自由意志信念的解释机制在某种意义上可能更为基础，能够在一定程度上涵盖以上所述的其它解释机制。因此，本文对不同歧视主体（人类vs.算法）如何影响道德惩罚欲的机制探讨将着重检验自由意志信念的作用。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "此外，可能还存在与自由意志无关的竞争假设。首先，人的行为更容易被解释，而算法复杂和不透明。被试因为算法的内在逻辑难以甄别，也就更难判定歧视行为是不道德的，甚至可能认为其具有合理性，进而对其表现出宽容。其次，人无法真正惩罚算法，即惩罚算法是不切实际的，但人可以惩罚人类。换言之，所谓惩罚算法是惩罚算法的载体，并非惩罚算法本身。鉴于很难真正惩罚算法，因此当算法出现歧视后，人不怎么愿意惩罚它。鉴于以上与自由意志无关的竞争假设存在，我们将会通过4个调节效应研究（研究3\\~6）将之进行排除。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "1.3拟人化",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "自由意志通常情况下被当作人的特征（Waytzetal.,2010)，讨论算法是否具有自由意志即是在将算法拟人化。拟人化（anthropomorphism）是指\"将人类特征、动机、意向或心理状态赋予非人对象”（Epley etal.,2007)。人工智能尤其是算法对于人们来说相对抽象，在很多情况下设计者会以拟人化的方式将其呈现，人们也倾向于以拟人化的方式对其进行知觉。人工智能的拟人化能够在一定程度上增进信任（Waytz etal.,2014)，但过度拟人化也可能会诱发恐怖谷（uncanny valley）效应（Mori,1970），使积极态度急转直下。人们会根据人工智能的外表来推断其心智，人工智能越像人，人们就越倾向于认为其有类人的心智（Bigman et al,2019)。当然，拟人化人工智能的方式本身也包括赋予其人类的心理状态如自由意志等，使人工智能的行为看起来是自由选择的结果。不过，人们的拟人化倾向也是存在个体差异的（Waytz etal.,2010)，面对同样一个人工智能，有的人会更倾向于将其拟人化，而有的人则不会。拟人化倾向的个体差异影响广泛（Epley&Waytz,2010)，越多将算法拟人化，则越可能认为算法具有某种程度的自由意志或者自主性，并让人们可以对其进行道德归责（Grayetal., 2007)。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "总之，人们越倾向于拟人化人工智能，就会认为其拥有更多的自由意志，从而需要为其行为承担更多的道德责任乃至惩罚（Bigman etal.,2019;Waytz et al.,2014)。因此，拟人化倾向的个体差异以及算法本身的拟人化程度都会影响到人们是否更加以拟人的方式看待算法，同时也影响到人们对于道德违规算法的道德惩罚欲。据此，本文提出假设3：拟人化在歧视主体（人类vs.算法）对道德惩罚欲的影响中起调节作用。具体而言，在个体的拟人化倾向方面，对于拟人化倾向较低的人而言，他们对人类歧视的道德惩罚欲大于对算法歧视的道德惩罚欲，对于拟人化倾向较高的人来说，由于将算法更多当作人来看待，因而对人类歧视和算法歧视的惩罚欲没有显著差异；而在算法本身的拟人化方面，算法的拟人化程度越高，人们对算法歧视与对人类歧视的道德惩罚欲差异越小。",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "1.4研究概览",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "综上所述，本研究旨在考察人们对人类歧视和算法歧视的道德惩罚欲是否存在差异，并在此基础上进一步探讨其心理机制和边界条件。本研究的基本假设是：人们对算法歧视的道德惩罚欲小于对人类歧视的道德惩罚欲，这一效应受到自由意志信念的中介和拟人化的调节。本研究采用递进的6个实验来验证假设。6个实验均采用情境实验的方式，为被试呈现人类或算法的歧视行为并测量其道德惩罚欲，涉及到的歧视包括性别歧视（实验1和实验6)、学历歧视（实验2）、民族歧视（实验3和实验4）和年龄歧视（实验5)，并涵盖了具有代表性的全国范围被试和大学生被试。具体而言：实验1验证人们对算法歧视的道德惩罚欲是否小于对人类歧视的道德惩罚欲；实验2探究其中的心理机制，验证自由意志信念在歧视主体（人类vs.算法）影响道德惩罚欲中的中介作用；实验3通过操纵被试的自由意志信念，进一步检验自由意志信念是否是导致人们产生不同道德惩罚欲的机制；实验4则通过具体操纵人们对算法的自由意志信念，再一次检验自由意志信念是否是导致人们对不同歧视主体（人类vs.算法）有不同道德惩罚欲的机制；实验5探索可能的边界条件，验证拟人化倾向在歧视主体影响道德惩罚欲中的调节效应；实验6则直接对算法的拟人化程度进行操纵，进一步验证拟人化在歧视主体影响道德惩罚欲中的调节效应。",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "2 实验1：算法歧视引发更少道德惩罚欲",
        "text_level": 1,
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "实验1的目的是初步探讨与人类歧视相比，算法歧视是否会引发人们更少的道德惩罚欲。我们采用网络情境实验的方法，将被试随机分配至人类组和算法组，分别阅读人类歧视和算法歧视的情境材料并报告道德惩罚欲，以此比较人们对人类歧视和算法歧视的道德惩罚欲差异。",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "2.1 方法",
        "text_level": 1,
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "2.1.1 被试",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "本研究首先使用G\\*Power 3.1软件（Faul etal.,2007）计算研究所需样本量。以独立样本 $t$ 检验为统计方式，显著性水平 $\\mathtt { a } = 0 . 0 5$ 且中等效应量（ $\\stackrel { \\cdot } { d } = 0 . 5$ ）时，为了达到 $90 \\%$ 统计检验力，本实验至少需要172名被试。通过在Credamo 平台发布实验，实时剔除没有通过注意检查的被试数据并滚动采集，最终得到172份有效数据，包括男性76名（ $4 4 . 2 \\% )$ ，女性96名（ $5 5 . 8 \\%$ )，平均年龄 $M = 2 8 . 3 3$ 岁， $S D = 4 . 2 6$ 岁。参与实验的被试被随机分派到人类组和算法组，其中人类组85人，算法组87人。所有被试均自愿参加实验且知情同意，通过注意检查的被试在实验结束之后获得相应实验报酬。",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "2.1.2 实验设计与程序",
        "text_level": 1,
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "实验1为单因素两水平被试间实验设计，两组分别为人类组和算法组，所有被试被随机分配到其中一组。首先，所有被试均阅读性别歧视的情境材料（下划线内容为人类组材料，括号中为算法组材料)：“李亮和何萍夫妻二人都申请了同一银行的信用卡，夫妻双方都对自己的财产拥有平等的所有权，并且收入相同。银行审理人（算法）对二人的申请进行评估，最终给予李亮五万元的额度，而何萍却只有三万元额度”，情境材料改编自Bigman 等人（2020）的研究。为了确保被试认真阅读并理解了情境材料的内容，被试在阅读完情境材料后被要求回答注意检查题目（例如\"对李亮和何萍进行信用卡额度评估的是？\"1 $\\mathbf { \\Sigma } = \\mathbf { \\Sigma }$ 银行审理人， $2 =$ 算法)，如未正确回答该题目，该被试将在Credamo 数据平台上被拒绝，平台将递补搜集其他被试以满足样本量需求。",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "在阅读完情境材料并进行注意检查后，被试填写了道德惩罚欲问卷。我们采用Hofmann等人（2018）对道德惩罚欲的测量，请被试回答以下3个题目（括号中为算法组题目)：“你认为这个银行审理人（算法）应该为这种行为受到多大程度的道德惩罚？”、“你在多大程度上想要去惩罚这个银行审理人（算法）？”、“你在多大程度上认为应该要求这个银行审理人（算法）恢复因其不道德行为所造成的损害？\"3个题目均采用李克特7点量表计分（从“1 $\\mathbf { \\Sigma } = \\mathbf { \\Sigma }$ 一点也不\"到“7 $\\mathbf { \\Sigma } = \\mathbf { \\Sigma }$ 非常\")，得分越高表明被试对情境中的人类(或算法)的道德惩罚欲越强。实验1中该测量的内部一致性信度Cronbach $\\alpha = 0 . 8 7$ 。",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "考虑到不同被试对算法的看法和知识可能存在差异，从而影响到其对算法歧视的道德惩罚欲，因此为了排除相关可能的影响因素，被试还被要求报告他们对算法的熟悉程度（“你对算法有多熟悉？”，从“1 $\\mathbf { \\Sigma } = \\mathbf { \\Sigma }$ 一点也不熟悉\"到“5 $\\mathbf { \\Sigma } =$ 非常熟悉\")、了解程度（“与普通中国人相比，你认为你对算法有多了解？”，从“1 $\\mathbf { \\Psi } = \\mathbf { \\Psi }$ 一点也不了解\"到\"5 $\\mathbf { \\Sigma } = \\mathbf { \\Sigma }$ 非常了解”）和喜爱程度（“你有多喜欢算法？”，从“1 $\\mathbf { \\Sigma } = \\mathbf { \\Sigma }$ 一点也不喜欢\"到“5 $\\mathbf { \\Sigma } = \\mathbf { \\Sigma }$ 非常喜欢\")。其中熟悉程度和了解程度的题项改编自Leo 和Huh（2020）的研究，喜爱程度的题项改编自Godspeed 量表中的条目（Bartneck etal.,2009)。最后，被试报告了性别和年龄两项人口统计学信息。",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "2.2结果",
        "text_level": 1,
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "独立样本 $t$ 检验结果显示，人类组的道德惩罚欲评分（ $\\scriptstyle { M = 5 . 2 9 }$ $S D = 0 . 9 9$ ）高于算法组（ $M = 4 . 9 7$ ， $S D = 1 . 3 4 \\rangle$ ，差异呈边缘显著， $t ( 1 7 0 ) = 1 . 8 2$ ， $p { = } 0 . 0 7 3$ ，Cohen's $d = 0 . 2 7$ 。为了验证结果的稳健性，将被试的性别（男 $\\mathbf { \\tau } = 1$ ，女 $= 2$ ）和年龄作为协变量进行控制，方差分析结果显示，人类组的道德惩罚欲评分仍然高于算法组，差异呈边缘显著， $F ( 1 , 1 6 8 ) = 3 . 2 2$ $p = 0 . 0 7 5$ ， $\\eta _ { \\mathrm { p } } ^ { 2 } \\ = 0 . 0 1 9$ 。为了进一步排除年龄和性别可能对结果的影响，我们分别对其进行了相关分析和独立样本 $t$ 检验，结果发现年龄与道德惩罚欲评分相关不显著（ $\\rvert _ { r } = 0 . 0 1$ ， $p =$ 0.853)，男性和女性的道德惩罚欲无显著差异， $t ( 1 7 0 ) = 0 . 8 3$ ， $ { p } = 0 . 4 0 8$ 。",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "为了排除被试对算法的熟悉程度、了解程度和喜爱程度可能对结果的影响，我们将算法组的道德惩罚欲评分与这些变量进行相关分析，结果表明相关均不显著， $r _ { \\ast \\ast } = - 0 . 1 3$ ， $r$ 了解$= - 0 . 1 0 , r _ { \\scriptscriptstyle \\frac { \\mathrm { e } } { \\mathrm { e } } \\scriptscriptstyle \\frac { \\mathrm { e } } { \\mathrm { e } } } = - 0 . 1 5 , p \\mathrm { s } > 0 . 0 5 \\mathrm { , }$ （",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "2.3讨论",
        "text_level": 1,
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "实验1初步验证了算法歧视相比于人类歧视会引发人们更少的道德惩罚欲，并且排除了被试对算法的熟悉程度、了解程度和喜爱程度的可能影响。但实验1只涉及到一种歧视类型即性别歧视，并且未探索其中深层的心理机制。鉴于此，实验2的情境设置于算法歧视常见的招聘领域，重点考察其中可能存在的学历歧视现象，拟在进一步检验实验1结果稳健性的基础上试图发现自由意志信念的中介作用。",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "3实验2自由意志信念的中介作用",
        "text_level": 1,
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "实验2在实验1的基础上丰富了歧视的类型，加入了对学历歧视的考察，并且进一步探讨现象背后的深层机制，验证自由意志信念可能在其中扮演的中介作用。",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "3.1方法",
        "text_level": 1,
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "3.1.1 被试",
        "text_level": 1,
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "对于本实验适用的独立样本 $t$ 检验，取中等效应量 $d = 0 . 5$ ，显著性水平 $\\mathtt { a } = 0 . 0 5$ ，通过G\\*Power3.1软件（Faul etal.,2007）计算本实验所需样本量结果表明，172名被试才能达到$90 \\%$ 统计检验力。通过Credamo 平台招募被试，实时剔除没有通过注意检查的被试数据并滚动采集，最终得到172份有效数据。这172名被试的平均年龄为 $2 8 . 1 4 \\pm 6 . 2 1$ 岁，其中女性104名，占比为 $60 . 5 \\%$ ，男性68名，占比为 $3 9 . 5 \\%$ 。被试被随机分派到人类组（86人）和算法组（86人)。所有被试在实验开始之前均仔细阅读了实验说明并知情同意，有效数据被试在实验结束后获得实验报酬。",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "3.1.2 实验设计与程序",
        "text_level": 1,
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "同实验1，实验2也为单因素两水平被试间实验设计。被试首先阅读学历歧视的情境材料（下划线内容为人类组材料，括号中为算法组材料)：“在去年的秋季招聘中，韦蓝公司的人力资源经理李原负责（使用算法）进行招聘。招聘结束后，公司发现李原（算法）对应聘者的简历进行筛选时存在学历偏差，筛掉了所有硕士研究生以下学历的应聘者，而公司的大部分岗位对学历并无硬性要求。这阻碍了许多有才华、有能力、但不具有研究生学历的人获得该公司的工作”，情境材料改编自Bigman等人（2020）的研究。",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "在阅读完情境材料并进行注意检查后，两组被试分别报告了对人类歧视或算法歧视的道德惩罚欲，测量条目同实验1（Hofmann etal.,2018)。在实验2中，道德惩罚欲3个项目的内部一致性信度Cronbach $\\mathtt { a } = 0 . 8 7$ 。然后，我们测量了被试对于情境中做出学历歧视行为的人类或算法的自由意志信念。采用改编后的自由意志量表（free will inventory;Nadelhoffer etal.,2014)，共5个条目（ $\\mathrm { \\bf q } = 0 . 8 6 )$ ，例如\"李原（算法）是有自由意志的”，均为李克特7点计分（ $1 =$ 强烈反对， $7 =$ 强烈同意)，得分越高表明被试认为情境中的人类（或算法）有更多自由意志。最后，被试报告了性别、年龄和受教育程度三项人口统计学信息。",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "3.2结果",
        "text_level": 1,
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "3.2.1歧视行为主体对道德惩罚欲的影响",
        "text_level": 1,
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "独立样本 $\\mathbf { \\chi } _ { t }$ 检验结果显示，人类组的道德惩罚欲评分（ $\\cdot M { = } 5 . 1 1$ ， $S D = 1 . 1 4$ ）显著高于算法组（ $\\displaystyle M = 4 . 6 0$ ， $S D = 1 . 5 4 { \\dot { , } }$ ， $t ( 1 7 0 ) = 2 . 4 4$ ， $p = 0 . 0 1 6$ ，Cohen's $d = 0 . 3 8$ 。",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "为了进一步验证结果的稳健性，将被试的性别（男 $^ { \\circ } = 1$ ，女 $= 2$ )、年龄和教育程度（小学及以下 $\\dot { \\bf \\Phi } = 1 \\$ ，初中 $= 2$ ，普高/中专/技校/职高 $= 3$ ，专科 $\\ O = 4$ ，本科 $= 5$ ，硕士研究生 $= 6$ ，博士研究生 $^ { } = 7$ ）作为控制变量，方差分析结果显示，人类组的道德惩罚欲评分仍然显著高于算法组， $F ( 1 , 1 6 7 ) = 5 . 9 6 \\$ ， $p = 0 . 0 1 6$ ， ${ \\mathfrak { n } } _ { \\mathfrak { p } } ^ { 2 } ~ = 0 . 0 3$ 。",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "3.2.2自由意志信念的中介效应",
        "text_level": 1,
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "为了探索歧视主体对道德惩罚欲影响的心理机制，我们使用Hayes（2013）提供的 SPSS插件 PROCESS（Model4)，以歧视主体为自变量（人类组 $\\mathbf { \\varepsilon } = 0$ ，算法组 $\\mathbf { \\Psi } = 1$ )，自由意志信念为中介变量，道德惩罚欲为因变量，设定Bootstrap 样本量为 5000，采用偏差校正的方法，选取 $9 5 \\%$ 置信区间进行中介效应检验。数据结果显示，自由意志信念的中介效应值为-0.56，$9 5 \\%$ 的 Bootstrap 置信区间为[-0.95,-0.21]，不包含0，表明中介作用显著；并且在控制中介变量后，歧视主体对道德惩罚欲的直接效应为 $0 . 0 6 , 9 5 \\%$ 的Bootstrap 置信区间为[-0.44,0.55],包含0，表明其直接效应不再显著，自由意志信念在歧视主体对道德惩罚欲的影响中起完全中介作用。为了进一步验证中介效应的稳健性，我们又使用传统逐步回归方法进行了中介效",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "应分析（温忠麟 等,2004)，结果见图1。",
        "page_idx": 9
    },
    {
        "type": "image",
        "img_path": "images/e3eacff300ecf103c51e0c745c8edb9eb73c4d355c0c801fd2d9f2b8a60fcfe9.jpg",
        "img_caption": [
            "图1自由意志信念的中介作用"
        ],
        "img_footnote": [],
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "3.3讨论",
        "text_level": 1,
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "与实验1结果相一致，实验2再次验证了算法歧视相比于人类歧视会引发人们更少的道德惩罚欲，并且进一步发现了自由意志信念在其中的中介作用，即人们认为算法相比人类有更少的自由意志，因此不倾向于对其进行道德惩罚。因此，实验1和实验2对于本文的主要假设，即算法歧视比人类歧视引发更少道德惩罚欲，提供了稳定一致的支持，并且对自由意志信念的中介效应进行了初步验证。为进一步检验实验1和实验2结果的稳健性，实验3将实验情境材料设置为民族歧视情境。此外，为了进一步验证其中的心理机制，即自由意志信念是造成不同道德惩罚欲的原因，拟在实验3中操纵被试的自由意志信念。我们预测，若启动被试“不存在自由意志\"的信念，那么歧视主体对道德惩罚欲的影响将会消失。",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "4实验3操纵自由意志信念",
        "text_level": 1,
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "为了增加实验结果的稳健性，实验3再次丰富了歧视类型，关注民族歧视问题，并且通过对被试自由意志信念的操纵，进一步探讨自由意志信念是否是造成道德惩罚欲差异的机制。",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "4.1 方法",
        "text_level": 1,
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "4.1.1 被试",
        "text_level": 1,
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "采用G\\*Power 3.1软件（Faul etal.,2007）计算本实验所需样本量，对于本实验适用的双因素方差分析，取中等效应量 $f { = } 0 . 2 5$ ，显著性水平 $\\mathtt { a } = 0 . 0 5$ ，组数为4，要达到 $8 5 \\%$ 的统计检验力至少需要 201名被试。考虑到可能会出现少量不认真填答或未通过注意检查的无效数据，我们共招募了231名来自某高校的本科生参加实验，完成实验可获得相应学分。实验通过Qualtrics平台开展，被试在实验开始前均详细阅读了实验说明并知情同意，有 26 名被试的回答不符合要求或未通过注意检查，最终得到205份有效数据。这些有效被试的平均年龄为19.18岁（ $S D = 0 . 8 1 \\$ ，女性77名（占 $3 7 . 6 \\%$ ）°",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "4.1.2实验设计与程序",
        "text_level": 1,
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "实验3为2（歧视行为主体：人类vs.算法） $\\times 2$ （自由意志信念：高vs.低）被试间实验设计，所有被试被随机分配到四个组的其中一组。",
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "首先，被试阅读自由意志信念的操纵短文。在低自由意志信念组，被试阅读到一篇如下题为\"科学表明自由意志并不存在\"的短文，为了增加短文的真实性和可信性，我们标注了短文作者是一位名为\"克里斯·惠灵顿\"的博士。短文主要阐述了科学表明人们的所作所为都是他们大脑中简单物理过程的产物，自由意志只是一种幻觉（详见附录)。在高自由意志信念组，被试则阅读到如下一篇题为“科学表明存在自由意志\"的短文，短文同样标注了作者。短文主要阐述了科学表明人们的所作所为大多是他们做出的决定和自由意志的产物，自由意志不是一种幻觉 (详见附录)。",
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "在阅读完短文之后，所有被试被要求对该短文写一个简短的总结，不少于50字。自由意志信念的操纵翻译改编自Mackenzie等人（2014）的研究。为了检查自由意志信念的操纵是否有效，在写完简短总结后，被试被要求回答\"你在多大程度上相信存在自由意志？”（1：一点也不相信， $9 =$ 完全相信)。",
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "然后，被试阅读民族歧视的情境材料(下划线内容为人类组材料，括号中为算法组材料)：“在去年的秋季招聘中，韦蓝公司的人力资源经理张沛负责（使用算法）进行招聘。招聘结束后，公司发现张沛（算法）对应聘者的简历进行筛选时存在民族偏差，筛掉了所有少数民族的应聘者，留下的都是汉族人，而公司的所有岗位对民族并无要求。这阻碍了许多有才华、有能力的少数民族应聘者获得该公司的工作”，情境材料改编自Bigman 等人（2020）的研究。",
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "接着，在阅读完情境材料并进行注意检查后，两组被试分别报告了对人类歧视或算法歧视的道德惩罚欲，测量条目同实验1（Hofmann etal.,2018)，在实验3中，道德惩罚欲测量的内部一致性信度Cronbach $\\alpha = 0 . 8 6$ 。最后，被试报告了性别、年龄和民族三项人口统计学信息。",
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "4.2结果",
        "text_level": 1,
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "4.2.1操纵检查",
        "text_level": 1,
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "独立样本 $t$ 检验结果显示，低自由意志信念组的自由意志信念！ $\\stackrel { \\prime } { M } = 5 . 8 5 , S D = 1 . 9 0 \\$ 显著低于高自由意志信念组 $\\cdot M { = } 6 . 5 4$ $S D = 1 . 4 9 \\$ )， $t ( 2 0 3 ) { = } { - 2 . 8 8 }$ $p { = } 0 . 0 0 4$ ， Cohen's $d = - 0 . 4 0$ 。说明自由意志信念操纵有效。",
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "4.2.2歧视行为主体和自由意志信念对道德惩罚欲的交互作用",
        "text_level": 1,
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "以歧视行为主体（人类组 $\\mathbf { \\varepsilon } = 0$ ，算法组 ${ \\bf \\mu } = 1 { \\bf \\rho }$ ）和自由意志信念（低自由意志信念组 $\\mathbf { \\varepsilon } = 0$ 高自由意志信念组 $^ { \\circ } = 1$ ）作为自变量，以道德惩罚欲作为因变量进行方差分析。数据结果表明，人类组的道德惩罚欲评分 $( M { = } 4 . 5 9 , S D = 1 . 4 6 , 9 5 \\% \\mathrm { C I } [ 4 . 3 1 , 4 . 8 7 ] )$ 显著高于算法组（ $\\mathbf { \\mathcal { M } }$ $= 4 . 1 7$ $S D = 1 . 5 1$ $9 5 \\%$ CI[3.87, 4.46]), $F ( 1 , 2 0 1 ) = 4 . 0 1$ ， $\\scriptstyle p = 0 . 0 4 7$ ， $\\eta _ { \\mathrm { p } } ^ { 2 } \\ = 0 . 0 2 \\$ ，高自由意志信念组的道德惩罚欲评分 $\\left( M = 4 . 6 1 , S D = 1 . 2 6 , 9 5 \\% \\mathrm { C I } [ 4 . 3 6 , 4 . 8 6 ] \\right)$ 显著高于低自由意志组（ $M = 4 . 1 7$ ， $S D = 1 . 6 7$ $9 5 \\%$ CI[3.85,4.49])，差异呈边缘显著， $F ( 1 , 2 0 1 ) = 3 . 8 3$ ， $p = 0 . 0 5 2$ （204号 $\\eta _ { \\mathrm { p } } ^ { 2 } \\ = 0 . 0 2 \\$ ，歧视行为主体和自由意志信念的交互作用显著， $F ( 1 , 2 0 1 ) = 4 . 5 7$ ， $\\mathnormal { p } = 0 . 0 3 4$ ， $\\mathfrak { n }$ （204号$\\begin{array} { r l } { \\mathbf { \\Phi } _ { \\mathrm { ~ p ~ } } ^ { 2 } = 0 . 0 2 } \\end{array}$ 。简单效应分析发现，在高自由意志信念组，算法组的道德惩罚欲评分（ $\\mathbf { \\mathcal { M } } = 4 . 1 4$ $S D = 1 . 4 6 , 9 5 \\%$ CI[3.71,4.58]）显著低于人类组（ $M = 4 . 9 9$ ， $S D = 0 . 9 1$ ， $9 5 \\%$ CI [4.60, 5.39]),$F ( 1 , 2 0 1 ) = 8 . 1 9$ ， $p = 0 . 0 0 5$ ， $\\eta _ { \\mathrm { p } } ^ { 2 } \\ = 0 . 0 4$ ；在低自由意志信念组，算法组与人类组的道德惩罚欲评分无显著差异， $F ( 1 , 2 0 1 ) = 0 . 0 1$ ， $\\begin{array} { r } { p = 0 . 9 2 2 } \\end{array}$ ， $\\eta _ { \\mathrm { p } } ^ { 2 } \\ < 0 . 0 0 1$ （见图2）。",
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "在将被试的性别（男 $^ { \\circ } = 1$ ，女 $= 2 { \\dot { } }$ )、年龄和民族（汉族 $^ { \\ast } = 1 ^ { }$ ，少数民族 $= 2$ ）作为协变量进行控制之后，人类组的道德惩罚欲评分仍然显著高于算法组， $F ( 1 , 1 9 8 ) = 4 . 5 2$ ， $\\begin{array} { r } { p { = } 0 . 0 3 5 } \\end{array}$ ${ \\eta } _ { \\mathrm { p } } ^ { 2 } { \\ } = 0 . 0 2 { \\mathrm { ) } }$ ，高自由意志信念组的道德惩罚欲评分仍然显著高于低自由意志信念组， $F ( 1 , 1 9 8 )$ $= 4 . 8 9$ ， $\\scriptstyle p = 0 . 0 2 8$ ， $\\eta _ { \\mathrm { p } } ^ { 2 } \\ = 0 . 0 2 \\AA .$ )，歧视行为主体和自由意志信念的交互作用仍然显著， $F ( 1 , 1 9 8 )$ $= 4 . 8 8$ ， $p = 0 . 0 2 8$ ， $\\mathfrak { n } _ { \\mathrm { p } } ^ { 2 } ~ = 0 . 0 2$ 。",
        "page_idx": 11
    },
    {
        "type": "image",
        "img_path": "images/d25eef95068f0a73a020667e102b8d76b2cf6d3168e2f126e7251cd870916977.jpg",
        "img_caption": [
            "图2不同自由意志信念组对人类和算法歧视的道德惩罚欲评分"
        ],
        "img_footnote": [
            "Error bars: CI ",
            "注： $^ { * } p < 0 . 0 5$ ， $^ { * * } p < 0 . 0 1$ "
        ],
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "4.3讨论",
        "text_level": 1,
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "实验3通过对被试自由意志信念的操纵，进一步验证了自由意志信念是造成道德惩罚欲差异的机制，发现只有在自由意志信念较高时，不同歧视行为主体（人类vs.算法）才会引发不同程度的道德惩罚欲；而当自由意志信念较弱时，人们对不同歧视主体的道德惩罚欲差异不显著。但实验3存在一些不足之处，首先，实验3未能充分检验本研究所提出的机制，即“人们对算法的道德惩罚欲高于对人类的道德惩罚欲是由于人们认为算法相比人类缺乏自由意志\"；其次，实验3对自由意志信念的操纵并未影响被试对算法的惩罚欲，因此这种操纵可能并未对人们关于算法的自由意志信念产生影响。因此，为了更直接地检验对算法的自由意志信念是否是造成人们对不同歧视主体（人类vs.算法）有不同道德惩罚欲的机制，实验4将直接对人们关于算法的自由意志信念进行操纵。",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "5实验4操纵被试对算法的自由意志信念",
        "text_level": 1,
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "实验4通过实验操纵的方式提升被试对算法的自由意志信念，即采用单因素三水平设",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "计（人类/算法/相信算法有自由意志)，考察人类组与相信算法有自由意志组之间的差异是否较人类组与算法组的差异有所减小。",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "5.1 方法",
        "text_level": 1,
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "5.1.1 被试",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "采用G\\*Power 3.1软件（Faul etal.,2007）计算本实验所需样本量，对于本实验适用的单因素三水平方差分析，取中等效应量 $f { = } 0 . 2 5$ ，显著性水平 $\\mathtt { a } = 0 . 0 5$ ，组数为3，要达到 $90 \\%$ 的统计检验力至少需要 207名被试。考虑到可能会出现少量未完成或未通过注意检查的无效数据，我们共招募了247名来自两所高校的本科生参加实验，完成实验可获得相应学分。实验通过Qualtrics平台开展，被试在实验开始前均详细阅读了实验说明并知情同意，有 37名被试未完成实验或未通过注意检查，最终得到210份有效数据。这些有效被试的平均年龄为19.12岁（ $S D = 1 . 2 8 \\AA$ ，女性106名（占 $50 . 5 \\%$ )。",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "5.1.2实验设计与程序",
        "text_level": 1,
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "实验4为单因素三水平被试间实验设计，两组分别为人类组、相信算法有自由意志组以及算法组，所有被试被随机分配到其中一组。",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "首先，被试阅读民族歧视的情境材料，实验4仍然使用实验3中所用的民族歧视情境，但具体不同之处有三点。第一，为了更好地排除被试对算法的理解程度可能对实验结果造成的影响，两个算法组在民族歧视情境描述之前均加入了对“算法\"含义的解释及举例说明（改编自维基百科和 Merriam-Webster，详见附录)，以确保被试在完成实验前理解算法的含义；第二，实验4中对人类的表述有所不同，由于人名（如“张沛\"）属于具体明确的对象，而“算法”则属于宽泛的概念，无具体明确的对象，因此为了统一人类和算法情境表述的具体/抽象程度，实验4中的人类组的歧视主体仅表述为“人力资源经理”；第三，作为对被试是否相信算法有自由意志的操纵，相信算法有自由意志组的被试还阅读了以下关于情境中公司招聘所用算法的介绍：",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "韦蓝公司的算法接受过训练，可以根据应聘者的个人情况进行简历筛选。该算法的独特之处在于其是一个有自由意志的算法。也就是说，该算法的决策完全由其自己做出，并且其有能力做出不同的选择。",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "该操纵改编自Kim和Duhachek（2020）对于人工智能是否有意识的操纵。为了检验对算法自由意志信念操纵的有效性，被试需要对情境中算法的自由意志进行评分（“你认为该算法在多大程度上拥有自由意志？”，从\"1 $\\mathbf { \\Sigma } = \\mathbf { \\Sigma }$ 一点也没有\"到\"7 $\\mathbf { \\Sigma } = \\mathbf { \\Sigma }$ 非常多\")。",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "在阅读完情境材料并进行操纵和注意检查后，三组被试分别报告了对人类或算法的道德惩罚欲。需要提到的是，为了改进前面3个实验的道德惩罚欲测量条目中“道德惩罚”“不道德行为”等表述可能对被试作答的影响，本实验对测量条目进行了相应修改，将第一道题和第三道题分别修改为：“你认为该人力资源经理（算法）应该为这种行为受到多大程度的惩罚？”、“你在多大程度上认为应该要求该人力资源经理（算法）恢复因其行为所造成的损害？”，评分和计分方式同实验1（Hofmann etal.,2018）， $\\mathtt { q } = 0 . 8 2$ 。最后，被试报告了性别、年龄和民族三项人口统计学信息。",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "5.2结果",
        "text_level": 1,
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "5.2.1操纵检查",
        "text_level": 1,
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "独立样本 $t$ 检验结果显示，相信算法有自由意志组对算法的自由意志信念 $\\langle M = 3 . 7 0 , S D$ $= 1 . 7 3$ ）显著高于算法组（ $\\mathbf { \\mathcal { M } } = 2 . 6 5$ $S D = 1 . 3 4 )$ ， $t ( 1 3 7 ) = 4 . 0 0$ ， $p { < } 0 . 0 0 1$ ，Cohen's $d = 0 . 6 8$ 。说明我们对被试关于算法的自由意志信念操纵有效。",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "5.2.2关于算法的自由意志信念的影响",
        "text_level": 1,
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "以组别（人类组 $^ { \\circ } = 1$ ，相信算法有自由意志组 $= 2$ ，算法组 $= 3$ ）作为自变量，道德惩罚欲作为因变量进行方差分析，结果显示组别的主效应显著， $F ( 2 , 2 0 7 ) = 9 . 0 3 \\$ ， $p { < } 0 . 0 0 1 , \\eta _ { \\mathrm { p } } ^ { 2 } \\ =$ 0.08。计划对比（plannedcontrast）分析表明，算法组的道德惩罚欲（ $\\mathbf { \\partial } M = 3 . 9 4$ $S D = 1 . 4 5$ ）显著低于相信算法有自由意志组（ $\\ M = 4 . 5 6$ $S D = 1 . 6 2$ ）和人类组（ $\\ M = 4 . 9 8$ $S D = 1 . 3 5$ )， $p \\mathbf { s }$ $< 0 . 0 5$ ，但人类组与相信算法有自由意志组的道德惩罚欲无显著差异， $p = 0 . 1 0$ （如图3）。",
        "page_idx": 14
    },
    {
        "type": "image",
        "img_path": "images/55aa4d582c9aa89251e21b46409758815ce9f889e336d6119b765d075835e64f.jpg",
        "img_caption": [
            "图3不同歧视主体组的道德惩罚欲评分"
        ],
        "img_footnote": [
            "Error bars: $9 5 \\%$ CI ",
            "注： $^ { * } p < 0 . 0 5$ ， $^ { * * * } p < 0 . 0 0 1$ "
        ],
        "page_idx": 15
    },
    {
        "type": "text",
        "text": "以组别作为自变量，性别（男 $^ { \\circ } = 1$ ，女 $= 2$ )、年龄和民族（汉族 $^ { \\circ } = 1$ ，少数民族 $= 2$ ）作为协变量，道德惩罚欲作为因变量进行协方差分析，结果显示，性别： $F ( 1 , 2 0 4 ) = 0 . 3 4$ ， $p =$ 0.559；年龄： $F ( 1 , 2 0 4 ) = 1 . 1 3$ ， $p = 0 . 2 8 9$ ；民族： $F ( 1 , 2 0 4 ) = 1 . 7 2$ ， $p { = } 0 . 1 9 1$ ；效应均不显著。组别的效应依然显著， $F ( 2 , 2 0 4 ) = 9 . 5 9$ ， $p < 0 . 0 0 1$ $\\eta _ { \\mathrm { p } } ^ { 2 } \\ = 0 . 0 9$ 。",
        "page_idx": 15
    },
    {
        "type": "text",
        "text": "5.3讨论",
        "text_level": 1,
        "page_idx": 15
    },
    {
        "type": "text",
        "text": "实验4 通过直接操纵人们对算法的自由意志信念，将人类组与相信算法有自由意志组以及算法组进行比较，发现人类组与相信算法有自由意志组之间的差异，相较于人类组与算法组的差异有所减小，从而进一步验证了自由意志信念是造成人们对不同歧视主体（人类 vs.算法）产生不同道德惩罚欲的机制。那么，既然算法歧视比人类歧视引发较少道德惩罚欲的原因是人们认为算法比人类拥有较少的自由意志，那么拟人化倾向的个体差异是否会对这种效应起到调节作用呢？为了回答这一问题，在实验5中，我们将继续探索歧视行为主体影响道德惩罚欲的边界条件，考察拟人化倾向可能存在的调节效应。",
        "page_idx": 15
    },
    {
        "type": "text",
        "text": "6 实验5拟人化倾向的调节作用",
        "text_level": 1,
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "理论上人类相较于算法有更高的自由意志，那么拟人化倾向较高的人是否会更倾向于增加对于算法自由意志的归因，从而对歧视行为主体对道德惩罚欲的关系造成影响呢？实验5旨在回答这一问题。此外，在实验5中我们着眼于年龄歧视问题，从而也进一步丰富了研究的歧视类型。",
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "6.1方法",
        "text_level": 1,
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "6.1.1 被试",
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "基于实验5适用的独立样本 $t$ 检验，使用G\\*Power3.1软件（Faul etal.,2007）计算本实验所需样本量，在显著性水平 $\\mathtt { a } = 0 . 0 5$ 且中等效应量（ $d = 0 . 5$ ）时，预测达到 $90 \\%$ 统计检验力水平总共至少需要172 名被试。通过Credamo 平台招募被试，随机分配至人类组和算法组，实时剔除没有通过注意检查的被试数据并滚动采集，剩余有效数据共199名（女性 88名）被试年龄在18\\~41岁（ $\\mathrm { . } M \\mathrm { = } 2 8 . 6 4$ ， $S D = 4 . 6 8$ ）之间，其中人类组101人，算法组98人。所有被试在实验开始之前均仔细阅读了实验说明并知情同意，有效数据被试在实验结束后获得一定实验报酬。",
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "6.1.2实验设计与程序",
        "text_level": 1,
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "实验5为单因素两水平被试间实验设计，两组分别为人类组和算法组，所有被试被随机分配到其中一组。被试首先阅读学历歧视的情境材料（下划线内容为人类组材料，括号中为算法组材料)：“在去年的秋季招聘中，韦蓝公司的人力资源经理赵广负责（使用算法）进行招聘。招聘结束后，公司发现赵广（算法）对应聘者的简历进行筛选时存在年龄偏差，筛掉了所有年龄大于35岁的应聘者，而公司的大部分岗位对年龄并无硬性要求。这阻碍了许多有才华、有能力、但年龄大于35岁的应聘者获得该公司的工作”，情境材料改编自 Bigman等人（2020）的研究。",
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "在阅读完情境材料并进行注意检查后，两组被试分别报告了对人类歧视或算法歧视的道德惩罚欲，测量条目同实验1（Hofmann etal.,2018）， $\\mathtt { q } = 0 . 8 4$ 。然后，我们测量了被试对于情境中做出年龄歧视行为的人类或算法的自由意志信念，测量条目同实验2（Nadelhoffer etal.，2014）， $\\mathtt { a } = 0 . 8 7$ 。接着，被试填写了拟人化个体差异量表（IndividualDifferences in",
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "Anthropomorphism Questionnaire,IDAQ；Waytz et al.,2014)，共15 个条目（ $\\mathbf { \\boldsymbol { a } } = 0 . 8 7 \\cdot$ )，例如“普通的鱼在多大程度上有自由意志？”，采用李克特11点计分（从‘ ${ \\mathrm { \\Delta } } ^ { * } 0 =$ 一点也不\"到“ $1 0 =$ 非常\")，得分越高表明被试的拟人化倾向越强。最后，被试报告了性别和年龄两项人口统计学信息。",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "6.2结果",
        "text_level": 1,
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "6.2.1歧视行为主体对道德惩罚欲的影响",
        "text_level": 1,
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "独立样本 $\\mathbf { \\chi } _ { t }$ 检验结果显示，人类组的道德惩罚欲评分（ $\\scriptstyle { M = 5 . 2 9 }$ $S D = 0 . 9 7$ ）显著高于算法组（ $M = 4 . 6 1$ ， $S D = 1 . 3 2 { \\rangle }$ ， $t ( 1 9 7 ) = 4 . 1 7$ ， $p < 0 . 0 0 1$ ，Cohen's $d = 0 . 5 9$ 。为了进一步验证结果的稳健性，将被试的性别和年龄作为控制变量，方差分析结果显示，算法组的道德惩罚欲评分仍然显著低于人类组， $F ( 1 , 1 9 5 ) = 1 7 . 2 8 \\$ ， $p < 0 . 0 0 1$ ， $\\eta _ { \\mathrm { p } } ^ { 2 } \\ = 0 . 0 8$ 。",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "6.2.2自由意志信念的中介效应",
        "text_level": 1,
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "为了再次验证歧视主体对道德惩罚欲影响的心理机制，我们使用Hayes（2013）提供的SPSS 插件PROCESS（Model4)，以歧视主体为自变量（人类组 $= - 1$ ，算法组 $\\mathbf { \\Psi } = 1 \\mathbf { \\Psi }$ ，自由意志信念为中介变量，道德惩罚欲为因变量，设定Bootstrap 样本量为 5000，采用偏差校正的方法，选取 $9 5 \\%$ 置信区间进行中介效应检验。数据结果显示，自由意志信念的中介效应值为-0.11， $9 5 \\%$ 的 Bootstrap 置信区间为[-0.23,-0.01]，不包含0，表明中介作用显著；并且在控制中介变量后，歧视主体对道德惩罚欲的直接效应为-0.23， $9 5 \\%$ 的Bootstrap 置信区间为$[ - 0 . 4 2 , - 0 . 0 4 ]$ ，不包含0，表明其直接效应仍然显著，自由意志信念在歧视主体对道德惩罚欲的影响中起部分中介作用。",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "6.2.3拟人化倾向的调节效应",
        "text_level": 1,
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "以道德惩罚欲为因变量考察歧视行为主体（人类组 $^ { = - 1 }$ ，算法组 $^ { \\circ } = 1$ ）与拟人化倾向的交互作用，结果表明歧视行为主体和拟人化倾向对道德惩罚欲存在显著的交互作用( $\\cdot b = 0 . 1 6$ $S E = 0 . 0 6 , t = 2 . 7 0 , p = 0 . 0 0 8 )$ ，人类组的道德惩罚欲显著高于算法组（ $b = - 0 . 3 4$ $S E = 0 . 0 8$ $t$ $= - 4 . 1 8 , p < 0 . 0 0 1 )$ ，拟人化倾向的高低对道德惩罚欲无显著影响（ $\\mathit { \\Delta } b = 0 . 0 1 , S E = 0 . 0 6 , t = 0 . 0 8 ,$ 号$\\begin{array} { r } { p = 0 . 9 3 7 ; } \\end{array}$ ，模型的调整 $R ^ { 2 } = 0 . 1 0 , \\Delta R ^ { 2 } = 0 . 0 3 , F \\left( 3 , 1 9 5 \\right) = 8 . 4 0 , p < 0 . 0 0 1$ 。交互作用如图4所示，简单斜率分析结果表明，在低拟人化倾向条件下，歧视行为主体对道德惩罚欲的影响显著（ $b = - 0 . 5 7$ $S E = 0 . 1 2$ ， $t = - 4 . 8 2$ $p < 0 . 0 0 1 )$ ；而在高拟人化倾向条件下，歧视行为主体对道德惩罚欲的影响不显著（ $b = - 0 . 1 2$ $S E = 0 . 1 2$ ， $t = - 1 . 0 5$ $p = 0 . 2 9 5$ )。并且在算法组，被试的拟人化倾向与对算法的自由意志信念显著正相关， $r = 0 . 2 0 , p = 0 . 0 4 4$ 。",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 18
    },
    {
        "type": "image",
        "img_path": "images/f4027a425c0aa515674b0cd9fbed30165e42981ead382b8a93e1bdbfc94d2378.jpg",
        "img_caption": [
            "图4拟人化倾向的调节作用"
        ],
        "img_footnote": [],
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "6.3讨论",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "实验5进一步探索了歧视行为主体影响道德惩罚欲的边界条件，结果发现拟人化倾向在歧视行为主体对道德惩罚欲的影响中起调节作用。在拟人化倾向较低的被试中，算法组的道德惩罚欲显著低于人类组；而在拟人化倾向较高的被试中，算法组和人类组的道德惩罚欲无显著差异。同时，实验5还再次验证了自由意志信念的中介作用，即人们之所以对算法歧视的道德惩罚欲较低，是由于认为其与人类相比有更少的自由意志。在实验6中，我们将直接操纵算法的拟人化程度，以期进一步验证拟人化的调节作用。",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "7实验6算法拟人化的调节作用",
        "text_level": 1,
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "为了更直接地探讨算法拟人化是否会调节歧视主体对道德惩罚欲的影响，实验6通过文字操纵的方式将算法拟人化，比较被试对人类歧视、拟人化算法歧视以及非拟人化算法歧视的道德惩罚欲，以此进一步验证拟人化在歧视主体影响道德惩罚欲中的调节作用。",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "7.1 方法",
        "text_level": 1,
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "7.1.1 被试",
        "text_level": 1,
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "基于实验6 的单因素三水平被试间设计，使用G\\*Power 3.1软件（Faul et al.,2007）计算本实验所需样本量，在显著性水平 $\\mathtt { a } = 0 . 0 5$ 且中等效应量 $\\scriptstyle ( f = 0 . 2 5 )$ ）时，预测达到 $90 \\%$ 统计检验力水平总共至少需要 207 名被试。通过Credamo 平台招募被试，随机分配至人类组、拟人化算法组和非拟人化算法组，实时剔除没有通过注意检查的被试数据并滚动采集，剩余有效数据共 207名（女性127名)，被试年龄在19\\~59岁（ $M = 2 9 . 5 3$ ， $S D = 6 . 6 2 \\$ ）之间，其中人类组、拟人化算法组和非拟人化算法组均为69人。所有被试在实验开始之前均仔细阅读了实验说明并知情同意，有效数据被试在实验结束后获得一定实验报酬。",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "7.1.2实验设计与程序",
        "text_level": 1,
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "实验6为单因素三水平被试间实验设计，三组分别为人类组、拟人化算法组以及非拟人化算法组，所有被试被随机分配到其中一组。与实验4相同，为了更好地排除被试对算法的理解程度可能对实验结果造成的影响，两个算法组在歧视情境描述之前均加入了对“算法”含义的解释及举例说明，以确保被试在完成实验前理解算法的含义。然后，被试阅读了学历歧视的情境材料（下划线内容为人类组材料，括号中为拟人化算法组和非拟人化算法组材料)：“在去年的秋季招聘中，韦蓝公司的人力资源经理赵广（使用算法“奇智”/使用算法“R2000\"）负责进行招聘。招聘结束后，公司发现赵广（奇智/R2000）对应聘者的简历进行筛选时存在性别偏差，对于男性有明显的偏好，筛掉了许多女性应聘者，而公司的大部分岗位对性别并无硬性要求。这阻碍了许多有才华、有能力的女性应聘者获得该公司的工作”，情境材料改编自Bigman等人（2020）的研究。",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "作为对算法拟人化的操纵，两组算法组的被试在阅读完性别歧视的情境材料后还阅读了关于材料中所用招聘算法的介绍。其中，拟人化算法组的被试阅读了以下关于算法“奇智”的介绍：",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "算法“奇智”的自我介绍：",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "嗨！我叫奇智，我是一种新型的招聘算法。我分析了过去十年投递给公司的所有简历，来学习如何找出最优秀的应聘者。我能够仔细地审查应聘者的简历与背景，准确预测未来可以满足岗位需求的员工、适合企业文化的员工，找出最优秀的应聘者，帮助企业挑选最好的员工。",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "非拟人化算法组的被试则阅读了以下关于算法“R2000”的介绍：",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "算法“R2000”的介绍：",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "R2000是一种新型的招聘算法。R2000分析了过去十年投递给公司的所有简历，来学习如何找出最优秀的应聘者。R2000能够仔细地审查应聘者的简历与背景，准确预测未来可以满足岗位需求的员工、适合企业文化的员工，找出最优秀的应聘者，帮助企业挑选最好的员工。",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "该操纵参考了已有研究对于拟人化程度的操纵方式，即为非人对象起一个人名，并且以第一人称加以描述，能够有效地提升拟人化程度（e.g.,Hur et al.,2015;May&Monga,2014)。除此之外，两组对于算法的描述完全相同。为了检验拟人化操纵的有效性，被试需要对情境中算法的拟人化程度进行评分（“算法‘奇智’／‘R2000’在多大程度上让你想起了一些人类的特质？”，从“1 $\\mathbf { \\Sigma } = \\mathbf { \\Sigma }$ 一点也没有\"到“7 $\\mathbf { \\Sigma } = \\mathbf { \\Sigma }$ 非常多\")，该操纵检查改编自Hur 等人（2015）的研究。",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "在阅读完以上材料并进行操纵和注意检查后，三组被试分别报告了对人类歧视或算法歧视的道德惩罚欲，测量条目同实验4（Hofmann et al.,2018)，评价对象为赵广/奇智/R2000,$\\mathtt { a } = 0 . 8 8$ 。最后，被试报告了性别和年龄两项人口统计学信息。",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "7.2结果",
        "text_level": 1,
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "7.2.1拟人化操纵检查",
        "text_level": 1,
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "独立样本 $\\mathbf { \\chi } _ { t }$ 检验结果显示，拟人化算法组的拟人化评分（ $\\stackrel { \\triangledown } { \\cdot } M = 5 . 4 3 , S D = 0 . 8 8 \\$ ）显著高于非拟人化算法组（ $\\pmb { M } = 4 . 8 3$ $S D = 1 . 2 5$ ， $t ( 1 3 6 ) = 3 . 3 1$ ， $p = 0 . 0 0 1$ ，Cohen's $d = 0 . 5 6$ 。说明我们对算法拟人化的操纵有效。",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "7.2.2算法拟人化的影响",
        "text_level": 1,
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "以道德惩罚欲作为因变量进行单因素方差分析发现，歧视主体的主效应显著， $F ( 2 , 2 0 4 )$ $= 1 2 . 6 0$ ， $p < 0 . 0 0 1$ ， $\\eta _ { \\mathrm { p } } ^ { 2 } \\ = 0 . 1 1$ 。计划对比（plannedcontrast）分析表明，人类组的道德惩罚欲评分（ $\\ M = 5 . 5 2$ ， $S D = 1 . 1 9$ ， $9 5 \\%$ CI[5.24,5.81]）显著高于拟人化算法组（ $M = 4 . 9 7$ ， $S D =$ 1.27, $9 5 \\%$ CI[4.66,5.27]）和非拟人化算法组（ $\\overset { \\cdot } { M } = 4 . 4 3$ ， $S D = 1 . 3 5$ $9 5 \\%$ CI[4.11,4.76])，而拟人化算法组的道德惩罚欲评分也显著高于非拟人化算法组， $p \\mathrm { s } < 0 . 0 5$ （如图5)。这表明对于同样的性别歧视，人类组（相比于算法组）的被试会产生更强烈的道德惩罚欲；而通过将算法拟人化，结果发现拟人化算法组（相比于非拟人化算法组）的被试也会产生更强烈的道德惩罚欲，说明算法拟人化在歧视主体对道德惩罚欲的影响中具有一定的调节作用。",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 21
    },
    {
        "type": "image",
        "img_path": "images/227e43dd238e26b5eb57ffe798149353335d80f5ce5b1ed2f1ff13db5abaf37b.jpg",
        "img_caption": [
            "图5不同歧视主体组的道德惩罚欲评分"
        ],
        "img_footnote": [
            "Error bars: $9 5 \\%$ CI ",
            "注： $^ { * } p < 0 . 0 5$ ， $^ { * * * } p < 0 . 0 0 1$ "
        ],
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "7.3 讨论",
        "text_level": 1,
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "实验6在实验5的基础上直接操纵的算法的拟人化程度，从而再次验证了算法拟人化在歧视主体对道德惩罚欲影响中的调节作用。具体而言，将算法拟人化会显著提升被试对算法的道德惩罚欲，这与我们的预测相一致。但拟人化算法组和人类组被试的道德惩罚欲仍然存在显著差异，这可能是由于文字操纵的算法拟人化虽然提升了算法整体的拟人化程度，但拟人化的算法仍然与人类水平有一定程度的差距（尤其是在自由意志信念方面）所致。",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "8总讨论",
        "text_level": 1,
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "本研究考察了人们对人类歧视和算法歧视的道德惩罚欲是否存在差异，并在此基础上探讨了造成差异的潜在机制和边界条件。通过6项实验，我们发现相对于人类歧视，算法歧视会引发人们更少的道德惩罚欲，自由意志信念是造成道德惩罚欲差异的潜在机制，并且这一差异受到拟人化倾向的调节。具体而言，通过为不同被试呈现人类或算法同样的歧视行为并测量其道德惩罚欲，我们发现人们对算法歧视的道德惩罚欲小于对人类歧视的道德惩罚欲，并且这一差异具有稳健性（实验1\\~6)。通过测量被试对人类或算法的自由意志信念（实验2）以及对被试的自由意志信念（实验3）和关于算法的自由意志信念（实验4）进行操纵，我们进一步发现自由意志信念是造成人们对不同歧视主体（人vs.算法)产生不同道德惩罚欲的潜在机制，即人们认为算法与人类相比具有较少的自由意志，因此对算法歧视的道德惩罚欲较少（实验2\\~4)。通过对被试拟人化倾向的测量（实验5）和对算法拟人化程度的操纵(实验6)，我们也发现了歧视主体对道德惩罚欲的影响受到拟人化的调节。在个体的拟人化倾向方面，对于拟人化倾向较低的被试来说，他们对算法歧视的道德惩罚欲小于对人类歧视的道德惩罚欲，而对于拟人化倾向较高的被试来说，他们对算法歧视和人类歧视的道德惩罚欲不存在显著差异（实验5)；在算法的拟人化程度方面，算法的拟人化程度越高，人们对算法歧视与对人类歧视的道德惩罚欲差异越小。在研究中我们考察了不同类型的歧视，包括性别歧视（实验1、6)、学历歧视（实验2）、民族歧视（实验3、4）以及年龄歧视（实验5)；并且研究的样本涵盖了不同被试，包括来自Credamo平台（实验1、2、5、6）的全国范围内被试以及来自某高校的大学生被试（实验3、4)。实验情境材料和被试的多样性保障了研究结果的稳健性。",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.1对人—算法的反应差异",
        "text_level": 1,
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "本研究发现，在面对人类和算法做出同样的歧视行为时，人们会产生不同的道德惩罚欲，即人们对算法歧视的道德惩罚欲小于对人类歧视的道德惩罚欲。首先，这一结果与 Bigmar等人（2020）的研究发现相一致。Bigman 等人（2020）比较了人们对人类歧视和算法歧视的道德义愤，结果发现相对于人类歧视，人们对算法歧视的道德义愤较少，这一研究主要从道德情绪的方面探讨了人们对人类和算法反应的不对称性（asymmetry)。而本文则从行为倾向的视角出发，再次验证了人们对人类和算法反应的不对称性。但需要强调的是，虽然同为对不同歧视主体（人vs.算法）的比较，但和Bigman 等人（2020）的研究相比，本研究与之区别的独特创新之处主要在于：第一，因变量的差异，Bigman 等人（2020）主要探讨了道德情绪即道德义愤的不同，而本文的研究重点在于行为倾向即道德惩罚欲的不同。虽然道德义愤和道德惩罚具有一定程度的相关性，但不意味着两者完全等同，道德惩罚欲依然有其独特的研究价值。并且Bigman 等人（2020）虽然在研究5中加入了与道德惩罚测量具有一定相似性的条目（如“有歧视行为的算法应该被弃用”“采用该算法的公司应该道兼\")，但一方面这些条目并非完全针对算法，另一方面其研究结果也并未发现两组之间的显著差异。第二，机制的差异，Bigman 等人（2020）的研究着重探讨了动机机制，而本文则重复验证了自由意志信念的机制，并且从一定意义上来说自由意志机制比动机机制更为基础，因为个体具有自由意志是判断其动机的必要条件（Laming,2004)；第三，调节的差异，Bigman 等人（2020）的研究并未进行调节变量的探索，他们在文章的局限和未来方向部分强调了拟人化倾向可能会扮演的调节作用，而本文则通过两个研究，从个体的拟人化倾向和算法本身的拟人化两个方面重复验证了拟人化的调节作用。",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "其次，这一发现将道德惩罚欲的相关研究拓展至人工智能领域。先前关于道德惩罚欲的研究大多聚焦于人类，且对于影响因素的探索也局限于人类相关变量（e.g.,Hofmann et al,2018)。本研究则在当前人工智能发展的大背景下扩大了道德惩罚欲的研究范围，将人工智能作为歧视行为主体的可能性纳入考察范围，并发现了歧视行为主体（人类vs.算法）也会对道德惩罚欲产生显著影响。",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "此外，在对于算法决策的态度研究方面，我们的发现在一定程度上提供了算法厌恶（algorithmaversion）反例的新证据。算法厌恶研究发现，人们对算法在心理上有一种不信任感（Meehl,1954)，虽然算法在计算能力等诸多方面已经超越了人类、表现更优，但通常情况下人们更偏好人类决策而非算法决策（Dietvorst etal.,2015,2018)。如相对于人类决策的错误，算法决策错误对于人们来说更难以接受（Prahl& Van Swol,2017)。尤其是当决策涉及道德时，人们更反对机器代替人类做出决策，因为认为机器缺少做道德决策的必要心智能力，即使机器决策结果积极，人们仍然反对（Bigman＆Gray,2018)。在本研究中，我们发现当算法和人类都做出同样的歧视行为时，人们对算法的道德惩罚欲更小，这与先前支持算法厌恶的研究结果并不一致，如对算法犯错态度更严苛（Prahl&Van Swol,2017）等。但需要注意的是，这一结果也并不能够完全推翻算法厌恶的相关发现，因为人们或许仍然不愿意让算法做道德决策（Bigman＆Gray,2018)，但只是在算法和人类同样做出道德决策后消极反应更少而已。换句话说，人们对算法做道德决策的“欣赏\"或许仅限于算法已经做出决策之后，而非体现在决策之前的偏好上。",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "要产生算法欣赏（algorithm appreciation），似乎需要客观性较强的任务，人们才会更加偏好算法决策（Logg et al.,2019)。算法因其计算能力和客观性可能会被认为更准确公正（Groveet al.,2000），但实际上算法歧视的事例并不鲜见，危险仍然存在（e.g.,Borgesius,2018)。在面对算法歧视时，人们不会像面对人类歧视时那般愤怒（Bigman etal.,2020），我们也发现人们不会像面对人类歧视时那样想要进行惩罚，在情绪和行为倾向上程度都更低，由此可能造成对算法歧视的警惕性降低、习惯性甚至合理化增强，从而带来更严重的歧视问题。",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "8.2对人—算法的知觉差异 ",
        "text_level": 1,
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "本研究还发现人们对人类和算法的知觉存在差异，即认为算法比人类拥有更少的自由意志，而这也是解释道德惩罚欲差异的潜在机制。首先，这一发现与前人关于人工智能心智知觉和心理状态的相关研究大致一致（e.g.,Grayet al.,2007)。如人们认为机器人具有中等程度的能动性（Epley&Waytz,2010)，即做出自主、有计划行为的心理能力逊于人类。这与我们关于人们认为算法的自由意志少于人类的发现类似，都证实了人们认为算法等人工智能相关的机器型非人对象虽然有一定程度的心理能力，但仍远达不到人类水平。其次，这一发现也再次验证了自由意志信念与道德惩罚之间的紧密联系。人们之所以对算法歧视的道德惩罚欲小于对人类歧视的道德惩罚欲，我们发现与算法具有较低程度的自由意志有关。一个人自由行动、能够做出不同选择的能力对其是否应当承担道德责任和惩罚具有至关重要的影响(e.g., Shariff et al.,2014; Clark et al.,2014)，关于自由意志是否存在的信念也会影响对违规者的惩罚（Aspinwall et al.,2012)。本文的发现与前人对于自由意志和道德惩罚关联的研究结果一致，在更广义上，与心理能力是承担道德责任的必要前提这一观点也相符合（Gray etal.,2012)。此外需要提到的是，虽然可能存在与自由意志无关的竞争假设，如人的行为相对于算法更容易被解释、人无法真正惩罚算法等，但本文通过2个自由意志信念的调节效应研究（实验3\\~4）和2个拟人化（与自由意志密切相关）的调节效应研究（实验5\\~6）重复验证了本文所提出的自由意志信念机制，在一定程度上排除了上述竞争假设。",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "当然，对人—算法的知觉差异不仅体现在对其本身心智知觉的差异上，还可能体现在对其行为的知觉中。具体而言，虽然在实验情境甚至现实生活中人类和算法做出了完全一样的歧视行为并造成了同等影响，但人们对其严重性的知觉却可能存在差异。Bonezzi和Ostinelli（2021）的研究发现与人类歧视相比，做出性别和种族歧视行为的算法被认为有偏见的可能性更低，这是由于人们认为算法并不会像人类一样关注个体特征，而是以规则和程序进行笼统评判决策（Bonezzi&Ostinell,2021)。本文虽然没有直接测量和探讨人们对算法歧视和人类歧视严重性的知觉，但从研究的结果来看与已有发现是一致的。",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "同时，我们的研究发现拟人化倾向对于人们是否想要对算法歧视进行道德惩罚具有调节作用，这在本质上与具有完整的人类心智是承担道德责任的必要条件（Bigman&Gray,2018;Gray etal.,2012）等研究结果相一致。人工智能的拟人化是业界趋势（Broadbent,2017）、人工智能伦理问题之关键（Bostrom& Yudkowsky,2011)。以歧视研究为例，以拟人化的算法作为歧视的主体不仅有助于更直接地探讨人们对人类和算法的知觉差异，或许也能够在一定程度上“模拟”人类歧视的心理过程，从而帮助我们更好地理解歧视的产生。",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "8.3局限与展望 ",
        "text_level": 1,
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "我们的研究证明了人们对人类歧视和算法歧视的道德惩罚欲存在差异，这种差异是由于人们对人类和算法的自由意志知觉不同，并且这一差异受到拟人化的调节。不过，我们也承认当前研究仍具有一定的局限性，这为未来的研究指出了一些方向。",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "首先，在实验设计的细节方面存在一定不足。第一，实验1、2、3、5的道德惩罚欲测量直接采用了Hofmann 等人（2018）的条目，其中“道德惩罚”和“不道德行为”的表述置于算法歧视行为可能会对被试的回答造成一定的影响。当然我们在实验4和实验6中变换为了更加中性的说法，并未影响主要结果。第二，被试对算法的熟悉和了解程度可能对研究结果造成影响，但在一些实验（1、2、3、5）中我们并未解释算法的含义并举例说明，这在实验4和实验6中进行了弥补，但未来的研究仍需重点关注这一问题。第三，实验 2\\~4的歧视情境描述存在歧视主体表述维度差异的问题，即“人力资源经理李原/张沛/赵广”属于具体明确的对象，而算法属于宽泛的概念，无具体明确的对象。有研究发现，相比于一个身份不明的违规者，人们更倾向于惩罚一个确定的违规者（e.g.,Small&Loewenstein,2005），所以实验中歧视主体表述维度的差异可能对研究结果造成一定的影响。为此我们在实验1 和实验4的情境材料中均采用较为抽象的表述，在实验6的情境材料中则均采用较为具体的表述，均得到了类似结果。",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "其次，人们对人类歧视和算法歧视的道德惩罚欲差异可能还存在别的解释机制。在本文中我们着重探讨了自由意志信念的中介作用，但实际上人们对人类和算法心智知觉的差异还可能体现在别的方面，例如意识（consciousness; McDermott,2007）、意向性（intentionality;Weisman etal.,2017)，以及体验情绪的心理能力（Epley&Waytz,2010）等。未来的研究可以更加细致地去考察这些可能的变量，并对这些影响因素进行比较，以便更透彻地理解人对人类和算法反应差异的心理机制。除了心智知觉方面的差异之外，上文中也提到人们对算法歧视和人类歧视的严重性程度的知觉存在差异（Bonezzi&Ostinelli,2021)，因此在之后的研究中也可以将此纳入对人类和算法反应差异的机制探索中。此外，人们日常生活中约定俗成的“道德惩罚阈限”也可能对道德惩罚欲产生影响。即对于非人对象而言，人们对其道德惩罚欲可能本身就存在一定的阈限，哪怕其道德违规再严重也难以突破一定阈值，因此在之后的研究中也可以对相关阈限问题进行进一步的探讨。",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "最后，道德惩罚欲可能与道德归责的主体相关。在本文的研究中，我们考察了被试对算法的道德惩罚欲，发现人们对算法歧视的道德惩罚欲小于对人类歧视的道德惩罚欲。这一发现还有一个可能的原因在于人们并不愿意将道德责任归因于算法。以往研究发现人们不愿意让机器做道德决策（Bigman＆Gray,2018)，那么在机器已经做出道德决策的情况下，相应的道德责任究竞应该由谁来承担？是算法？是算法的设计者？是投资算法的企业？抑或监管算法的相关机构也需要承担一定的责任？随着人工智能的应用和算法决策的日益普及，越来越多的算法决策已经成为了既定事实，尽管人类仍然是这些人工智能的设计者、应用者、监管者，但伴随着人们对人工智能道德遣责的增加，人工智能相应承担的责任和惩罚也会加重，这无疑会带来一种潜在的“甩锅”可能性——设计者、企业甚至政府利用人工智能来逃避自身错误的责任（Bigman et al.,2019)。而道德归责之后的惩罚也会随之受到影响，这一方面是由于责任与惩罚的相关性，即人们若倾向于将责任归因于人，那么对于人工智能的道德惩罚也会相应较少；另一方面，从道德惩罚本身的“惩戒”、“规范”等实际功用而言，对人工智能背后的“人”，尤其是涉及非法牟利或使用不当的“使用者”进行惩罚或许更合理，也更有现实意义。虽然如算法等人工智能现在还无法成为完全的道德主体，但是在其犯错时，我们依然还是可能惩罚它，如扫地机器人犯错可能招致人类脚踢的惩罚，而若算法犯错，人也可能惩罚承载其的智能设备，如摔手机等。当然，对算法探讨的核心也是为了人类福祉。因此，对于人类和人工智能之间道德责任乃至道德惩罚的分配都值得进一步研究。",
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "9结论",
        "text_level": 1,
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "本研究结论如下：第一，相对于人类歧视，人们对算法歧视的道德惩罚欲更少；第二，这一现象的潜在机制是人们认为算法（与人类相比）更缺乏自由意志；第三，个体拟人化倾向越强或者算法越拟人化，人们对算法的道德惩罚欲越强。",
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "参考文献",
        "text_level": 1,
        "page_idx": 27
    },
    {
        "type": "text",
        "text": "Al Ramiah, A., Hewstone, M., Dovidio, J. F.,& Penner, L.A. (2010). The social psychology of discrimination: Theory, measurement and consequences. In L. Bond, F. McGinnity, & H. Russell (Eds.), Making equality count: Irish and international research measuring equality and discrimination (pp. 84-112). Dublin, Ireland: Liffety Press.   \nAngwin, J., Larson, J., Mattu, S.,& Kirchner, L. (2016). Machine bias. Retrieved June 18,2021, from https://www.propublica.org/article/machine-bias-risk-assessments-in-criminalsentencing   \nAngwin, J., Matt, S., & Larson, J. (2015). The tiger mom tax: Asians are nearly twice as likely to get a higher price from Princeton Review. Retrieved June 18， 2021， from https://www.ProPublica.org/article/asians-nearly-twice-as-likely-to-get-higher-price-fromprinceton-review   \nAspinwall,L. G., Brown, T.R.,& Tabery, J. (2012). The double-edged sword: Does biomechanism increase or decrease judges' sentencing of psychopaths? Science, 337, 846-849.   \nBartneck， C.，Kulic，D.， Croft, E.，& Zoghbi， S. (2009). Measurement instruments for the anthropomorphism， animacy， likeability, perceived intelligence,and perceived safety of robots. International Journal of Social Robotics, I(1), 71-81.   \nBatson, C. D., Kennedy, C.L., Nord,L. A., Stocks, E. L., Fleming, D. Y.A., Marzette, C. M.,..& Zerger, T. (20o7). Anger at unfairness: Is it moral outrage?. European Journal of Social Psychology,37(6),1272-1285.   \nBaumeister， R. F. (2008). Free will in scientific psychology. Perspectives on Psychological Science,3(1),14-19.   \nBaumeister, R. F. (2014). Constructing a scientific theory of free will In W. Sinnot-Armstrong (Ed.),Moral psychology， Vol. 4. Free will and moral responsibility (pp. 235-255). Boston Review.   \nBaumeister, R.F., Masicampo, E.J.,& DeWall C.N. (2009). Prosocial benefits of feeling free: Disbelief in free will increases aggression and reduces helpfulness. Personality and Social ",
        "page_idx": 27
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 28
    },
    {
        "type": "text",
        "text": "Psychology Bulletin,35(2),260-268.   \nBaumeister, R. F.， Stillwell, A.，& Wotman, S.R. (1990). Victim and perpetrator accounts of interpersonal conflict: Autobiographical narratives about anger. Journal of Personality and Social Psychology,59(5),994-1005.   \nBigman, Y.E.,& Gray, K. (2018).People are averse to machines making moral decisions. Cognition, 181, 21-34.   \nBigman, Y. E., Gray, K., Waytz, A.,Armestad, M.,& Wilson,D.(202O). Algorithmic discrimination causes less moral outrage than human discrimination [Preprint]. PsyArXiv.   \nBigman, Y. E., Waytz, A., Alterovitz, R.，& Gray, K. (2019). Holding robots responsible: The elements of machine morality. Trends in Cognitive Sciences,23(5),365-368.   \nBonezzi，A.，& Ostineli， M. (2021). Can algorithms legitimize discrimination?. Journal of Experimental Psychology: Applied. Advance online publication.   \nBorgesius, F. Z. (2018). Discrimination, artificial intelligence,and algorithmic decision-making. Retrieved June 18， 2021， from htps:/rm.coe.int/discrimination-artificial-intelligenceandalgorithmic-decision-making/1680925d73   \nBostrom, N.,& Yudkowsky, E. (2011). The ethics of Artificial Intelligence. In K. Frankish (Ed.). Cambridge handbook of artificial intelligence. Cambridge: Cambridge University Press.   \nBroadbent, E. (2017). Interactions with robots: The truths we reveal about ourselves. Annual Review of Psychology, 68, 627-652.   \nClark, C.J.,Luguri, J.B., Ditto,P.H., Knobe,J.,Sharif,A. F.,& Baumeister,R.F. (2014). Free to punish: A motivated account of free will belief.Journal of Personality and Social Psychology,106(4),501-513.   \nCorrell,J., Judd, C. M., Park, B.,& Witenbrink, B. (2010). Measuring prejudice, stereotypes and discrimination. The SAGE handbook of prejudice, stereotyping and discrimination, (pp. 45- 62). Thousand Oaks, CA: Sage.   \nDastin, J. (2018). Amazon scraps secret AI recruiting tool that showed bias against women. Retrieved June 18， 2021， from htps://www.reuters.com/article/us-amazon-com-jobsautomation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-againstwomen-idUSKCN1MK08G   \nDatta, A., Tschantz, M. C.,& Datt, A. (2015). Automated experiments on ad privacy setings. Proceedings on Privacy Enhancing Technologies, 1(1), 92-112.   \nDietvorst, B.J., Simmons,J.P., & Massey, C. (2015). Algorithm aversion: People erroneously avoid algorithms after seeing them er. Journal ofExperimental Psychology: General, 144(1), 114- 126.   \nDietvorst, B.J., Simmons, J. P., & Massey, C. (2018). Overcoming algorithm aversion: People will use imperfect algorithms ifthey can (even slightly) modify them. Management Science, 64(3), 1155-1170.   \nEpley,N.,& Waytz, A. (2010). Mind perception. In S.T.Fiske, D. T. Gilbert,& G. Lindzey (Eds.),Handbook of social psychology (pp. 498-541). John Wiley & Sons, Inc.   \nEpley，N.， Waytz, A.，& Cacioppo, J. T. (2007). On seeing human: A three-factor theory of anthropomorphism. Psychological Review, 114(4), 864-886.   \nFaul, F., Erdfelder, E., Lang,A. G., & Buchner, A. (2007). G\\* Power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences. Behavior Research Methods,39(2),175-191.   \nFerrero,F.，& Barujel, A. G. (2019, October). Algorithmic driven decision-making systems in education: Analyzing bias from the sociocultural perspective. In 2019 XIV Latin American Conference on Learning Technologies (LACLO) (pp.166-173), San Jose Del Cabo, Mexico.   \nFredman,R.,Borg,J.S., innot-Armstrong, W.,Dickerson,J.P.,& Conitzer, V. (202O).Adating a kidney exchange algorithm to align with human values. Artificial Intelligence, 283,103261.   \nGray,H. M., Gray, K., & Wegner,D. M. (2007). Dimensions of mind perception. Science, 315(5812), 619.   \nGray, K., Young,L., & Waytz, A. (2012). Mind perception is the essence of morality. Psychological Inquiry, 23(2),101-124.   \nGrove,W. M., Zald, D.H., Lebow, B. S., Snitz, B.E.,& Nelson, C. (200O). Clinical versus mechanical prediction: A meta-analysis. Psychological Assessment, 12, 19-30.   \nHaidt, J.,& Graham, J. (2oo7). When morality opposes justice: Conservatives have moral intuitions that liberals may not recognize. Social Justice Research, 20, 98-116.   \nHao. K. (2019). AI is sending people to jail-and getting it wrong. Retrieved June 18, 2021, from https://www.technologyreview.com/2019/01/21/137783/algorithms-criminal-justice-ai/   \nHarvey, C. R., Ratray, S., Sinclair, A.，& Van Hemert, O. (2017). Man vs. machine: Comparing discretionary and systematic hedge fund performance. The Journal of Portfolio Management, 43(4), 55-69.   \nHayes,A. F. (2Ol3). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. New York: Guilford Press.   \nHofmann,W.， Brandt, M. J.， Wisneski, D. C., Rockenbach,B.,& Skitka,L. J. (2018). Moral punishment in everyday life. Personality and Social Psychology Bulletin, 44(12),1697-1711.   \nHur,J. D.， Minjung，K.，& Wilhelm, H. (2015). When temptations come alive: How anthropomorphism undermines self-control. Journal of Consumer Research, 42(2), 340-358.   \nKim,T. W.，& Duhachek,A. (2020). Artificial intelligence and persuasion: A construal-level account. Psychological Science, 31(4),363-380.   \nLambrecht, A., & Tucker, C.(2019). Algorithmic bias? An empirical study of apparent gender-based discrimination in the display of STEM career ads. Management Science, 65(7), 2966-2981.   \nLaming, D. (2004). Understanding human motivation: What makes people tick? Malden, MA: Blackwell.   \nLeo, X., & Huh, Y.E. (2020). Who gets the blame for service failures? Atribution of responsibility toward robot versus human service providers and service firms. Computers in Human Behavior; 113(4), 106520.   \nLogg,J. M.， Minson, J. A., & Moore, D. A. (2019). Algorithm appreciation: People prefer algorithmic to human judgment. Organizational Behavior and Human Decision Processes, 151,90-103.   \nMackenzie,M.J., Vohs, K.D.,& Baumeister,R.F. (2014). You didn't have to do that: Belief in free will promotes gratitude. Personality and Social Psychology Bulletin, 40(11),1423-1434.   \nMay,F., & Monga, A. (2014). When time has a willof its own, the powerless don't have the will to wait: Anthropomorphism of time can decrease patience.Journal of Consumer Research, 40(5), 924-942.   \nMcDermott, D. (2007) Artificial intelligence and consciousness. In Zelazo,P., Moscovitch, M. & Thompson, E. (Eds.)， Cambridge Handbook of Consciousness (pp. 117-150). Cambridge: Cambridge University Press.   \nMeehl,P.E.(1954). Clinical versus statistical prediction: A theoretical analysis and a review of the evidence. Minneapolis, MN: University of Minnesota Press.   \nMori,M. (1970). The uncanny valley. Energy, 7, 33-35.   \nNadelhoffer,T.,hepard,J.,Nahmias,E.,Sripada,C.,& Ross,L.T. (2014). The fre willinventory: Measuring beliefs about agency and responsibility. Consciousness and Cognition, 25, 27-41.   \nNahmias,E., Morris, S., Nadelhofer, T.,& Turner, J. (20o5). Surveying freedom: Folk intuitions about free will and moral responsibility. Philosophical Psychology, 18, 561-584.   \nNichols, S.,& Knobe,J. (2007). Moral responsibility and determinism: The cognitive science of folk intuitions. Nous, 41(4), 663-685.   \nObermeyer, Z., Powers,B., Vogeli, C.,& Mullainathan, S. (2019). Dissecting racial bias in an algorithm used to manage the health of populations. Science, 366(6464), 447-453.   \nPrahl,A.，& Van Swol, L. (2017). Understanding algorithm aversion: When is advice from automation discounted?. Journal of Forecasting, 36(6), 691-702.   \nRigoni, D., Kuhn, S., Gaudino, G.， Sartori, G.,& Brass,M. (2012). Reducing self-control by weakening belief in free will. Consciousness and Cognition, 21(3),1482-1490.   \nShariff, A.F., Greene, J. D., Karremans, J. C., Luguri, J.B., Clark, C.J.,Schooler, J. W.,..& Vohs, K. D. (2014). Free will and punishment: A mechanistic view of human nature reduces retribution. Psychological Science, 25(8), 1563-1570.   \nSinnott-Armstrong, W. (2014). Moral psychology: Free will and moral responsibility. MIT Press.   \nSmall,D.A., & Loewenstein, G. (2005). The devil you know: The effects of identifiability on punishment. Journal of Behavioral Decision Making, 18(5),311-318.   \nTang,S., Koval, C. Z., Larrck, R. P.,& Harris,L. (202O). The morality of organization versus organized members: Organizations are atributed more control and responsibility for negative outcomesthan areequivalent members.Journalof PersonalityandSocial Psychology, 119(4), 901-919.   \nVohs,K. D., & Schooler, J. W. (2008). The value of believing in free wil: Encouraging a belief in determinism increases cheating. Psychological Science, 19(1), 49-54.   \nWaytz,A., Cacioppo, J., & Epley, N. (2010). Who sees human? The stability and importance of ",
        "page_idx": 28
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 29
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 30
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "individual differences in anthropomorphism. Perspectives on Psychological Science,5(3), 219-232. ",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "Waytz,A., Cacioppo, J.,& Epley, N. (2014). Who sees human? The stability and importance of individual differences in anthropomorphism. Perspectives on Psychological Science, 5(3), 219-232.   \nWaytz,A., Heafner, J., & Epley, N. (2014). The mind in the machine: Anthropomorphism increases trust in an autonomous vehicle. Journal of Experimental Social Psychology, 52,113-117.   \nWegner, D.M., & Gray, K. (2017). The mind club: Who thinks,what feels, and why it matters. Penguin.   \nWeisman, K., Dweck, C. S., & Markman, E. M. (2017). Rethinking people's conceptions of mental life. Proceedings of the National Academy of Sciences, 114(43), 11374-11379.   \nWen, Z., Zhang,L., Hou, J.,& Liu, H. (2004). Testing and application of the mediating effects. Acta Psychologica Sinica, 36(5), 614-620.   \n[温忠麟，张雷，侯杰泰，刘红云.(2004).中介效应检验程序及其应用．心理学报,36(5),614- ",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "Algorithmic Discrimination Causes Less Desire for Moral Punishment than Human Discrimination ",
        "text_level": 1,
        "page_idx": 33
    },
    {
        "type": "text",
        "text": "XU LiyinglYU Feng²PENG Kaiping1 （ $^ { 1 }$ Department of Psychology, School of Social Sciences,Tsinghua University,Beijing 10oo84, China) (² Department of Psychology, School of Philosophy, Wuhan University, Wuhan 430072,China) ",
        "page_idx": 33
    },
    {
        "type": "text",
        "text": "Abstract ",
        "text_level": 1,
        "page_idx": 33
    },
    {
        "type": "text",
        "text": "The application of algorithms is believed to contribute to reducing discrimination in human decision-making,but algorithmic discrimination stillexists in real life.So is there a diffrence between folk responses to human discrimination and algorithmic discrimination? Previous research has found that people's moral outrage at algorithmic discrimination is less than that at human discrimination. Few studies, however, have investigated people's behavioral tendency towards algorithmic discrimination and human discrimination, especially whether there is a difference in their desire for moral punishment. Therefore, the present study aimed at comparing people's desire to punish algorithmic discrimination and human discrimination as wellas finding the underlying mechanism and boundary conditions behind the possible difference. ",
        "page_idx": 33
    },
    {
        "type": "text",
        "text": "To achieve the research objectives, six experiments were conducted, which involved various kinds of discrimination in daily life, including gender discrimination, educational background discrimination, ethnic discrimination and age discrimination.In experiment 1 and 2,participants were randomly assgned to two conditions (discrimination: algorithm vs. human), and their desire for moral punishment was measured. Additionally, the mediating role of free will belief was tested in experiment 2.To demonstrate the robustness of our findings,the underlying mechanism (i.e., free will belief) was further examined in experiment 3 and 4. Experiment 3 was a 2 (discrimination: algorithm vs.human) $\\times 2$ (belief in free will: high vs.low) between-subject design,and experiment 4 was a single-factor (discrimination: human vs. algorithm with free will vs. algorithm without free will) between-subject design. Experiment 5 and 6 were conducted to test the moderating role of anthropomorphism. Specifically, participants'tendency to anthropomorphize was measured in experiment 5,and the anthropomorphism of algorithm was manipulated in experiment 6. ",
        "page_idx": 33
    },
    {
        "type": "text",
        "text": "As predicted, the present research found that compared with human discrimination, people have less desire to punish algorithmic discrimination. And the robustness of this result was demonstrated by the diversity of our stimuli and samples. In addition, we found that free will belief played a mediating role in the efect of discrimination (algorithm vs. human) on the desire to punish. That is to say,the reason why people had less desire to punish when facing algorithm discrimination was that they thought algorithms had les free willthan humans.Finaly, the results also demonstrated the moderating effect of anthropomorphism. ",
        "page_idx": 34
    },
    {
        "type": "text",
        "text": "These results enrich literature regarding algorithm discrimination as wellas moral punishment from the perspective of social psychology. First, this research explored people's behavioral tendency towards algorithmic discrimination by focusing on the desire for moral punishment, which contributes to a better understanding ofpeople's responses to algorithmic discrimination. Second,the results are consistent with previous studies on people's mind perception of artificial intelligence. Third, it adds evidence that free will has a significant impact on moral punishment. ",
        "page_idx": 34
    },
    {
        "type": "text",
        "text": "Key wordsalgorithm, algorithmicdiscrimination， moralpunishment， freewillbelief, anthropomorphism ",
        "page_idx": 34
    },
    {
        "type": "text",
        "text": "附录",
        "text_level": 1,
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "一、自由意志量表（以人类组为例)：",
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "请选择你对以下陈述的同意程度（1强烈反对—7强烈同意)：",
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "1、李原有能力做出不同的选择。",
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "2、李原是有自由意志的。",
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "3、招聘中如何选择完全由李原自己决定。",
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "4、李原在根本上对自己的决定和行动有完全的控制。",
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "5、李原有自由意志，即使他的选择受到外部环境的限制。",
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "二、自由意志信念操纵材料（实验3）",
        "text_level": 1,
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "科学表明自由意志并不存在ByDr.ChrisWellington,Ph.D.克里斯惠灵顿博士",
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "人们的所作所为都是他们大脑中简单物理过程的产物。人们体验到的有意识的想法、记忆、情绪和选择，实际上只不过是一系列的化学作用和电子脉冲。因为科学家能够利用科学法则预测所有的身体反应，因此如果有足够的信息，科学家有一天将能够预测一个人的所有行为。自由意志是一种幻觉。",
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "现代科学现在已经表明，人类和所有其他生物一样受同样的过程支配。从细菌到人类，万物都在化学层面上通过密切相关的过程运行。同样，进化论的观点也证明了所有的植物和动物都是由相同的自然方式形成的。因此，虽然人类的复杂性可能有所不同，但他们的身体和大脑与其他任何东西都没有什么不同。不需要灵魂或自由意志的存在来解释我们的行为。",
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "经验告诉人们可以随自己的意愿行事，所以大多数人认为他们有自由意志。然而，这些欲望和冲动从何而来呢？事实上，人们通常不知道为什么他们会做出许多行为。在许多情况下，人们会为自己的行为方式找出理由，但他们在很大程度上并未意识到驱动他们行为的力量。行动不仅是由有意识的想法决定的，而且是由大脑在人们意识到的情况下处理的一系列信息决定的。这些过程可以分解成化学家和物理学家所描述的同样简单、可预测的过程。虽然人们看起来是有自由意志的，但他们的行为、选择，甚至他们的思想已经被他们的身体、环境和科学规律预先决定了。",
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "科学表明存在自由意志",
        "text_level": 1,
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "ByDr:ChrisWellington,Ph.D. ",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "克里斯惠灵顿博士",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "人们的所作所为大多是他们做出的决定和自由意志的产物。人们通常会控制自己有意识的想法，考虑不同的可能性，审慎思考其自由选择的记忆。这些因素已被证明是影响人们做出选择的主要因素。这些因素也是由个人直接控制的。此外，科学家还不能用科学法则预测人类所有的身体反应。正因为如此，科学家和哲学家们普遍认为，自由意志不是一种幻觉。",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "现代科学现在表明，人脑是已知世界中最复杂的生物。其他一切从细菌到非人类的动物，在大脑和认知水平上都是通过比人脑简单得多的过程来运行的。人类有抽象思维的能力。这意味着人类的思想不再局限于此时此刻，而是可以追溯到遥远的过去，并深入到未来。人们的选择是由这种有意识的抽象思维能力来指导的，因为他们可以考虑未来的后果或过去的错误。因此，在试图解释人类行为时，很有必要考虑自由意志。",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "日常经验告诉人们可以随自己的意愿行事，所以大多数人意识到他们有自由意志。人们通常很清楚自已为什么要做某一特定的行为或做出某一决定。在许多情况下，当人们被要求解释为什么做出某种选择时，他们可以很容易地解释导致这个选择的因素。这是因为一个人所做的任何行为或选择最终都取决于此人的直接意识控制。总而言之，科学已经表明，自由意志是每个人都拥有的东西，是人性的重要组成部分。",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "三、算法组含义解释及举例(实验4、实验6)",
        "text_level": 1,
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "算法（algorithm)，在数学（算学）和计算机科学之中，指一个被定义好的、计算机可施行其指示的有限步骤或次序，常用于计算、数据处理和自动推理。随着人工智能的发展，算法决策越来越多地被用于辅助甚至是替代人的决策，例如使用算法进行信贷审批、人才招聘、犯罪风险评定等等。",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "https://www.merriam-webster.com/dictionary/algorithmhttps://zh.wikipedia.org/zh-cn/%E7%AE%97%E6%B3%95",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "四、拟人化个体差异量表",
        "text_level": 1,
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "你认为以下描述在多大程度上是成立的？请在0（一点也不）到10（非常）中选择：",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "1、用于制造、娱乐和生产过程的科技设备、机器（如汽车、电脑、电视）在多大程度上是有意图的？",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "2、普通的鱼在多大程度上有自由意志？",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "3、普通的山在多大程度上有自由意志？",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "4、一台电视机在多大程度上可以体验情绪？ ",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "5、普通的机器人在多大程度上有意识？",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "6、奶牛在多大程度上是有意图的？",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "7、一辆汽车在多大程度上有自由意志？",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "8、海洋在多大程度上有意识？",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "9、普通的电脑在多大程度上有它自己的心灵？",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "10、一头猎豹在多大程度上可以体验情绪？",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "11、环境在多大程度上可以体验情绪？",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "12、普通的昆虫在多大程度上有它自己的心灵？",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "13、一棵树在多大程度上有它自己的心灵？",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "14、风在多大程度上是有意图的？",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "15、普通的爬行动物在多大程度上有意识？",
        "page_idx": 37
    }
]