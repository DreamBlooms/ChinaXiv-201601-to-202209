[
    {
        "type": "text",
        "text": "融合协同过滤和XGBoost的推荐算法",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "崔岩，祁伟，庞海龙，赵辉(长春工业大学 计算机科学与工程学院，长春 130012)",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "摘要：协同过滤是信息过滤和推荐系统中应用最广泛的技术，但是在数据处理中存在数据稀疏问题，影响推荐算法的准确性。提出融合协同过滤和XGB0ost的推荐算法，根据用户对项目的评价以及项目本身所具备的自身特点，挖掘项目和用户的潜在关系，提高算法的推荐准确性。采用百度深度学习框架PaddlePaddle在 Book-Crossings 数据集上进行实验，实验结果表明，提出的算法和文献中两种算法相比，准确性有显著提升。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "关键词：XGBoost；协同过滤；准确性；推荐系统 中图分类号：TP301.6 doi: 10.19734/j.issn.1001-3695.2018.06.0463 ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Extreme gradient boosting recommendation algorithm with collaborative filtering ",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Cui Yan, Qi Wei, Pang Hailong, Zhao Hui (College of Computer Science & Engineering, Changchun UniversityofTechnology,Changchun l300l2, China) ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Abstract: Collaborative fltering playsan important role inrecommendationsystemand is the most successul and widelyused technology ininformation flteringand information system.However,colaborativefltering hasasparse problem indata processing,whichafectsthe accuracyofthe proposed algorithm.This paper proposed arecommendationalgorithmcombining collaborative filteringand XGBoosttoexplore the potentialrelationshipbetween the projectand theuser basedonthe user's evaluationoftheprojectanditsowncharacteristics.It improvedtherecommendationaccuracyofthe algorithm.Theresultsof experiments on thebook-crosings data setusingthe baidudeeplearing framework paddlepaddlepaddlesshowthat, Compared with the two algorithms in the literature,the accuracy of the proposed algorithm is significantly improved. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Key words:XGBoost; collaborative filtering; accuracy; recommendation system ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "0 引言",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "随着近些年来网络环境的迅速发展，网络信息的覆盖正在遍及本文所需要的各个方面。人们在线获取的数据也越来越丰富，但却导致了数据量急速增长，根据数据统计结果表示，在每分钟时间内，Facebook的活跃用户会在网络上分享大约68.4万比特的信息，Twitter用户则会发出超过10万条，世界上 $90 \\%$ 的数据产生在2010—2012年，到2020年，全球信息总量将会是 2011年的22倍，达到 $3 5 . 2 Z \\mathrm { B } ^ { [ 1 ] }$ 。但其中有很多属于无关冗余数据，这导致了“信息超载[2]（informationoverload)”问题，网络世界被信息所包围，正在从IT(information technology)走向DT（data technology）时代[3]，因此，推荐系统[4]应运而生，成为帮助用户获取有效信息的必要工具，作为一种解决信息量超载的过滤技术，起到了重要的作用。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "在推荐系统发展中，协同过滤[5仍占据着主导位置。协同过滤能够过滤机器难以自动进行内容分析的信息，有效地利用其他相似用户的反馈信息、提高个性化学习的速度。但实际应用中会出现数据稀疏性[9-10]问题、数据增加情况下的扩展性[1I]问题、冷启动[12]问题。数据稀疏性是在用户对项目评价很少时，基于用户的评价所得到的用户间的相似性可能达不到预期效果，最后会影响推荐的准确性，扩展性问题是：在数据量很大时或新加入大量信息后，不能及时找出相似度很高的用户项目关系，从而无法实现实时推荐。冷启动问题是当新用户与新项目加入推荐系统时，因为没有相应的历史数据，无法进行相似度计算，从而无法产生有效推荐。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "针对上述问题，已有许多相关研究。文献[13]提出两阶段联合聚类评分方法，聚类后的矩阵维度远远小于原始矩阵维度，减少计算量的同时又提高了精准度，但算法须依靠评分的权重，预测得到的评分可靠度不高。文献[14]提出了奇异值分解(SVD)解决维度问题，解决了数据量增加情况下的扩展问题，但在数据量很大时十分耗费时间，不利于使用。文献[15]提出了融合社交信息的矩阵分解推荐方法，通过社交信息能够更加准确的挖掘兴趣爱好，并通过好友关系提高了推荐的精准度，在文献[16]中提出了XGBoost[17算法在电子商务商品推荐中的应用,不足在于未能联系用户以往的行为特征，推荐存在缺陷。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "本文为了解决数据的稀疏性提出了一种融合协同过滤和XGBoost的 推 荐 算 法（eXtremeGradientBoostingrecommendation algorithmwith collaborative filtering,XGBCF)通过协同过滤构建用户间的相似矩阵和项目间的相似矩阵计算相似度，根据最近邻关系组成相似集合对，生成训练集，再利用 XGBoost对训练集进行拟合，得出最佳权值和学习率，利用目标函数进行分类,推荐给用户，提高了推荐的准确性。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "1 相关工作",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "1.1协同过滤算法",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "协同过滤（collaborative filteringrecommendation）在信息过滤和信息系统中是一种常用的技术，是集体智慧的一种典型体现，其原理是对用户的历史行为进行分析和挖掘，发现用户的偏好，基于不同的兴趣偏好对用户进行群组划分。最主要的功能为预测和推荐，协同过滤主要分为两类：基于用户的协同过滤算法（userbased collaborative filtering）和基于项目的协同过滤（item-basedcollaborative filtering)，基于用户的协同过滤算法分析了用户的历史行为，找出用户感兴趣的内容或项目，并根据不同用户对相同项目的打分，分析他们的偏好程度，计算相似度，从而在相似用户间进行推荐。基于项目的协同过滤原理和基于用户的协同过滤相似，只是在计算相似度的时候关注的是项目本身，也就是说根据用户对项目的偏好找到相似的项目，其步骤为先计算已评价项目和待预测项目的相似度，并以计算出的相似度作为权重系数，通过权重控制已评价项目的分数，得到待预测项目的预测值。与已评价的进行比较，如果预测值和已评价的较相近便进行组合推荐。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "关于相似度的计算，现有的几种基本方法都是基于向量下的相似度计算，即计算向量之间的距离，距离越近，他们的相似度越大。推荐的情况下，在用户物品偏好的二维矩阵中，本文可以通过将用户对所有物品的偏好作为矢量来计算用户之间的相似度，或者将所有用户对某个项目的偏好作为矢量来计算项目之间的相似度。其常用的相似度包括：皮尔森相关系数[18]（Pearsoncorrelationcoefficient，PCC)，余弦相似性[19]等。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "余弦相似度（cosinesimilarity）计算公式如下：",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\ns i m ( u , \\nu ) = \\frac { \\sum _ { i \\in I } R _ { u , i } \\cdot R _ { \\nu , i } } { \\sqrt { \\sum _ { i \\in I } R _ { u , i } ^ { 2 } } \\cdot \\sqrt { \\sum _ { i \\in I } R _ { \\nu , i } ^ { 2 } } }\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "其中：所求的是用户 $\\mathrm { ~  ~ u ~ }$ 和 $\\mathbf { v }$ 的相似度，I为两个用户都评过分的项目， $r _ { u , i }$ 表示用户 $\\mathrm { ~  ~ u ~ }$ 对项目i的评分， $r _ { \\nu , i }$ 表示的是用户 $\\mathbf { v }$ 对项目i的评分。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "皮尔森相似系数(Pearsoncorrelationcoefficient）定义为",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\ns i m ( u , \\nu ) = \\frac { \\displaystyle \\sum _ { u \\in U } ( R _ { u , i } - \\overline { { R _ { i } } } ) ( R _ { u , \\nu } - \\overline { { R _ { \\nu } } } ) } { \\displaystyle \\sqrt { \\sum _ { u \\in U } ( R _ { u , i } - \\overline { { R _ { i } } } ) ^ { 2 } } \\sqrt { \\sum _ { u \\in U } ( R _ { u , \\nu } - \\overline { { R _ { \\nu } } } ) ^ { 2 } } }\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "其中：U表示的是所有评过分数的用户集合， $\\overline { { R _ { i } } }$ 表示的是对项目i的平均打分， $\\overline { { R _ { j } } }$ 标志的是对项目j的平均打分。皮尔森相关系数用于计算两个用户联系的紧密程度，取值在[-1,1]。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "协同过滤预测评分公式定义为",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\nR _ { \\nu , i } = \\overline { { { r } } } _ { \\nu } + \\frac { \\displaystyle \\sum _ { u \\in U } ( r _ { u , i } - \\overline { { { r } _ { u } } } ) * s i m ( u , \\nu ) } { \\displaystyle \\sum _ { u \\in U } \\lvert s i m ( u , \\nu ) \\rvert }\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "其中： $R _ { \\nu , i }$ 表示用户 $\\mathbf { v }$ 对为评分项目i的预测值，V表示的是最近邻中拥有待评分项i的用户集合。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "Top- $. N$ 算法是一种按照一定规则对数据进行排序的算法，在本文中将本文提出的算法（XGBCF）的结果通过式（3）计算未对项目评分用户的预测评分值，然后把预测值按照降序排列，产生推荐列表，推荐给用户。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "1.2 XGBoost算法",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "XGBoost全称为 extreme gradient Boosting,是华盛顿大学陈天奇博士2014 年在GBDT 算法基础上对Boosting 算法提出的的一种改进，内部决策树使用的是回归树，具有速度快，效果好，能够处理大规模数据，自定义损失函数等一系列特点。它采用了弱分类器的逐次迭代计算，提高分类的精确性。算法相关原理如下：",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "树的复杂性定义为",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\nf _ { t } ( x ) = w _ { q ( x ) } , w \\in R ^ { T } , q \\in R ^ { d } \\to \\{ 1 , 2 , . . . , T \\}\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "其中： $\\mathsf { q }$ 表示的是树的结构， $\\mathbf { w }$ 表示叶子权重部分。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "改进的复杂度函数为",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\n\\Omega ( f _ { t } ) = \\gamma ^ { T } + \\frac { 1 } { 2 } \\lambda \\sum _ { j = 1 } ^ { T } w _ { j } ^ { 2 }\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "其中：T为叶子节点个数， $w _ { j } ^ { 2 }$ 表示的是每个叶子节点上面输出分数的 $\\mathrm { L } _ { 2 }$ 模平方， $\\gamma$ 和在最终的模型公式中控制这部分的比重.这样就可以衡量模型的复杂性，从而有效控制过拟合。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "改写的目标函数：",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\n\\begin{array} { l } { { \\displaystyle O b j ^ { ( t ) } = \\sum _ { i = 1 } ^ { n } [ l ( y _ { i } , \\hat { y } _ { i } ^ { ( t - 1 ) } ) + g _ { i } f _ { t } ( x _ { i } ) } } \\\\ { { \\displaystyle ~ + \\frac { 1 } { 2 } h _ { i } f _ { t } ^ { 2 } ( x _ { i } ) ] + \\Omega ( f _ { t } ) + c o n s \\tan t } } \\end{array}\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "其中：1就是损失函数， $\\Omega$ $( f _ { t } )$ 为正则化项，包含 $\\mathrm { L } _ { 1 } , \\mathrm { L } _ { 2 }$ 正则化，constant为常数项，通过式子可以看出，最终的目标函数依赖于每个数据点的在误差函数上的一阶和二阶导数。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "利用式（6）对目标函数再次改写，其中1被定义为每个叶子节点上面样本集合 $I _ { j } = \\{ i \\vert q ( x _ { i } ) = j \\}$ 。",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\n\\begin{array} { l } { { \\displaystyle O b j ^ { ( t ) } \\cong \\sum _ { i = 1 } ^ { n } [ g _ { i } f _ { t } ( x _ { i } ) + \\frac { 1 } { 2 } h _ { i } f _ { t } ^ { 2 } ( x _ { i } ) ] + \\Omega ( f _ { t } ) } } \\\\ { { \\displaystyle = \\sum _ { j = 1 } ^ { T } [ ( \\sum _ { i \\in I _ { j } } g _ { i } ) w _ { j } + \\frac { 1 } { 2 } ( \\sum _ { i \\in I _ { j } } h _ { i } + \\lambda ) w _ { j } ^ { 2 } ] + \\lambda ^ { T } } } \\end{array}\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "$G _ { j } = \\sum _ { i \\in I _ { j } } g _ { i } \\ , H _ { j } = \\sum _ { i \\in I _ { j } } h _ { i }$ ",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "化简为 （20 $O b j ^ { ( t ) } = \\sum _ { j = 1 } ^ { T } [ G _ { j } w _ { j } + \\frac { 1 } { 2 } ( H _ { j } + \\lambda ) w _ { j } ^ { 2 } ] + \\gamma ^ { T }$ ",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "对 ${ \\boldsymbol w _ { j } }$ 进行求导，令导数为0可以得到：",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\nw _ { j } ^ { \\ast } = \\cdot \\frac { G _ { j } } { H _ { j } + \\lambda }\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "把 ${ \\boldsymbol w _ { j } }$ 最优解代入得到目标函数：",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\nO b j = - \\frac { 1 } { 2 } \\sum _ { j = 1 } ^ { T } \\frac { G _ { j } ^ { 2 } } { H _ { j } + \\lambda } + \\gamma ^ { T }\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "其中：T为叶子节点的个数， $\\lambda$ 和 $\\gamma$ 为比重系数，防止过拟合的产生。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "2 融合协同过滤和XGBoost的推荐算法构建 ",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "2.1算法思想 ",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "因每个用户对项目的评价有限，在构建用户行为矩阵时会存在大量空值，为了解决此问题，本算法根据用户的以往行为，挖掘用户间关系和用户项目间关系，通过已评分项目构建用户对和用户项目对，并分别计算相似度，构建相似矩阵，计算每个用户对其他用户及项目的相似性，对计算结果进行排序，组成最近邻集合，通过协同过滤预测评分公式，得到预测评分，再利用XGBoost算法进行分类，计算出分类错误率，通过权值和学习率的更新，找出分类错误的样本，并重置权重，达到提高算法精准度的效果，最后利用top- $. N$ 生成推荐列表展示给用户。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "2.2 算法相关定义",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "定义1用户集合U,共有 $\\mathfrak { n }$ 个用户，下标表示用户的索引。",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\nU = \\{ u _ { 1 } , u _ { 2 } , . . . . u _ { n } \\}\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "定义2项目集合 $\\mathrm { ~ I ~ }$ ，共有 $\\mathrm { ~ m ~ }$ 个项目，下标表示项目的索引。",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\nI = \\{ I _ { 1 } , I _ { 2 } , . . . . . I _ { m } \\}\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "定义3表1中为项目和特征的交叉， $i f _ { m , n }$ 表示的是第 $\\mathrm { ~ m ~ }$ 个项目的第 $\\mathfrak { n }$ 个特征.",
        "page_idx": 2
    },
    {
        "type": "table",
        "img_path": "images/744d390dcfd2bfee535098fd359226c70098db4a55ac51095995213622eed775.jpg",
        "table_caption": [
            "表1项目特征矩阵ifeature",
            "表3项目评分矩阵"
        ],
        "table_footnote": [],
        "table_body": "<html><body><table><tr><td>项目</td><td>fi</td><td>f</td><td>f</td><td></td><td>fm</td></tr><tr><td>i</td><td>ifi,1</td><td>if1.2</td><td>if1.3</td><td></td><td>if1.n</td></tr><tr><td>i2</td><td>if2.1</td><td>if2.2</td><td>if2.3</td><td></td><td>if2,n</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>in</td><td>ifn1</td><td>ifn.2</td><td>ifn3</td><td>…</td><td>ifm.n</td></tr></table></body></html>",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "定义4用户特征矩阵ufeature表格中 $U _ { p q }$ 为用户和特征的交叉，表示的是第 $\\mathfrak { p }$ 个用户的第 $\\mathsf { q }$ 个特征。",
        "page_idx": 2
    },
    {
        "type": "table",
        "img_path": "images/26bc46260559a4ef18419e1e8372c7d0223245a9b683ff5e542ea189d69b17a0.jpg",
        "table_caption": [
            "Table1 Item feature marixifeature ",
            "表1用户特征矩阵ufeature",
            "Table2User feature marixufeature "
        ],
        "table_footnote": [],
        "table_body": "<html><body><table><tr><td>用户</td><td>fi</td><td>f</td><td>f</td><td></td><td>f</td></tr><tr><td>u1</td><td>uf1,1</td><td>uf1.2</td><td>uf1,3</td><td>：</td><td>uf1.p</td></tr><tr><td>u2</td><td>uf21</td><td>uf2,2</td><td>uf2.3</td><td></td><td>uf2.p</td></tr><tr><td></td><td>：</td><td></td><td></td><td>：</td><td></td></tr><tr><td>uq</td><td>ufa.1</td><td>ufa,2</td><td>ufq.3</td><td></td><td>Ufp.q</td></tr></table></body></html>",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "定义5用户对项目评分矩阵 ${ \\textsc { R } } ,$ 其中 $R _ { p , m }$ 表示的是用户p对项目 $\\mathrm { ~ m ~ }$ 的评分。",
        "page_idx": 2
    },
    {
        "type": "table",
        "img_path": "images/e2a70e180676a0868e56a1a51df2a5df6cac1c00a752d259adfba3b968e89a02.jpg",
        "table_caption": [],
        "table_footnote": [],
        "table_body": "<html><body><table><tr><td colspan=\"5\">Table3 Item scoring marix ifeature</td></tr><tr><td>用户</td><td>i</td><td>i</td><td>i</td><td>im</td></tr><tr><td>u1</td><td>R1,1</td><td>R1.2</td><td>R1,3</td><td>R1,m</td></tr><tr><td>u2</td><td>R2.1</td><td>R2.2</td><td>R2.3</td><td>R2.m</td></tr><tr><td></td><td>…</td><td>…</td><td></td><td></td></tr><tr><td>up</td><td>Rp.1</td><td>Rp.2</td><td>Rp.3</td><td>Rp.m</td></tr></table></body></html>",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "2.3算法描述",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "本算法包括生成训练样本集，XGBoost精准分类处理和生成推荐三个步骤：",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "1)生成训练样本集",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "输入：经过数据清洗的用户特征矩阵ufeature，经过数据清洗的项目特征矩阵ifeature，用户对项目的评分矩阵R，用户集合U，项目集合I。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "输出：训练样本集。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "处理流程：",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "a)在用户一项目的评分矩阵中找出已经评分的项目集合I和已经对项目评过分数的用户集合U。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "b)把上述的I和U 分别拆分成两个为一组的用户对集合$u p a i r = \\{ < u _ { { } _ { m } } , u _ { { } _ { n } } > \\mid u _ { { } _ { m } } , u _ { { } _ { n } } \\in U \\}$ 和项目对集合$i p a i r = \\{ < i _ { a } , i _ { b } > | i _ { a } , i _ { b } \\in I \\}$ 。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "c)找出upair和ipair拆分的数据对在ifeature和ufeature所对应的位置，然后用式(1)计算出用户对相似度 $s i m ( u _ { m } , u _ { n } )$ ，利用式（2）计算项目对相似度 $s i m ( i _ { m } , i _ { n } )$ 。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "d)循环前三个步骤，得到所有用户和所有项目对应相似性，分别构建用户相似度矩 $u s i m ( m , m )$ 和项目相似度矩阵 $i s i m ( n , n )$ 。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "e)计算每个用户在用户相似度矩阵的相似性，对计算结果进行排序，将相似度最高的 $\\mathbf { \\bar { n } }$ 个用户组合成用户最近邻集合$N _ { u } = \\{ ( u _ { 1 } , u _ { 2 } . . . . . u _ { n } ) | u \\in u s i m \\}$ ，同样方式组合项目最近邻集合$N _ { i } = \\{ ( i _ { 1 } , i _ { 2 } . . . . i _ { n } ) | i \\in i s i m \\} \\ .$ 0",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "f)遍历用户对项目的评分矩阵R，选出项目i对应的最近邻集合 $N _ { i }$ 。根据式（3)计算出用户 $\\mathsf { p }$ 对项目 $\\mathfrak { n }$ 的预测评分 $p _ { p , n } ^ { i }$ ，把预测值和原始用户-项目矩阵中的差值记作 $x _ { 1 } ^ { i }$ ，同理选出用户u 对应的最近邻集合 $N _ { u }$ ，利用式（3）计算出用户 $\\mathsf { p }$ 对项目 $\\mathfrak { n }$ 的预测评分 $P _ { p , n } ^ { u }$ ，把预测值和原始用户-项目矩阵中的差值记作$X _ { 2 } ^ { u }$ ，最后把上面得到的差值和 $R _ { u , i }$ 组合成新的数据集$d a t a = \\{ \\{ x _ { 1 } ^ { i } , x _ { 2 } ^ { u } , R _ { u , i } \\} \\vert i \\in I , u \\in U , R _ { u , i } \\in R \\}$ ",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "2)XGBoost分类输入：训练集样本。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "输出：分类结果。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "处理流程：",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "a)将所有的训练样本赋予相同的权重 $\\mathbf { w }$ 。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "b)采用XGBoost算法进行分类，迭代 $\\mathrm { ~ m ~ }$ 次，并用下面的公式计算分类错误率：",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\ne r r _ { m } = \\frac { \\displaystyle \\sum \\omega _ { i } I ( y _ { i } \\neq G _ { m } x _ { i } ) } { \\displaystyle \\sum \\omega _ { i } }\n$$",
        "text_format": "latex",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "其中： $\\omega _ { i }$ 表示第i个样本的权重， $G _ { { \\scriptscriptstyle m } }$ 代表的是第 $\\mathbf { m }$ 个分类器。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "c)更新学习率: ",
        "page_idx": 3
    },
    {
        "type": "equation",
        "text": "$$\n\\alpha _ { m } = \\frac 1 2 \\mathrm { l o g } ( ( 1 - e r r _ { m } ) / e r r _ { m } )\n$$",
        "text_format": "latex",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "这样做的目的是通过剪枝防止过拟合的产生，同时降低了生成树的规模，保证迭代样本空间，在之后的学习率计算中可以通过迭代更新学习率。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "d)反复进行步骤 $\\mathbf { b } ) \\mathbf { c }$ ，得到相应的错误率，然后重置第 $\\mathbf { \\eta } _ { \\mathrm { ~ n ~ } }$ 个样本的权重为 $\\omega _ { 0 } = \\omega _ { i } * e ^ { \\alpha _ { m } * I ( y _ { i } \\ne G _ { m } x _ { i } ) }$ ",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "e)在经过多次迭代后，通过更新学习率和权重系数找出分类错误的样本，并进行权重重置，这样便可以得到更加精确地分类。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "3)生成推荐列表",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "输入：数据集data，用户 $\\mathrm { ~  ~ u ~ }$ 在data 中的数据。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "输出：用户 $\\mathrm { ~  ~ u ~ }$ 的推荐列表。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "a)构建回归树，将数据集以标签的形式作为根节点输入。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "b)根据式（8）所示的目标函数建立XGBoost模型，因为XGBoost有可以自定义损失函数的特点，在这里将损失函数定义为logistic损失函数。",
        "page_idx": 3
    },
    {
        "type": "equation",
        "text": "$$\nl ( y _ { i } , \\hat { y } _ { i } ) = y _ { i } \\ln ( 1 + e ^ { - \\hat { y } _ { i } } ) + ( 1 - y _ { i } ) \\ln ( 1 + e ^ { \\hat { y } _ { i } } )\n$$",
        "text_format": "latex",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "其中 $y _ { i }$ 表示实际值， $\\hat { y } _ { i }$ 标志的是预测值。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "c)对损失函数求二阶偏导数，利用式（10）更新学习率，调整权重参数，代入到式(8)中，得到XGBCF模型。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "d)利用XGBCF模型对用户 $\\mathrm { ~  ~ u ~ }$ 未评分的项目进行预测评分，并利用top-N产生推荐列表反馈给用户使用。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "3 算法验证 ",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "3.1实验数据 ",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "本文采用的数据集是由 Cai-Nicolas Ziegler 提供的 book-crossing[20数据集，数据集由三部分组成，分别为用户信息数据集，图书信息数据集和用户评分数据集，其中用户数据集包括用户id，人口统计信息（位置，年龄)，如表4所示，图书数据集包含由各自的ISBN进行标识。无效信息已从数据集中删除。此外，还提供了一些基于内容的信息（‘书名’‘作者’‘出版日期’‘出版商')，如表5所示，评分数据集包含了1,149,780条评分信息，包含了278.858位用户对271,379本图书的评分，评级（Book-Rating）是明确的，区间从1-10（更高的值表示更高的评价）也就是有更高的兴趣。实验中将数据集的 $7 5 \\%$ 作为训练集， $2 5 \\%$ 作为测试集。",
        "page_idx": 3
    },
    {
        "type": "table",
        "img_path": "images/298dce8b186eeb46ea3a307bd7c6335e7ac27bcf57c4c1963a3366c10c066a5c.jpg",
        "table_caption": [
            "表4用户信息特征示例",
            "Table 4Example of user information characteristics ",
            "表5图书信息特征示例"
        ],
        "table_footnote": [],
        "table_body": "<html><body><table><tr><td>用户id</td><td>年龄</td><td>位置</td></tr><tr><td>1</td><td>18</td><td>Stock california</td></tr><tr><td>2</td><td>51</td><td>Black mountain</td></tr></table></body></html>",
        "page_idx": 3
    },
    {
        "type": "table",
        "img_path": "images/35e9031b9122ae53f9186388aa8463e9ba23b2546715a39fc563a292cff63feb.jpg",
        "table_caption": [
            "Table 5Example of book information characteristics "
        ],
        "table_footnote": [],
        "table_body": "<html><body><table><tr><td>书名</td><td>作者</td><td>出版年份</td><td>出版商</td></tr><tr><td>Classical</td><td>Mark p.o.morford</td><td>2002</td><td>Oxford university</td></tr><tr><td>mythology Decision in</td><td>Richard bruce</td><td></td><td></td></tr><tr><td>Normandy</td><td>wright</td><td>2001</td><td>HarperFlamingo canada</td></tr><tr><td>More Cunning T</td><td>Amy Tan</td><td>2005</td><td>Berkley publish group</td></tr></table></body></html>",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "3.2 度量标准",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "本文实验采用平均绝对误差（mean absolute error,MAE）度量分类准确性,MAE在评分区间上做了归一化处理，定义如下：计算结果越小，预测越精准，推荐效果越好。",
        "page_idx": 3
    },
    {
        "type": "equation",
        "text": "$$\n\\ M A E = { \\frac { 1 } { \\mid E ^ { p } \\mid } } \\sum _ { ( u , a ) \\in E ^ { p } } \\mid r _ { u a } - r _ { u a } ^ { \\prime } \\mid\n$$",
        "text_format": "latex",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "其中： $r _ { u a }$ 表示用户 $\\mathrm { ~  ~ u ~ }$ 对商品a的真是评分， $r _ { u a } ^ { \\prime }$ 表示的是用户 $\\mathrm { ~  ~ u ~ }$ 对商品a的预测评分， $E ^ { \\dprime }$ 表示的是测试集。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "3.3 实验结果与分析",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "因实验中不同参数会影响算法实验效果，所以先通过拟合数据集来确定一系列最优参数，再进行算法的比较，上文已经提及，本文的用户间相似度由皮尔逊相关系数计算，项目间相似度由修正的余弦函数相似性计算。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "1)学习率计算",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "学习率控制算法损失梯度调整权值的速度，过小的学习率会导致收敛过慢，而过大又会导致代价函数动荡，在这里让学习率在0.1\\~1变化，通过实验图像（1）可以看出，在学习率α$\\scriptstyle = 0 . 3$ 时，平均绝对误差（MAE）达到全局最小值，且不再随着学习率的增长而变化。",
        "page_idx": 3
    },
    {
        "type": "image",
        "img_path": "images/06e18e7a73ce0d6404a8d812051e7c4e92342a3eae3e3a894571eeca79de6261.jpg",
        "img_caption": [
            "图1学习率对平均绝对误差的影响",
            "Fig.1Influence of learning rate on mean absolute error "
        ],
        "img_footnote": [],
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "2)最近邻数",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "最近邻数是影响推荐精准度的关键因素，本文已求出最佳学习率，在这里固定学习率 $\\mathrm { ~ a ~ } { = } 0 . 3$ ，让最近邻数在10-200之间变化，通过实验求出最佳最近邻数，根据图2所示，随着用户最近邻数的增加，本文提出的融合算法的平均绝对误差逐渐减小，推荐精度上升，在最近邻数 $k { = } 1 2 5$ 时达到全局最小值并不再变化，如图3所示，最近邻数 $\\mathbf { k }$ 在10\\~75区间变化时，XGBCF的平均绝对误差震荡，随后增大 $\\mathbf { k }$ 值，平均绝对误差（MAE)持续减小，推荐精度上升，项目最近邻数 $k { = } 1 2 5$ 时，XGBCF的MAE达到最小，且不再发生变化，推荐精准率保持不变。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "因此，针对于本文算法（XGBCF)，分别设置用户最近邻数为125，项目最近邻数为125，学习率 $\\mathrm { ~ a ~ } { = } 0 . 3$ ，进行实验。",
        "page_idx": 4
    },
    {
        "type": "image",
        "img_path": "images/b8d9c8491740a1f3d6cd9768b46592e2fba3ba9553b5c3dd7d6327e238ab5dd5.jpg",
        "img_caption": [
            "图2用户近邻对平均绝对误差的影响"
        ],
        "img_footnote": [],
        "page_idx": 4
    },
    {
        "type": "image",
        "img_path": "images/d7008dca3d837a538bd8a990c7d9959d526a621a6e47276658e53efcbba98e6a.jpg",
        "img_caption": [
            "Fig.2Influence of user neighbour on mean absolute error ",
            "图3项目近邻对平均绝对误差的影响"
        ],
        "img_footnote": [],
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "3)算法分析及对比",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "本文提出的算法（XGBCF）因加入了决策树，在构建算法时便对用户以及项目进行了初步分类，减少了后续的分类过程，在拟合过程中能够求出最优参数，达到了更精确的分类，推荐准确性也随之提高，将本文算法与文献[13]和文献[14]算法进行对比，根据图像（4）可以看出，本文提出的融合协同过滤和XGBoost的推荐算法的平均绝对误差（MAE）小于文献中提到的算法，可知本文提出的推荐算法准确性较文献中两个算法算法有显著提高。",
        "page_idx": 4
    },
    {
        "type": "image",
        "img_path": "images/0d93050eadd703c87d71b277a3cd044b8afbf1c2a2ad5353d465030696cddd4d.jpg",
        "img_caption": [
            "Fig.3Influence of item neighbour on mean absolute error ",
            "图4算法结果对比",
            "Fig.4Comparison of algorithm results "
        ],
        "img_footnote": [],
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "4 结束语",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "本文提出融合协同过滤和XGBoost的推荐算法，通过构建用户间的相似矩阵和项目间的相似矩阵计算相似度，根据最近邻关系组成相似集合对，生成训练集，再利用XGBoost对训练集进行拟合，得出最佳权值和学习率，利用目标函数进行分类。最后生成推荐列表推送给用户，本文算法克服了因数据稀疏导致的推荐准确性不足的现象，通过实验验证准确性较传统协同过滤有显著提高，下一步的工作将继续基于推荐系统的特征提取和安全问题进行进一步研究。",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "参考文献：   \n[1]Gantz J,Reinsel D.The digital universe in 202O:Big data,bigger digital shadows，and biggest growth in the far east.[EB/OL]. (2013-02) https://www.emc.com/collateral/analyst-reports/idc-digital-universeunited-states. pdf.   \n[2]Meng Xiangwu, Hu Xun, Wang Licai,et al. Mobile recommender systems and their applications [J]. Journal of Software,2013,24(1): 91-108.   \n[3]连玉明．人类社会从IT时代到DT时代[J].商业文化,2016(11):66- 69.(Lian Yuming. Human society from IT era to DTera[J].business culture, 2016 (11): 66-69.)   \n[4]Milicevic A K, Nanopoulos A Ivanovic,M. Social tagging in recommender systems:a survey of the state-of-the-art and possible extensions [J]. Artificial IntelligenceReview,2010,33 (3):187-209.   \n[5]Patil VA,RaghaL. Comparing performance of collaborative filtering algorithms [C]// Proc of International Conference on Communication, Information& Computing Technology.2012:1-6.   \n[6] 王成，朱志刚，张玉侠，等．基于用户的协同过滤算法的推荐效率和个 性化改进[J].小型微型计算机系统,2016,37(3):428-432.(Wang Cheng, Zhu Zhigang, Zhang Yuxia,et al. Recommendation efficiency and personalized improvement ofuser-based collaborative filtering algorithm [J]. Jourmal of Chinese Computer Systems,2016,37(3): 428-432.)   \n[7]马宏伟，张光卫，李鹏．协同过滤推荐算法综述[J].小型微型计算机 系统,2009,30(7):1282-1288.(Ma Hongwei, Zhang Guangwei,Li Peng. Collaborative filtering recommendation algorithm [J]. Journal of Chinese Computer Systems,2009,30 (07): 1282-1288.)   \n[8] 刘建国，周涛，郭强，等．个性化推荐系统评价方法综述[J].复杂系 统与复杂性科学,2009,6(3):1-10.(Liu Jianguo,Zhou Tao,Guo Qiang,et al.Review of individualized recommendation system evaluation methods [J]. Complex Systems and Complexity Sciences,20o9,6 (3):1-10.)   \n[9]Yang Diyi,Chen Tianqi,Zhang Weinan,et al.Localimplicit feedback mining for music recommendation [C]// Proc of the 6th ACM Conference on Recommender Systems.New New ork:ACMPress,2012: 91-98.   \n[10] Oh K J,Lee WJ,Lim CG,et al. Personalized newsrecommendation using classified keywords to capture user preference [C]// Proc of the 16th International Conference on Advanced Communication Technology. Piscataway,NJ: IEEE Press,2014: 1283-1287.   \n[11]李聪．电子商务协同过滤可扩展性研究综述[J].现代图书情报技术， 2010(11):37-44.(Li Cong. Summary of research on scalability of collaborative filtering in electronic commerce [J].Modern Library and Information Technology,2010 (11): 37-44.)   \n[12]孙小华．协同过滤系统的稀疏性与冷启动问题研究[D].杭州：浙江大 学,2005.(Sun Xiaohua.The sparsity and cold start problem of collaborative filtering system [D]. Hangzhou: Zhejiang University,2005.)   \n[13]吴湖，王永吉，王哲，等．两阶段联合聚类协同过滤算法[J].软件学 报,2010,21(5):1042-1054.(Wuhu,Wang Yongji,Wang Zhe,etal. Twostage joint clustering collaborative filtering algorithm [J]. Journal of Software,2010,21(5): 1042-1054.)   \n[14] VozalisMG,Margaritis KG.Applying SVD on item-based filtering [C]// Proc of International Conference on Intelligent Systems Design and Applications.Washington DC: IEEE Computer Society,2005: 464-469.   \n[15]刘华锋，景丽萍，于剑．融合社交信息的矩阵分解推荐方法研究综述 [J]．软件学报,2018,29 (2): 340-362.(Liu Huafeng,Jing Liping,Yu Jian. A review of matrix factorization recommendation methods for integrating social information[J].Journal of Software,2018,29(2): 340-362.) ",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "[16]张昊，纪宏超，张红宇.XGBoOst 算法在电子商务商品推荐中的应用",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "[J]．物联网技术,2017,7(2):102-104.(Zhang Hao,Ji Hongchao,Zhang Hongyu.Application of XGBoost algorithm in e-business commodity recommendation [J].Internet of Things Technologies,2017,7(2):102-104.) [17] Chen Tianqi,Carlos Guesintr. XGBoost:a scalable tree boosting system [C]//Proc of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York:ACM,2016:785-794. [18]Herlocker J,Konstan J,Borchers A,et al.An algorithmic framework for performing collaborative filtering [C]// Proc of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. New York: ACM Press,1999: 230-237. [19] Saltong.The SMART retrieval system-experiments in automatic document processing[M]. Englewood Cliffs,New Jersey:Prentice Hall Inc,1971. [20] GroupLens [EB/OL]. http://www. grouplens.org/. ",
        "page_idx": 5
    }
]