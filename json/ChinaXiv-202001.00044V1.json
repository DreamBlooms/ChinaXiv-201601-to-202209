[
    {
        "type": "text",
        "text": "基于Spark的SKA1-MID自校准管线分布计算实现",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "戴伟1 汪森1李秋虹²邓辉³梅盈³王锋13\\*1.昆明理工大学云南省计算机技术应用重点实验室，云南昆明，6500512.复旦大学，上海，2100003.广州大学天体物理中心，广东广州，510006",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "摘要 ",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "SKA 科学数据处理产生的数据超出了所有已存在的分布式处理系统的处理能力，如何实现一个分布式执行框架是当前科学数据处理的一个重要研究内容。Spark 是非常成熟的一个商业框架，在互联网应用中被广泛应用，本文根据 SKA项目进展要求，重点研究了如何将算法参考库(ARL)中的部分管线移植到 Spark上执行。本文对部分实现过程进行了分析讨论，给出了相应的任务流程实现。最终结果表明，移植后代码生成结果符合预期，Spark能够满足部分数据分布式数据的要求，但迫切需要解决自身存在的一系列问题。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "关键词：分布计算管线，算法参考库-ARL，分布数据处理",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "中图分类号：TP3",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "一、前言",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "为了进一步开展当前重大科学问题如暗物质和暗能量、黑洞和致密天体、宇宙起源、天体起源以及宇宙生命起源等研究工作的需要，平方公里阵（Square Kilometre Array,SKA）项目[1，2被提出，并成为国际上即将建造的最大综合孔径射电望远镜[3]，得到全球天文学家的重点关注。SKA建在澳大利亚、南非及南部非洲8个国家的无线电宁静区，其接收面积可达1平方公里，频率覆盖50MHz-20GHz。SKA作为下一代射电望远镜，具有极高的灵敏度（比JVLA灵敏度提高50倍,搜寻速度提高10000倍），以千公里的基线获得极高的空间分辨率，以纳秒级的采样获得精细的时间结构，以 $1 0 mathsf { P b } / \\mathsf { s }$ 的速率产生超越全球互联网总量的数据。以宽视场、多波束、高动态、高分辨和大数据为核心概念的SKA将颠覆射电天文学的传统研究手段，给天文学研究带来革命性全新的理念。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "SKA高分辨率、高灵敏度、高动态范围和宽视场等新特性，给SKA数据处理特别是工业界带来了前所未有的挑战。SKA的巨大规模和复杂程度远远超出了现有射电天文望远镜阵列，全规模运行的 SKA产生的海量数据需要10亿亿次/秒处理能力，是目前世界上最快的超级计算机神威太湖之光处理能力（0.9亿亿次/秒）的10倍。考虑到计算效率和软件执行效率（目前天文软件在超算平台上的执行效率普遍在 $10 \\%$ 甚至更低），实际需求将大大超出这个理论估算[4]。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "为了充分利用计算资源，确保数据处理流程的可靠性，近5年来，SKA的科学数据处理器（SDP）一直在研究与测试执行框架(Execution Framework)技术，以期找到满足未来发展要求，性能突出的执行框架技术。这其中，除了本文作者所在项目组参与的DALiuGE等相关工作[5,6]以外，也一直在研讨商用执行框架如 Spark[7,8]、DASK[9]的可用性。本文的工作，正是针对这一方面的工作，细致讨论了SPARK执行框架在未来SKA 科学数据处理",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "中的可用性。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "二、研究动机与需求",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "2.1研究动机",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "Spark 于2009 年诞生于加州大学伯克利分校AMPLab。已经成为Apache 软件基金会旗下的顶级开源项目。相对于MapReduce上的批量计算、迭代型计算以及基于Hive的SQL查询，Spark 可以带来上百倍的性能提升。目前 Spark 的生态系统日趋完善，Spark SQL的发布、Hive on Spark项目的启动以及大量大数据公司对 Spark 全栈的支持，让Spark 的数据分析范式更加丰富。Spark 与 Hadoop 的 MapReduce 计算框架类似，但相对MapReduce 而言，Spark 特点更为突出，如其具有可伸缩、基于内存计算等特性，可以直接读写Hadoop上任何格式数据，在进行批处理时更加高效，延迟更低。目前已经成为轻量级大数据快速处理的统一平台。这其中，弹性分布式数据集(Resilient Distributed Datasets,RDD)是 Spark的核心，RDD 是一种分布式的内存抽象，表示一个只读的记录分区的集合，",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "特别需要关注的是，Spark 是基于内存计算的大数据并行计算框架，提高了在大数据环境下数据处理的实时性，同时保证了高容错性和高可伸缩性，允许用户将Spark 部署在大量廉价硬件之上，形成集群。这对于当前 SKA科学数据处理来说，这样基于全内存与廉价集群的方式非常有吸引力。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "算法参考库(ARL)是由射电天文科学家TimCornwelI领头开发的射电干涉阵数据处理算法验证库，用以为后续 SKA的数据处理提供算法验证。目前，ARL基于Python 语言，已经实现了射电干涉阵处理的主要算法，全部程序开源，供射电干涉阵数据处理参考使用。自2018年SKA完成主要工作包的关键设计评估，进入桥接阶段后，ARL已经成为系统学习、研究SKA数据处理的基础算法参考库。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "针对 SKA一期中频阵可见度校准问题,当前的ARL中,实现了一个全串行的MID1 ICAL管线，分为预测、校准、反馈、去卷积四个部分。MID1ICAL管线的特点如下：",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "(1）逻辑任务同时具有数据密集型和计算密集型的特性；  \n(2）逻辑任务之间存在数据依赖，且任务之间通讯量巨大；  \n(3）需要多次迭代完成，并且两次迭代之间数据需要大量更新；  \n(4）现有存储条件无法长时间保留原始数据，需要在一个观测周期内完成管线的执行。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "为了满足SKA后续建设工作，如何将这样的串行代码移植到分布计算框架下，并分析其实现方法和性能变化，深入了解不同的算法在分布计算框架下的实现方式与性能评价，对于后续开展SKA科学数据处理有重要的作用，这也正是SKA桥接阶段的工作重点，需求非常迫切。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "2.2处理需求",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "SKA1中频有197个天线，最大基线长度是120公里。SKA1低频有130000个天线，最长基线长度40公里。预计SKA1的数据注入速度约为2TB/s。为进行实验与性能分析，本文中以SKA中频天线设计指标为基础，定义基线数19306个，81.92个通道，每个通道宽度800MHz，4个极化以及36个采样时间。总计算任务28800个。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "在未来的系统部署中，成像管线（Imaging Pipeline）和非成像管线(Non-ImagingPipeline)是其中的2个重点。其中成像管线将包括可见度函数接收、可见度函数预处理、实时校准、快速成像、瞬变源候选体检测、数据缓冲等多个部分。非成像管线将包括接收脉冲星守时特性文件、脉冲星候选体接收、瞬变观测缓冲、脉冲星守时处理等各个部分。从当前SKA的建设来看，这些管线的研制是整个数据处理系统的核心。本文讨论的管线，是实时",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "校准管线的一个关键部分。",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "三、软件实现与关键技术",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "3.1代码基本流程",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "图1给出了ICAL中的管线单一通道对应的逻辑任务，将这样的逻辑任务由串行转为分布计算，最关键的是将可以原来紧耦合的功能，转变为松散耦合的模块。我们重点说明Reppre_ifft和Degrid，以及Pharotpre_dft_sumvis两个功能部分。",
        "page_idx": 2
    },
    {
        "type": "image",
        "img_path": "images/8d80767c322f7ad05fcbbed18203db523697f65f13be3c3ecb563aaaa203345a.jpg",
        "img_caption": [
            "图1.MID1ICAL管线单一通道对应的逻辑任务，括号内是需要处理的数据量 Figure 1. The logical diagram of MID1 ICAL Pipeline with single channel. The data in the parentheses shows the amount of data "
        ],
        "img_footnote": [],
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "3.1.1Reppre_ifft和Degrid代码实现 ",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "Reppre_ifft&Degrid 阶段是根据局部天空模型，预测观测天空的可见数据，开发中利用了如下ARL函数。对这一部分并行的实现方法是对频段、分片、时间片等进行数据的分片。最终对于MID1ICAL管线，我们采用了以单个频段（不同频段可以并行处理）分拆任务的方法实现分布并行计算。",
        "page_idx": 2
    },
    {
        "type": "image",
        "img_path": "images/f6f6fced100b102335c10cb6c98b3bf5cecc8e2914c25455b36b51cabbab3c57.jpg",
        "img_caption": [
            "图2Degkerupd_deg 阶段任务依赖关系图Figure 2.The dependency diagram in Degkerupd_deg phase"
        ],
        "img_footnote": [],
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "Reppre_ft阶段主要是对 Image 类和 Skycomponent 的处理，整个过程的输入是Image 和 Skycomponent，输出是Image，并送入下个阶段。代码基本调用过程包括：",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "(1) arl/skycomponent/operations/insert_skycomponent: 将 skycomponent 中的信息按照nchan 和 npol 两个轴插入到 Image，关联函数包括：insert_function_sinc,insert_function__L,insert_function_pswf，insert_function_array。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "(2) arl/fourier_transforms/fft_support/fft:对 Image 进行傅里叶变换(3)arl/image/operations/reproject_image:将切片后的 Image 按照新的 wcs 进行重投影。(4) arl/image/iterators/raster_iter: Image 的切片函数",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "Degrid 阶段主要是对图像中的数据进行卷积，具体卷积的过程和可见度数据中的uvw等属性相关。并将结果放入本来为空的Visibility类的 Data属性中。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "在卷积之前，image 先被padding 到切片之前的大小，即在它的周围填充0。然后整个矩阵再和前一步在get_kernelist中得到的 griding correction function做一个点对点的乘法，对得到的结果再做一个fft，就得到了通道化的 image，这个通道化的image 接下来就将被卷积。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "在分布执行后，最终用以下方法合并 reppre_ifft和degrid 任务。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "sc.parallelize(initset).flatMap(i $\\ x = >$ reppre_ift_degrid_kernel(ix,broads_input_telescop :_data,broadcast_Ism)) ",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "这里initset 是六元组(beam,major_loop,frequency,time,facet,polarisation)。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "2.1.1.2Pharotpre_dft_sumvis ",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "为了避免 RDD Pharotpre_dft_sumvis 的一个<key,value>对过大，我们将一个 item 中的时间分片个数由 120 减为10．这样 RDD Pharotpre_dft_sumvis 的每一个<key,value>对中包括20个频率的10个时间片。图3给出了任务依赖关系图。",
        "page_idx": 3
    },
    {
        "type": "image",
        "img_path": "images/84114bea394b6c45110cfdef0493288890d680446ffcefbaacffce53eec92b95.jpg",
        "img_caption": [],
        "img_footnote": [],
        "page_idx": 3
    },
    {
        "type": "image",
        "img_path": "images/16da5be780734202d716b90861c6a91a68179675c6c51df33eb3d43aa891a200.jpg",
        "img_caption": [
            "图3．Timeslots 阶段任务依赖关系图Figure 3.The dependency diagram in Timeslots phase",
            "图4．grikerupd_rep 阶段任务依赖关系图 Figure 4.The dependency diagram in grikerupd_rep phase. "
        ],
        "img_footnote": [],
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "SKA管线的每个任务IO大小以及计算量都是确定的。对于IO，输入、输出以及中间数据大小都是确定的，准确计算出每个任务具体的输入输出，以及准确计算出每个任务的计算量对分布式计算的任务调度具有指导意义。管线数据建模的依据是对每一个管线中的逻辑任务，通过分析所采用的算法的复杂度，并且计算输入输出的大小。",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "四、系统部署与测试",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "4.1环境配置",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "在测试中我们采用三套不同配置的集群作为测试环境，集群1包括1个节点，该节点配备1.5 TB内存，CPU 为80 核，每个核主频为2.2GHZ.。集群2包括4个节点，每个节点配备 64 GB 内存，CPU 为8核，每个核主频为1.8 GHZ。软件系统中 Spark 的版本为 2.0，JDK版本为1.8。",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "4.2 性能测试 ",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "在上述测试互不干涉中，我们分别对单机串行程序和基于Spark的程序进行了测试，串行程序完全是在集群1的高配环境中完成的，最终的执行时间见图4所示。",
        "page_idx": 4
    },
    {
        "type": "image",
        "img_path": "images/10ccc7eee240d3be1a1af41c88717e01d1bbe239dacd088e4ba0a669afd3f232.jpg",
        "img_caption": [
            "图4性能对比示意图，在3个进程数下执行的时间对比，Y轴单位为秒 Figure 4. The contrast diagram of execution time elapse with 3 different process number, The unit of Y axis is second. "
        ],
        "img_footnote": [],
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "五、结论与未来工作",
        "text_level": 1,
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "Spark 是当前工业界最流行的分布式执行框架之一。实验表明，基于 Spark 构建 SKA的分布式执行框架是有可能性的，但Spark存在一些很实际的困难，具体说明如下：",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "1: Spark考虑更多的是数据密集型，它的任务调度和资源管理目前只支持CPU，需要更改其任务调度和资源管理代码来支持混合计算任务的调度。我们在研究中发现，Spark 性能瓶颈在于数据的连接操作，Spark 的\"cogroup\"需要对几个大的数据集进行排序操作，产生大量的节点通讯。另外RDD 链过长，内存不能及时释放，Spark 内存不足时，数据需要写到磁盘，序列化与反序列化耗费大量时间。Spark cogroup 和 groupByKeys 需要排序操作，会耗费大量内存。从这个方面来看，Spark要满足SKA的建设要求存在较多待改进的地方。在未来可以值得在如下方面继续进行性能优化",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "1）增大内存。Spark 内存不足时，数据需要写到磁盘，序列化与反序列化耗费大量时间。Spark 的 cogroup 操作需要内存排序，耗费内存资源。",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "2）利用分布式缓存系统替换Cogroup 操作；",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "3）利用分布式缓存系统存储部分RDD 的内容，打破长RDD链，及时释放内存资源；",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "4）利用 Spark 的 Partitioning 操作代替 cogroup,Partitioning 可以做到数据重组。同时设计分区函数，较少join操作。根据射电数据处理的特点，在预测阶段，设计根据频率的分区函数，需要将同一频段的可见度数据聚集在一起，按照频段进行分区，可以避免join操作。在去卷积阶段，设计根据分片的分区函数，避免join操作。",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "2: Spark的 shuffle 性能存在严重缺陷，Shuffle 是MapReduce 框架中的一个特定的phase(分阶段）,介于Map phase 和 Reduce phase 之间,当Map 的输出结果要被 Reduce使用时，输出结果需要按key哈希，并且分发到每一个Reducer上去,这个过程就是shuffle。由于shuffle 涉及到了磁盘的读写和网络的传输，因此shuffle 性能的高低直接影响到了整个程序的运行效率。针对天文海量数据处理这样的要求，Spark 的 shuffle 性能显然满足不了要求。我们拟采用内存数据库来代替 shufle 的相关操作，并可以进一步提高 Spark 的并行计算性能。这样的工作是后续研究的重点。",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "参考文献：",
        "text_level": 1,
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "[1]Carill C, Rawlings S. Science with the Square Kilometer Array: motivation, key science projects, standards and assumptions [J]. arXiv preprint astro-ph/0409274,2004, [2]Dewdney P, Lazio T, Hall P, et al. The square kilometer array (SKA) radio telescope: Progress and technical directions [J]. Radio Science Bulletin,20o8,326(4-19. ",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "[3]Staveley-Smith L. The Square Kilometre Array[J]. Australasian Science,2009, [4]Broekema P C, Nieuwpoort R VV, Bal H E. ExaScale high performance computing in the square kilometer array; proceedings of the The Workshop on High-Performance Computing for Astronomy DATE,F,2012 [C]. ",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "[5]赖铖，梅盈，邓辉,etal.MUSER可见度数据积分方法与实现[J].天文研究与技术，v.15;No.57(1): 81-9.",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "[6]于晓雨，邓辉，梅盈,etal．宽视场成像网格化算法中w-plane 最优经验值研究[J].天文研究与技术,2019,16(2):218-24.",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "[7]Zaharia M, Chowdhury M,Franklin M J,et al. Spark: Cluster computing with working sets [J]. HotCloud, 2010,10(10-10): 95. ",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "[8]Spark A.Apache Spark: Lightning-fast cluster computing [M]. 2015. ",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "[9]Rocklin M. Dask: Parallel computation with blocked algorithms and task scheduling;   \nproceedings of the Proceedings of the 14th python in science conference,F,2015 [C].   \nCiteseer. ",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "Implementation of SKA1-MID self-calibrating pipeline based on Spark ",
        "text_level": 1,
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "Dai Wei1 Wang Sen1 Li Qiuhong² Deng Hui3 Mei Ying³ Wang Feng 123 \\* ",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "1. Yunnan Key Laboratory of Computer Technology Application, Kunming University of Science and Technology, Kunming, Yunnan, 650051 2.Fudan University, Shanghai, 210000 3.Astrophysics Center of Guangzhou University, Guangzhou 510o06, China ",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Abstract ",
        "text_level": 1,
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "The amount of the scientific data generated by the SKA exceeds the processing capabilities of all existing distributed processing systems. How to implement a distributed execution framework is an important research issue of scientific data processing. Based on Spark framework,oen of the the most mature execution frameworks, this study attempts to systematically analyze how to migrate iCal pipelines in the Algorithm Reference Library (ARL) to Spark.We analyze and discusses the implementation procedure and present the corresponding task flow implementation.The final experiments show that the results of the iCAL upon Spark is correct. In summary, Spark could meet the requirements of distributed data for certain data.The limitations of Spark itself severely restrict its application in SKA. ",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Keywords: Distributed Pipeline, Spark, ARL，Distributed data processing ",
        "page_idx": 7
    }
]