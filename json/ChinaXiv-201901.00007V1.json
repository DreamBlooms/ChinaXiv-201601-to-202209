[
    {
        "type": "text",
        "text": "基于自适应权重的遮挡信息立体匹配算法",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "张雅妮1，刁勤晴1，朱凌云 2\\*",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "(1．重庆理工大学 计算机科学与工程学院，重庆 400054;2.重庆理工大学两江国际学院，重庆 401135)",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "摘要：针对传统局部立体匹配算法在深度不连续区域误匹配率高的问题，提出一种基于自适应权重的遮挡信息立体匹配算法。首先，采用左右一致性检测算法检测参考图像与目标图像的遮挡区域；然后利用遮挡信息，在代价聚合阶段降低遮挡区域像素点所占权重，在视差优化阶段采用扫描线传播方式选择水平方向最近点填充遮挡区域的视差；最后，根据Middlebury数据集提供的标准视差图为视差结果计算误匹配率。实验结果表明，基于自适应权重的遮挡信息匹配算法相对于自适应权重算法误匹配率降低了 $1 6 \\%$ ，并解决了局部立体匹配算法在深度不连续区域误匹配率高的问题，提高了算法的匹配精确性。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "关键词：立体匹配；自适应权重；遮挡检测；代价聚合；视差优化 中图分类号：TP391.41 doi:10.19734/j.issn.1001-3695.2018.08.0669 ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Occlusion information stereo matching approach based on adaptive weight ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Zhang Yani1,Diao Qinqing1, Zhu Lingyun2† (1.College of Computer Science&Engineering，Chongqing Universityof Technology，Chongqing 40o054，China;2. Liangjiang International College,Chongqing University ofTechnology, Chongqing 401135,China) ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Abstract:Aiming atthe high mismatching rateof traditional local stereo matching algorithm atthedepth discontinuities, this paper proposed an oclusion information stereo matching approach based on adaptiveweight.Firstly，left-right consistency check algorithm detected the occlusion area of the reference image and the target image.Then,this paper utilized occlusion information toreduce the weight of pixels in theocclusion area at the processofcost aggregation,and scanline propagation flledocclusion pixels with horizontally nearest points inthedisparityrefinementstage.Finally,the mismatching rateof disparitymap was calculated acording tothe Middleburystandard image dataset.Theexperimental results show that compared with adaptive support weight approach,the occlusion information stereo matching approach based on adaptive weight decreases the mismatching rate by $1 6 \\%$ . Meanwhile,the proposed algorithm not only has lower mismatching rate in the depth discontinuous region, but also improves the accuracy of algorithm matching. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Key words: stereo correspondence; adaptive weight; occlusion detection; cost aggregation; disparity refinement ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "0 引言",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "立体匹配是通过两台平行放置、参数相同的摄像机从不同视角拍摄同一场景得到的两幅图像计算视差图的过程。Scharstein与Szeliski对立体匹配算法做了详尽的研究，并将其分为四个步骤：匹配代价计算、代价聚合、视差计算以及视差优化。全局立体匹配[2是在整幅立体图像对上进行视差优化，最小化能量函数计算视差。局部立体匹配[34是对支持窗口内的像素点进行代价聚合，采用简单的WTA(winnertake alI)视差选择策略计算视差。两种立体匹配算法都包含一个假设[5]，即场景是分段平滑的。局部立体匹配算法假设支持窗口内的场景是平滑的，而全局立体匹配算法则直接基于平滑性假设进行建模。然而，该假设在实际生活中通常是不合理的，在大多数物体的边缘部分，深度是不连续的。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "深度不连续区域通常伴随着遮挡问题的出现。在双目立体视觉系统中，遮挡现象[的出现主要是由于拍摄视角的不同，距离摄像头较近的前景区域将距离摄像头较远的背景区域的部分像素点所遮挡，使背景区域被遮挡的像素点仅在立体图像对的一幅图中成像。由于遮挡问题的非双目可见性，许多算法都将遮挡恢复当作是一个附属问题不处理或者在视差优化阶段做简单处理。然而，要想得到更加精确的深度图像，对遮挡区域的处理是必不可少的。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "遮挡处理的方式通常分为两种。第一种方式是在视差优化阶段直接对遮挡区域的像素点进行检测与恢复，常见的视差优化方法有左右一致性检测 LRC(left right consistency)[7]、亚像素插值[8]、加权中值滤波[9]、图像分割平面填充[10]等。陆军等人[1提出一种新的视差优化插值算法，采用左右一致性遮挡检测算法检测遮挡区域，利用颜色与距离相似性进行插值计算，提高遮挡估计的效果；Ye等人[I2]提出一种多步视差优化的遮挡处理框架，将异常值分为最左侧遮挡、非边界遮挡、以及错误匹配三类，依据不同策略对异常值分别进行恢复，并提出一种基于顺序的表面决策方法应对背景复杂或者存在多个背景区域的情况。第二种方式是通过改进匹配算法使其对遮挡问题具有好的鲁棒性。如周旺尉等人[13]提出一种自适应权重Census变换立体匹配算法，在Census变换阶段计算灰度差区别对待窗口内的像素点，并在代价聚合阶段引入自适应权重改变聚合窗口大小，提高了算法在深度不连续区域的匹配效果。事实上，在匹配过程中，由于遮挡区域的非双目可见性，其匹配代价远高于非遮挡区域像素点的匹配代价，会影响非遮挡区域像素点的匹配结果。将遮挡信息与匹配过程融合，在匹配过程中降低遮挡区域像素点对非遮挡区域像素点的影响，会得到更好的匹配效果。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "本文是在经典自适应窗口权重立体匹配算法[14]的基础上提出的改进方法。在具有遮挡信息的实验条件下，从两个方面对遮挡区域像素点进行处理。一方面，在代价聚合阶段为遮挡区域像素点分配较小的权重，以降低其对待匹配像素点代价聚合的影响；另一方面，在视差优化阶段根据前景遮挡背景的先验知识为遮挡区域像素点重新计算视差，以提高在深度不连续区域视差值计算的准确性。通过实验对比分析，本文提出的算法不仅提高了立体匹配在深度不连续区域的匹配精确性，同时改善了匹配得到视差图的前景膨胀，以及边缘模糊等问题。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "1 自适应权重立体匹配算法",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "Yoon等人提出的自适应权重立体配算法[14来源于格式塔分组原理中的接近性与相似性原则（即物体间的相对距离越近，越容易被认为是一个整体；在其他因素相同的情况下，物体越相似，越容易被认为是一个整体)，将颜色相似性与距离接近性两个因素作为权重的影响因子，并将匹配分为三个步骤，自适应窗口权重计算，相似差异计算，视差选择。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "1.1自适应窗口权重计算",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "算法根据几何接近性与颜色相似性来调整每个像素点在支持窗口内的权重，以减少模糊匹配，距离越接近的像素点权重越大，颜色越相似的像素点权重越大，同时，两者对于像素点权重的约束是相互独立的，权重公式描述为",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\nw ( p , q ) = \\exp ( - ( \\frac { \\Delta c _ { p q } } { \\gamma _ { \\mathrm { c } } } + \\frac { \\Delta g _ { p q } } { \\gamma _ { \\mathrm { p } } } ) )\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "其中： $\\boldsymbol { p }$ 为支持窗口中心的像素点， $q$ 为点 $p$ 支持窗口内的像素点， $\\Delta c _ { p q }$ 是 $p$ 与 $q$ 两点间的RGB 颜色距离， $\\Delta g _ { p q }$ 是 $p$ 与$q$ 两点间的欧氏距离， $\\gamma _ { \\mathrm { c } }$ 和 $\\gamma _ { \\mathfrak { p } }$ 分别是控制颜色与距离的参数， $\\gamma _ { \\mathfrak { p } }$ 与窗口的大小成正比。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "1.2相似差异计算",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "立体匹配的关键在于在支持窗口内进行代价聚合，花费代价越小，两个待匹配点的相似度就越高。区别于其他匹配算法，该算法在代价聚合阶段同时考虑了参考图像与目标图像中两个支持窗口的权重计算，是为了减小在深度不连续区域出现的匹配误差。代价聚合时的相似差异可描述为",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\nE ( p , \\overline { { p } } _ { d } ) = \\frac { { \\displaystyle \\sum _ { q \\in S _ { p } , \\overline { { q _ { d } } } \\in S _ { p _ { d } } ^ { - } } } w ( p , q ) w ( \\overline { { p } } _ { d } , \\overline { { q } } _ { d } ) e ( q , \\overline { { q } } _ { d } ) } { { \\displaystyle \\sum _ { q \\in S _ { p } , \\overline { { q _ { d } } } \\in S _ { p _ { d } } ^ { - } } } w ( p , q ) w ( \\overline { { p } } _ { d } , \\overline { { q } } _ { d } ) }\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "其中目标图像中的点 $\\overline { { p } } _ { d }$ 与 $\\overline { { q } } _ { d }$ 分别是与参考图像中 $\\textit { p , q }$ 两点视差为 $d$ 的匹配点。分母用做归一化处理。匹配代价的计算公式如下：",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\ne ( q , \\overline { { q } } _ { d } ) = \\operatorname* { m i n } \\left\\{ \\sum _ { c \\in \\{ r , g , b \\} } \\Big | I _ { c } ( q ) - I _ { c } ( \\overline { { q } } _ { d } ) \\Big | , T \\right\\}\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "其中： $I _ { c }$ 是 $c \\in \\{ r , g , b \\}$ 颜色通道的颜色强度， $T$ 是控制匹配代价范围的值。采用TAD（truncatedabsolutedifference）方法计算匹配代价，可以增强算法处理异常值的鲁棒性。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "1.3视差选择 ",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "采用简单的WTA视差选择策略选择视差。视差选择公式描述为",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\nd _ { p } = \\arg \\operatorname* { m i n } _ { \\substack { d \\in ( d _ { \\operatorname* { m i n } } , d _ { \\operatorname* { m a x } } ) } } E ( p , \\overline { { p } } _ { d } )\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "在点 $p$ 所有可能的视差范围内，代价聚合得到的相似差异最小的点即为同源匹配点，对应的视差记为点 $p$ 的视差。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "2 遮挡条件下的自适应权重立体匹配算法",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "2.1遮挡条件下立体匹配存在的问题",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "在局部立体配匹配算法中，自适应权重算法的匹配精确度远高于自适应窗口算法，但在纹理重复以及深度不连续区域仍然存在较高的误匹配率。其中，误匹配绝大部分发生在深度不连续区域。由于双目摄像机拍摄视角不同，在深度不连续区域通常伴随着遮挡问题的出现。如图1所示，点 $p$ 存在于参考图像中，但在目标图像中，点 $p$ 对应的同源匹配点因被遮挡而不存在。",
        "page_idx": 1
    },
    {
        "type": "image",
        "img_path": "images/14f07eafbf59882492a900be19e483e899b85d7579b961e8b3e5f0e1fd01cb33.jpg",
        "img_caption": [
            "图1一个躺在平面背景里的简单物体",
            "Fig.1A simple object laying on a planar background "
        ],
        "img_footnote": [],
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "由遮挡引起的匹配问题主要体现在两个方面，一方面，遮挡区域像素点具有较高的匹配代价，通过遮挡区域像素点对非遮挡区域像素点进行代价聚合，相似性差异会高于一般值，从而导致错误匹配；另一方面，遮挡像素点本身是没有对应的同源匹配点，直接通过其他像素点为其计算视差是不准确的。本文从这两个方面对立体匹配算法进行改进，在代价聚合阶段为遮挡区域像素点分配较低的权重，在视差优化阶段重新为遮挡区域像素点计算视差。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "2.2遮挡条件下的自适应权重计算",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "位于遮挡区域的像素点，其同源匹配点因被其他区域遮挡而不存在，因此，在为其计算匹配代价时，计算的是遮挡区域像素点与其他区域像素点的匹配代价，代价值通常比较高。在代价聚合阶段，若待匹配像素点的支持窗口内包含遮挡区域的像素点，则其相似性差异会比较高，从而导致错误匹配。因此，可以利用遮挡信息，在代价聚合阶段为遮挡区域的像素点分配较低的权重，从而降低遮挡区域像素点所产生的不良影响。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "本文对遮挡区域采取的检测算法是左右一致性检测(left-rightconsistencychecking，LRC)，由于在代价聚合阶段同时考虑了参考图像与目标图像中两个支持窗口的权重计算，因此，需要分别对两幅图像的遮挡区域进行检测。如下是对参考图像遮挡区域检测方法的介绍。首先，需要分别得到参考图像与目标图像的初始化视差图；然后，遍历参考图像中的每一个像素点，点 $p$ 的视差记为 $d _ { \\mathrm { { 1 } } }$ ，点 $p$ 在目标图像中对应的同源点 $( p - d _ { 1 } )$ 的视差记为 $d _ { 2 }$ ，若 $\\left| d _ { \\mathrm { 1 } } - d _ { \\mathrm { 2 } } \\right| >$ Threshold,则认为点 $p$ 为遮挡区域的像素点；最后，得到参考图像的遮挡信息。检测伪代码如下所示。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "Input: Reference image disparity map $R _ { d }$ ，Target image disparity map $T _ { d }$ ，threshold The width of $R _ { d } ~ w$ ，the height of $R _ { d }$ h The widthStep/sizeof of $R _ { d }$ step，the channels of $R _ { d }$ nchs ",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "Output: Reference occlusion image $R _ { o }$ ",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "1:for $y : = 0$ to $h$ （204号   \n2:for $x { : = } 0$ to $w$ （20   \n3: $d _ { 1 } \\to ( R _ { d } \\to i m a g e d a t a [ y * s t e p + x * n c h s ] )$   \n4: $d _ { 2 }  ( T _ { d }  i m a g e d a t a [ y * s t e p + ( x - d ) * n c h s ] )$   \n5： if $\\boldsymbol { a b s } ( d _ { 1 } - d _ { 2 } ) >$ threhsold   \n6: $( R _ { o } \\to i m a g e d a t a [ y * s t e p + x * n c h s ] ) \\to 0$   \n7:else $( R _ { o }  i m a g e d a t a [ y * s t e p + x * n c h s ] )  2 5 5$   \n8:return $R _ { o }$ ",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "利用上述检测得到的遮挡信息，在代价聚合阶段为遮挡区域的像素点分配较小的权重，权重公式描述为",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\n\\left\\{ \\begin{array} { l l } { \\displaystyle \\varepsilon , ~ \\mathrm { q i s i n o c c l u s i o n r e g i o n } } \\\\ { \\displaystyle w ( p , q ) = \\exp ( - ( \\frac { \\Delta c _ { p q } } { \\gamma _ { c } } + \\frac { \\Delta g _ { p q } } { \\gamma _ { p } } ) ) , ~ \\mathrm { o t h e r w i s e } } \\end{array} \\right.\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "其中 $\\boldsymbol { \\varepsilon }$ 是一个不为零的较小值，即使是同源像素点，也会因颜色的轻微不同(光照影响)而存在匹配代价，若 $\\scriptstyle { \\varepsilon = 0 }$ ，当待匹配像素点的支持窗口内包含较多遮挡区域的像素点，在为其代价聚合计算相似性差异时，会因减少代价聚合像素点的个数而降低相似性差异，从而导致在视差选择阶段选择错误视差。目标图像中的遮挡区域检测以及权重计算方式与参考图像相同。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "2.3遮挡条件下的视差重计算",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "对于遮挡区域的像素点，其同源匹配点在另一副图像中是不存在的，因此，直接通过其他像素点为其计算视差是不准确的，本文在视差优化阶段重新为遮挡区域像素点计算视差。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "在实际应用中，遮挡区域一般存在于背景区域，由于观察视角的不同，前景区域挡住背景的部分区域而导致遮挡出现。如图2所示，从左侧视角可以观察到红色下对角线纹理区域，但对于右侧视角来说该区域属于盲区，在左侧视角拍摄得到的参考图像中，红色区域被认为是遮挡区域；同样，从右侧视角可以观察到绿色上纹理区域，该区域对于左侧视角来说属于盲区，在右侧视角拍摄得到的目标图像中，绿色区域被认为是遮挡区域。通过观察发现，遮挡区域都存在于背景区域。",
        "page_idx": 2
    },
    {
        "type": "image",
        "img_path": "images/6390727b903037a88ddc9527603a234cd8bbafdf9c22fbc7b6c8a43ae796452a.jpg",
        "img_caption": [
            "图2前景遮挡背景",
            "Fig.2Foreground occlusion background "
        ],
        "img_footnote": [],
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "从同一视角拍摄两个物体，在拍摄得到的图像中，距离摄像头较近的物体属于前景区域，距离摄像头较远的物体属于背景区域。在深度不连续区域通常伴随着遮挡问题的出现，被遮挡的区域是距离前景区域最接近的背景区域。在双目立体视觉模型中，依据三角测量原理可以得到距离与视差的计算公式为",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\nZ = f { \\frac { b } { d } }\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "其中： $z$ 表示物体距离摄像机的深度， $f$ 为摄像机的焦距， $b$ 为基线， $\\textit { d }$ 表示视差。当 $f$ 与 $b$ 保持不变时，物体距摄像机距离越近，视差越大，因此，背景区域的视差值小于前景区域。依据该原理，在视差优化阶段，为遮挡区域的像素点重新计算视差。首先，根据新的权重计算方式，按照自适应权重立体匹配算法得到参考图像的视差图 $R _ { d }$ ；然后对最初检测到的参考图像的遮挡图 $R _ { o }$ 进行扫描，若像素点 $R _ { o } ^ { \\ ( i ) }$ 为遮挡区域的像素点，则在该像素点的水平方向上向左向右扫描，分别找到该像素点左边与右边第一个不是遮挡区域的像素点${ R _ { o } } ^ { ( a ) } , { R _ { o } } ^ { ( b ) }$ ；最后对应于参考图像，比较这两个像素点的视差${ \\cal R } _ { d } ^ { ( a ) } , { \\cal R } _ { d } ^ { ( b ) }$ ，较小的视差记为遮挡像素点 $R _ { d } ^ { ( i ) }$ 的视差。算法流程图如图3所示",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 2
    },
    {
        "type": "image",
        "img_path": "images/a8507f1265baf0eabf6246bf557d7ec33e2269f494ba68621aea13af416c1eb9.jpg",
        "img_caption": [
            "图3遮挡区域像素点视差重计算流程图",
            "Fig.3Flow chart of parallax recalculation of occlusion pixels "
        ],
        "img_footnote": [],
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "通过对遮挡区域的像素点在代价聚合以及视差优化两个阶段的处理，目的是提高传统自适应权重算法在深度不连续区域的匹配精确度，改善匹配得到视差图的前景膨胀以及在视差不连续区域边缘模糊等问题。实验过程及结果在第三小节做具体分析。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "2.4误匹配率计算 ",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "本文通过计算视差图的错误百分比对匹配算法进行评估，计算方式如下：",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\nW = \\frac { 1 } { N } \\sum _ { ( x , y ) } \\left( \\left| d ( x , y ) - d _ { g } ( x , y ) \\right| > \\theta ) \\right.\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "其中： $N$ 为视差图像素点总数， $d ( x , y )$ 为算法所得像素点 $( x , y )$ 的视差值， $d _ { g } ( x , y )$ 为Middlebury数据集提供的标准视差图(ground truth)对应像素点 $( x , y )$ 的视差值， $\\theta$ 为阈值（大小通常为1)。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "为了更好地对实验结果进行评估，通常计算算法在无遮挡区域(nocc)、所有区域(all)以及深度不连续区域(disc)的三种错误百分比。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "3 分析与讨论",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "为了测试所提算法的匹配效果，本文从两方面进行了实验分析：a)利用左右一致性检测算法对参考图像与目标图像的遮挡区域进行检测；b)在具有遮挡信息的条件下，在代价聚合与视差优化阶段对遮挡区域像素点进行处理，得到新的视差图。实验采用的软件平台为VS2010，使用 $^ { C + + }$ 语言编写算法，通过OpenCV开源数据库完成对图片的读取、显示与保存处理。硬件平台：计算机处理器为IntelCorei7-8550U，CPU主频为 $1 . 8 0 \\mathrm { G H z }$ ，内存容量为8G。实验测试数据来源于Middlebury标准图像集中的四对标准图像(Tsukuba,Venus,Teddy, Cones)。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "3.1遮挡检测结果及分析",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "遮挡检测采用的方法是左右一致性检测(LRC)，所用的视差图是根据经典自适应窗口权重立体匹配算法[14得到的。由于经典自适应权重算法在代价聚合阶段同时考虑了参考图像与目标图像两个支持窗口的权重，因此，在遮挡区域检测阶段需要分别得到参考图像与目标图像的遮挡区域。实验所使用的参数如表1所示",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "表中 $T$ 为控制匹配代价范围的参数，W为支持窗口的宽度， $\\gamma _ { \\mathfrak { p } }$ 与 $\\gamma _ { \\mathrm { c } }$ 分别为控制距离和颜色权重的参数，Threshold表示LRC检测算法所设定的阈值。如图4分别是Tsukuba,Venus,Teddy以及Cones的参考图像以及其对应的遮挡区域检测结",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "果。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "表1经典自适应窗口权重算法以及遮挡检测算法的参数",
        "page_idx": 3
    },
    {
        "type": "table",
        "img_path": "images/c21bf11c8c8280d0a0579cd9b7780cde4032d88dcbcf2708f29277f306d1f978.jpg",
        "table_caption": [
            "Table 1Parameters for adaptive weight-support approach and occlusion detection algorithm "
        ],
        "table_footnote": [],
        "table_body": "<html><body><table><tr><td>参数</td><td>T</td><td>W</td><td>Yp</td><td>Ye</td><td>Threshold</td></tr><tr><td>值</td><td>40</td><td>35</td><td>17.5</td><td>5</td><td>1</td></tr></table></body></html>",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "在遮挡图像中，遮挡区域的像素点颜色为黑色，其他区域的像素点颜色为白色。由图4可以看出，遮挡通常发生在深度不连续的区域，并且距离成像设备越近的物体（视差越匹配算法在深度不连续区域仍有较高的误匹配率。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "3.2立体匹配结果与分析",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "在得到遮挡区域的图像后，依据本文提供的改进算法，在代价聚合阶段为遮挡区域像素点分配较低的权重，这里的权重值 $\\varepsilon = 0 . 1$ ，不设置为0的原因是平衡本应该存在的匹配代价，防止因减少代价聚合的像素点的个数而降低匹配代价，造成误匹配；在视差优化阶段依据前景遮挡背景的先验知识重新为遮挡区域像素点计算视差。本文算法所得到的视差图",
        "page_idx": 3
    },
    {
        "type": "image",
        "img_path": "images/8d856485c1a8202443090a09062ef6f71633fac558ed3af5253f972eec066a4b.jpg",
        "img_caption": [],
        "img_footnote": [],
        "page_idx": 3
    },
    {
        "type": "image",
        "img_path": "",
        "img_caption": [
            "图5实验结果",
            "Fig.5Experience result "
        ],
        "img_footnote": [],
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "由图5可以看出，匹配得到了较好的视差结果，并且较为清晰的区分了物体在深度不连续区域的不同视差。给定视差图、基线、以及校准得到的焦距信息，根据三角测量原理即可计算出像素点在三维世界中的位置信息。从视差图中可以看出，颜色强度越强，视差值越大，距离越近。通过对比标准视差图，可以发现本文得到的视差图在低纹理区域以及纹理重复区域仍然有一定的误匹配，后续可以在该方面继续进行研究。",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "3.3算法对比分析",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "为了证明算法匹配结果的精确性，将所得到的视差图与标准视差图进行对比，分别计算算法在无遮挡区域(nocc)、所有区域(all)、深度不连续区域(disc)的错误百分比以及平均错误百分比，并与经典自适应窗口立体匹配算法[14]、自适应权重的改进算法[151以及引入自适应权重的Census变换立体匹配算法[13]进行对比，所得结果如表2所示。",
        "page_idx": 4
    },
    {
        "type": "table",
        "img_path": "images/617a0aff23675a6af8bb0167cf232216dbe032c29c1dd62e31e4748e52d3011c.jpg",
        "table_caption": [
            "表2算法误匹配率 "
        ],
        "table_footnote": [],
        "table_body": "<html><body><table><tr><td colspan=\"5\">Table 2 Mismatchingrate</td></tr><tr><td>Algorithm</td><td>Tsukuba</td><td>Venus</td><td>Teddy</td><td>Cones</td><td>Avg</td></tr><tr><td></td><td>Proposed 1.60 1.82 6.60 0.43 0.58 2.35 6.71 11.8 17.1 2.67 8.12 7.3 5.58</td><td></td><td>nocc all disc nocc all disc nocc all disc nocc all disc</td><td></td><td></td></tr><tr><td></td><td>Paper[14]1.38 1.85 6.90 0.71 1.916.13 7.88 13.3 18.6 3.97 9.79 8.266.67</td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>Paper[15] 2.072.9310.20.22 0.63 2.53 5.9911.9 14.4 2.72 8.637.57 5.83 Paper[13] 4.83 6.4511.8 1.03 1.927.58 7.89 6.6518.14.52 5.40 7.42 6.95</td><td></td><td></td><td></td><td></td></tr><tr><td>4</td><td>Proposed Paper [14]</td><td>8</td><td>Proposed Paper [14]</td><td></td><td></td></tr><tr><td>2</td><td></td><td></td><td>4</td><td></td><td></td></tr><tr><td>0</td><td></td><td></td><td>2</td><td></td><td></td></tr><tr><td>nocc</td><td>all</td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>0</td><td></td><td></td></tr><tr><td></td><td></td><td>disc</td><td>nocc</td><td>all</td><td></td></tr><tr><td></td><td>(a)Tsukuba</td><td></td><td></td><td></td><td>disc</td></tr><tr><td>20</td><td></td><td></td><td></td><td>(b)Venus</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>Proper[1d]</td><td></td><td>10</td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>15</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>8</td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>10</td><td></td><td></td><td>6</td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>4</td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>Proposed</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>Paper [14]</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>5</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>2</td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>nocc</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>nocc</td><td>all</td><td>disc</td></tr><tr><td></td><td></td><td>disc</td></table></body></html>",
        "page_idx": 4
    },
    {
        "type": "image",
        "img_path": "",
        "img_caption": [
            "图6本文算法与自适应权重算法对比结果",
            "Fig.6Result of contrast between Proposed and adaptive weight approach "
        ],
        "img_footnote": [],
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "由表2可以看出，本文所提算法相较于经典自适应权重立体匹配算法[14]平均误匹配率降低了 $1 6 \\%$ 。文献[15]是自适应权重的改进算法，文献[13]是针对深度不连续区域误匹配率高的改进算法，将本文算法与两种算法进行比较，本文算法有更低的误匹配率。由于本文是针对深度不连续区域的遮挡检测与处理，检测得到遮挡区域，并依据前景遮挡背景对其进行恢复，因此，降低了算法在深度不连续区域的错误百分比。同时，减少遮挡区域像素点对非遮挡区域像素点代价聚合时的影响，提高了立体匹配算法的匹配精确度。",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "为了更加清楚地表示算法的改进效果，通过图6显示本文算法与自适应权重算法[14]的对比结果，可以看出本文提出的算法不仅降低了算法在深度不连续区域的误匹配率，还提高了立体匹配算法的匹配精确度，算法改进结构简单，后期实验可以通过引入多线程提高算法运算效率。",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "4 结束语",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "本文在代价聚合阶段为遮挡区域像素点分配较低的权重，降低了遮挡区域像素点对于待匹配像素点代价聚合的影响，提高了立体匹配整体结果的精确性；在视差优化阶段依据前景遮挡背景的先验知识重新为遮挡区域像素点计算视差，提高了遮挡区域像素点视差计算的准确性，降低了立体匹配在深度不连续区域的误匹配率。实验结果显示，本文算法改善了所得视差图的前景膨胀，边缘模糊等问题。通过与经典自适应立体匹配算法及其改进算法对比，本文算法提高了局部立体匹配算法在深度不连续区域匹配结果的精确性。本文算法的匹配精确度在自适应权重立体匹配算法上更进一步，但算法效率稍低，后期会针对如何提高算法的运行效率做进一步研究与实验。",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "参考文献：",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "[1] Scharstein D，Szeliski R.A taxonomy and evaluation of dense two-frame stereo correspondence algorithms [J]. International Journal of Computer Vision,2002,47 (1-3): 7-42.   \n[2] Zhang Gexiang,Rong Haina, Song Hui,et al. Multi-aperture stereo reconstruction for artificial compound eye with cross image belief propagation [J].Applied Optics,2018,57(7): B160.   \n[3]王琼，江晓亮，袁建英，等．基于改进Census 变换的区域立体匹配 算法[J].计算机应用研究，2015,32(10):3164-3167.(Wang Qiong, Jiang Xiaolinag，Yuan Jianying，et al. Regional stereo matching algorithm based on improved Census transform [J].Application Research of Computer,2015,32(10): 3164-3167.）   \n[4]Lee S,Hong H. Near-real-time stereo matching method using both cross-based support regions in stereo views [J]. Optical Engineering, 2018,57(2): 023103.   \n[5]Mattoccia S,Giardino S,Gambini A．Accurate and efficient cost aggregation strategy for stereo correspondence based on approximated joint bilateral filtering [C]// Proc of the 9th Asian Conference on Computer Vision.New York:ACMPress,2012:371-380.   \n[6]Malathi T,Bhuyan MK.Asymmetric occlusion detection using linear regression and weight-based filling for stereo disparity map estimation [J].IET Computer Vision,2017,10(7): 679-688.   \n[7]吕倪祺，宋广华，杨波威．特征融合的双目半全局匹配算法及其并 行加速实现[J].中国图象图形学报，2018,23(6):0874-0886.(Lv Niqi，Song Guanghua，Yang Bowei. Semi-global stereo matching algorithm based on feature fusion and its CUDA implementation [J]. Journal of Image and Graphics,2018,23(6): 0874-0886.）   \n[8]边继龙，李金凤，罗嗣卿．基于变分原理的亚像素级立体匹配方法 [J]．计算机应 用研究,2014,31(9):2846-2849.(Bian Jilong,Li Jinfeng, Luo Siqing. Sub-pixel stereo matching method based on variational principle [J]. Application Research of Computer，2014,31(9): 2846-2849.)   \n[9]Zhang Qi,Xu Li, Jia Jiaya. $1 0 0 +$ times faster weighted median filter (WMF)[C]// Proc of IEEE Conference on Computer Vision and Pattern Recognition. Piscataway,NJ: IEEE Press,2014: 2830-2837.   \n[10] Xie Yuechao,Zeng Siyu,Chen Long.A novel disparity refinement method based on semi-global matching algorithm[C]// Proc of IEEE International Conference on Data Mining Workshop.Piscataway,NJ: IEEE Press,2015:1135-1142.   \n[11]陆军，方莹，张鑫．融合 AD与Census 变换的动态规划立体匹配与 遮挡处理[J].北京理工大学学报,2015,35(12):1274-1279.(Lu Jun, Fang Ying,Zhang Xin. Stereo matching and occlusion handling based on dynamic programming using AD and Census transform [J]. Transactions of Beijing Institute of Technology，2015，35(12): 1274-1279.)   \n[12] Ye Xiao,Gu Yuzhang，Chen Lili，et al.Order-based disparity refinement including occlusion handling for stereo matching [J].IEEE Signal Processing Letters,2017,24(10): 1483-1487   \n[13]周旺尉，金文光．一种新颖的自适应权重Census 变换立体匹配算法 [J]．计算机工程与应用，2016,52(16):192-197.(Zhou Wangwei,Jin Wenguang.Novel stereo matching algorithm for adaptive weight Census transform [J].Computer Engineering and Applications,2016,52 (16): 192-197.)   \n[14] Yoon K J,Kweon I S.Adaptive support-weight approach for correspondence search [J].IEEE Trans on Pattern Analysis& Machine Intelligence,2006,28(4):650-656.   \n[15]杨奎，赵剡，苏庆华，等．基于递推自适应权重的快速稠密立体匹配 [J]．北京航空航天大学学报，2013,39(7):963-967.(Yang Kui,Zhao Yan,Su Qinghua,et al. Fast recursive adaptive weight stereo matching [J].Journal of Beijing University of Aeronautics and Astronautics,2013, 39(7):963-967.) ",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 5
    }
]