[
    {
        "type": "text",
        "text": "基于改进引力搜索算法的K-means 聚类\\*",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "魏康园a,b，何庆a,b，徐钦帅a,b(贵州大学a.大数据与信息工程学院;b.贵州省公共大数据重点实验室，贵阳 550025)",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "摘要：针对 K-means 算法的聚类结果极易受到聚类中心的影响而陷入局部最优解的问题，提出一种基于改进引力搜索的K-means聚类算法。首先引入自适应概念，对引力系数衰减因子进行控制，提高算法的全局探索能力和局部开发能力；然后，引入免疫克隆选择机制，以便算法能够有效跳出局部最优，并通过对12个基准测试函数的实验验证改进引力搜索算法的有效性和优越性；最后，通过结合改进的引力搜索算法和 K-means 算法，提出一种新的聚类算法A2F-GSA-Kmeans，并在6个测试数据集上的实验表明，该算法具有较好的聚类质量。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "关键词：K-means算法；引力搜索算法；引力系数衰减因子；免疫克隆选择算法 中图分类号：TP301.6 doi:10.3969/j.issn.1001-3695.2018.06.0310 ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Novel K-means clustering algorithm based on improved gravitational search algorithm ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Wei Kangyuana, b, He Qinga, bt, Xu Qinshuaia, b (a.Colegeof Big Data& Information Engineering,b.Guizhou Provincial KeyLaboratoryof Public Big Data Guizhou University,Guiyang 550025,China) ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Abstract:Inorder to solvetheproblem thattheclusteringresult of K-means algorithmgets afected bythe initial cluster centers easily,this paper proposed anovel K-means clusteringalgorithm basedon improved gravitational search algorithm. Firstly,itenhancedtheglobal explorationandlocalexploitationcapabilityofthealgorithmwiththeintroductionofadaptive concept tocontrol theatenuation factorof gravitationalconstant.Then,byintroducing immuneclonal selectionalgorithmto makethealgorithm jumpoutofthe local optimum eficiently.The experimental resultson twelve test functions prove the effectivenessand superiorityof the improved GSA.Finally,bycombining the improvedGSAwith K-means algorithm,this paper proposed anew clustering algorithm caled A2F-GSA-Kmeans.The experimental resultsonsix test datasets showthat the algorithm has better clustering quality. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Keywords:K-meansclustering algorithm；gravitational search algorithm；attenuation factorof gravitational constant; immune clonal selection algorithm ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "0 引言",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "聚类是分析数据的重要方法，其作用是将多个抽象对象按照相应的标准分成由相似的对象组成的多个类过程，已经被广泛应用于许多领域，其中K-means算法在处理大量数据时具有简单高效的优点，已经被广泛应用，但其聚类结果极易受到聚类中心的影响，导致陷入局部最优解错误!未找到引用源。，并且要求用户指定聚类数量，然而不同的聚类数将会得到不同的聚类结果，直接影响算法的效率。因此，算法本身可以获得最优数目的聚类是非常重要的。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "群智能算法因其强大的全局搜索能力，已经被越来越多的学者应用到聚类问题中，来弥补传统聚类算法的缺陷。例如杨菊蜻等错误!未找到引用源。通过对蝙蝠优化算法（BA）的位置和速度更新方式进行优化，同时引入非线性惯性权重和limit阈值思想，提高了算法的收敛性能，并将改进算法与K-means结合，提出了一种基于改进BA算法的K-means 算法，取得了较好的聚类效果；于佐军等人错误!未找到引用源。通过引入算术交叉操作改进人工蜂群算法中引领蜂和跟随蜂的搜索模式，并结合K-means算法，提出一种聚类算法来自动寻找最优的聚类数。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "引力搜索算法错误！未找到引用源。（Gravitational Search Algorithms，GSA）是EsmatRashedi教授等于2009年提出的一种新的群智能优化算法，该算法通过模拟物理学中万有引力来搜索全局最",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "优解。研究发现，在对基准测试函数进行优化时，经典GSA算法的优化精度与收敛速度均明显优于粒子群优化算法（particle swarm optimization，PSO）和遗传算法（geneticalgorithm，GA）等优化算法错误!未找到引用源。。但是，与其他元启发式算法类似，经典GSA算法同样存在早熟收敛、易陷入局部极值等缺陷，基于此，近年来国内外学者实现了许多有效的改进GSA 算法，如Liu 等人错误!未找到引用源·利用混沌映射优化GSA 算法中粒子的位置初始化，同时将自适应递减惯性权重系数引入到位置更新公式中，提出并实现了AC-GSA算法，并在经典基准测试函数的测试和优化最小二乘支持向量机超参数上都取得了良好的结果；Sun 等人错误!未找到引用源。基于粒子个体的异质性，利用粒子个体最优值和全局最优值对GSA算法的Kbest和速度更新方式进行改进，提出了LIGSA算法，使得粒子能够学习K个近邻粒子而充分开发搜索空间并有效防止早熟收敛，同时全局最优值的引导可加速算法收敛速度；Mirjalili等人错误!未找到引用源。基于GSA算法中引力系数G对于平衡算法全局探索能力与局部开发能力的重要性，利用混沌映射对引力系数进行改进，并验证了其能够跳出局部最优实现更高寻优精度的有效性。然而，尽管已有研究对经典GSA算法的寻优效果有所提高，且大多集中于结合PSO算法对GSA算法的速度和位置更新方式的改进误!未找到引用源。8错误!未找到引用源。，但对于实现算法探索与开发能力的有效平衡和解决其早熟收敛问题仍需深入研究。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "综上所示，本文针对引力搜素算法易陷入局部最优、发生早熟收敛现象等问题，首先对引力搜素算法中的引力系数作出改进，保留算法较高精度和收敛速度的同时，提高算法的全局探索能力和局部最优能力；然后再引入免疫克隆选择机制，改善算法早熟收敛现象；最后将改进的GSA算法应用到K-means聚类算法中，通过调节K值大小，利用聚类评价函数来获取最佳的聚类数。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "1 相关工作",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "1.1 K-means 算法",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "K-means 算法是一种基于划分的聚类算法，该算法首先随机选取样本空间中的 $K$ 个数据点作为聚类中心，然后通过计算样本中其他数据点与中心点的欧式距离大小，来对数据进行划分。该算法的流程如图1所示。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "对于欧氏距离的数据，本文使用均方误差MSE作为聚类的目标函数，且MSE的值越小表示聚类效果越好。定义为",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\nM S E = \\frac { 1 } { n } \\sum _ { j = 1 } ^ { k } \\sum _ { y _ { i } \\in C _ { j } } \\left\\| y _ { i } - z _ { j } \\right\\| ^ { 2 }\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "其中， $z _ { j }$ 表示聚类中心。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "本文使用轮廓系数错误!未找到引用源。来评价不同聚类数下的聚类质量，从而找出最佳的聚类数。对于每个聚类的轮廓系数的表示为",
        "page_idx": 1
    },
    {
        "type": "image",
        "img_path": "images/014cc185c5acbeaa88fac28ccaab7bdde49bd1115854af5dbbbaf39a3724674f.jpg",
        "img_caption": [
            "图2GSA算法流程图"
        ],
        "img_footnote": [],
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\ns i l _ { i } = \\frac { 1 } { r _ { i } } \\sum _ { m = 1 } ^ { r _ { i } } \\frac { b ( m ) - a ( m ) } { \\operatorname* { m a x } \\{ b ( m ) , a ( m ) \\} }\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "其中： $r _ { i }$ 表示每个聚类中样本个数； $a ( m )$ 表示样本 $m$ 与同类其他样本的平均距离； $b ( m )$ 表示样本 $m$ 与其他聚类中所有样本平均距离的最小值。",
        "page_idx": 1
    },
    {
        "type": "image",
        "img_path": "images/7f720f03e1cee1f3944e5197ea9d8f4159b3d91aee683f8497a3daad4f04ea71.jpg",
        "img_caption": [
            "图1K-means聚类算法流程图"
        ],
        "img_footnote": [],
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "对于整个数据集，则可通过平均轮廓指标来评价聚类结果的有效性，表示如下：",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\ns i l = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } s i l _ { i }\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "其中： $N$ 表示数据集中样本大小。且 $- 1 \\leq s i l \\leq 1$ ，若 $^ { s i l }$ 接近1时，表示 $a ( m )$ 远小于 $b ( m )$ ，即聚类质量效果好。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "1.2经典 GSA算法",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "引力搜索算法（GSA）是将空间中所有的粒子视为遵循牛顿第二定律进行无阻力运动的有质量的物体，质量越大的物体将占据更优位置。通过物体间相互万有引力的作用，寻到最优解。经典的GSA算法流程如图2所示。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "经典的引力搜索算法描述如下：假设由 $N$ 个粒子 $X _ { i }$ 构成的种群，在 $D$ 维搜索空间中，定义第 $i$ 个粒子的位置为",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\nX _ { i } = ( X _ { i } ^ { 1 } , X _ { i } ^ { 2 } , \\cdots , X _ { i } ^ { k } , \\cdots , X _ { i } ^ { D } ) , i = 1 , 2 , \\cdots , N\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "其中： $x _ { i } ^ { k }$ 表示第 $i$ 个粒子在第 $k$ 维上的位置。当进行第 $t$ 次迭代时，粒子 $i$ 的惯性质量 $M _ { i } ( t )$ 可根据其适应度值来更新，更新公式为",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\nm a s s _ { i } ( t ) = \\left\\{ \\begin{array} { l l } { \\displaystyle \\frac { f i t _ { i } ( t ) - w o r s t ( t ) } { b e s t ( t ) - w o r s t ( t ) } \\ } & { \\ i f \\ b e s t ( t ) \\neq w o r s t ( t ) } \\\\ { 1 \\ } & { \\ o t h e r w i s e } \\end{array} \\right.\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\nM _ { i } ( t ) = \\frac { m a s s _ { i } ( t ) } { \\displaystyle \\sum _ { j = 1 } ^ { N } m a s s _ { j } ( t ) }\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "其中： ${ \\it f i f } _ { i } ( t )$ 表示粒子 $i$ 在迭代 $t$ 时的适应度值， $i = 1 , 2 , \\cdots , N$ 。对于求解最小值优化问题，最优适应度best(t)和最差适应度worst(t)分别为",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\nb e s t ( t ) = \\operatorname* { m i n } _ { j \\in \\{ 1 , 2 , \\cdots , N \\} } \\hat { \\mathscr { H } } t _ { j } ( t )\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\nw o r s t ( t ) = \\operatorname* { m a x } _ { j \\in \\{ 1 , 2 , \\cdots , N \\} } \\hbar t _ { j } ( t )\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "反之，即可用于最大值优化问题。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "当进行第 $t$ 次迭代时，定义粒子 $j$ 和粒子 $i$ 在第 $k$ 维的相互吸引力为",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\nF _ { i j } ^ { k } \\left( t \\right) = G ( t ) \\frac { M _ { i } ( t ) \\times M _ { j } ( t ) } { R _ { i j } ( t ) + \\varepsilon } ( x _ { j } ^ { k } ( t ) - x _ { i } ^ { k } ( t ) )\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "其中： $\\boldsymbol { M } _ { \\flat }$ 表示作用粒子 $j$ 的惯性质量； $M _ { i }$ 表示被作用粒子 $i$ 的惯性质量； $\\boldsymbol { \\varepsilon }$ 为常量； $G ( t )$ 表示 $t$ 次迭代时的万有引力系数； $R _ { i j } ( t )$ 表示粒子 $i$ 与粒子 $j$ 之间的距离（一般取欧氏聚类），计算式分别为",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\nG ( t ) = G _ { 0 } \\times e ^ { ( - \\alpha \\frac { t } { T } ) }\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\nR _ { i j } ( t ) = \\left\\| X _ { i } ( t ) , X _ { j } ( t ) \\right\\| _ { 2 }\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "其中： $G _ { 0 }$ 表示宇宙在最初时刻的万有引力常量； $\\alpha$ 表示引力系数的衰减因子，一般取值为常数； $T$ 表示最大迭代次数。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "在GSA中，设第 $t$ 次粒子 $i$ 在第 $\\mathbf { k }$ 维所受的总作用力为",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\nF _ { i } ^ { k } = \\sum _ { j = 1 , j \\ne i } ^ { K b e s t } r a n d _ { i } \\times F _ { i j } ^ { k } ( t )\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "其中：randi 表示[0.1]的一个随机数； $F _ { i j } ^ { k }$ 的定义如式（6）所示；Kbest初始值为 $N$ ，并随着时间推移逐渐减小为1，定义为",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\nK b e s t ( t ) = f i n a l \\_ p e r + ( \\frac { 1 - t } { T } ) \\times ( 1 0 0 - f i n a l \\_ p e r )\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "其中： $f i n a l _ { - } p e r$ 表示对其他粒子产生作用力的粒子百分比。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "依据牛顿第二定律，当进行第 $t$ 次迭代时，粒子 $i$ 在第 $k$ 维上的加速度可定义为",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\na _ { i } ^ { k } ( t ) = \\frac { F _ { i } ^ { k } ( t ) } { M _ { i } ( t ) }\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "GSA算法每一次迭代进化过程中，粒子根据下式更新粒子$i$ 的速度 $\\nu$ 和位置 $x$ ，即",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\n\\boldsymbol { \\nu } _ { i } ^ { k } \\left( t + 1 \\right) = r a n \\boldsymbol { d } _ { j } \\times \\boldsymbol { \\nu } _ { i } ^ { k } \\left( t \\right) + \\boldsymbol { a } _ { i } ^ { k } \\left( t \\right)\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\nx _ { i } ^ { k } \\left( t + 1 \\right) = x _ { i } ^ { k } \\left( t \\right) + \\nu _ { i } ^ { k } \\left( t + 1 \\right)\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "其中： $r a n d _ { j }$ 表示[0.1]的一个随机数。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "2 改进的引力搜索算法",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "本文针对经典引力搜索算法易陷入局部最优解、发生早熟收敛现象等问题，提出一种基于自适应引力系数衰减因子和免",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "疫克隆选择机制的改进引力搜索算法（adaptiveattenuation factor based gravitational search algorithm,A2F-GSA）。 ",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "2.1自适应引力系数非线性衰减 ",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "在 GSA算法中，万有引力系数 $G$ 对于寻找算法最优解非常重要，如式（7）所示，其中主要参数为 $G _ { 0 }$ 和 $\\alpha$ ，且通常取值为一个常数。研究表明，参数 $G _ { 0 }$ 通常取值为100时，算法能够取得最佳优化效果错误!未找到引用源。。对于参数 $\\alpha$ ，通过调整其取值大小会发现，在算法迭代前期，参数 $\\alpha$ 取较小值，能够保证粒子增加的步长，提高算法的全局探索能力；而在算法迭代中后期，当参数 $\\alpha$ 取值较大时，将会加快收敛速度，提升算法的局部开发能力错误!未找到引用源。。通过研究指数函数的特性，结合参数 $\\alpha$ 对算法性能的影响，本文提出一种基于迭代次数自适应变化的引力系数衰减因子，定义如下：",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\n\\alpha ( t ) = \\gamma \\times e ^ { \\mathrm { { \\imath g } } ( \\eta \\times \\frac { t } { T } ) }\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "其中： $t$ 表示当前迭代次数； $T$ 表示最大迭代次数；／和 $\\eta$ 分别为 $\\alpha$ 函数的参数。选择合适的参数的来控制 $\\alpha$ 函数的变化范围，本文选取 $\\gamma = 1 0 0$ ， $\\eta = 0 . 1$ 。自适应的 $\\alpha$ 在算法早期迭代时生成较大的引力系数 $\\boldsymbol { G }$ ，能够更加有效的提升全局探索能力，在后期选代时生成较小的引力系数 $G$ ，能够有效提升局部开发能力。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "2.2引入免疫克隆选择机制",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "通过分析经典GSA算法的基本原理可知，随着算法的迭代进化，粒子将逐渐聚集于群体中适应度较优的粒子，从而使得粒子分布收缩，多样性减小，导致算法易陷入局部最优。受文献错误！未找到引用源。结合人工蜂群算法和克隆选择算法（Clonal Selection Algorithm，CSA）提出的DQABCI算法和文献错误！未找到引用源。基于粒子群算法及CSA 算法提出的MAPCPSOI算法启发，本文在经典GSA算法中引入免疫克隆选择机制，结合GSA算法的寻优能力和CSA算法的选择复制、变异和再选择的特点，使得算法具有跳出局部最优的能力，改善算法的早熟收敛现象。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "克隆选择算法（CSA）错误!未找到引用源。由De Castro 等人于 2000年提出，是一种基于人工免疫算法内部微演化过程的优化算法。其以构建记忆单位为基础，实现全局探索与局部开发能力平衡错误!未找到引用源。，并由单个最优个体演化为群体最优解集，能够在扩大算法寻优区域的同时，体现免疫系统的多样性错误!未找到引用源。CSA算法主要包括克隆复制、克隆变异和克隆选择三个阶段，其中克隆复制阶段用于实现种群规模及寻优空间的扩张；克隆变异阶段用于增加种群粒子的多样性，构造出新的种群；克隆选择阶段用于在新建种群中选取适应度（亲和力）高的抗体进入下一代，在实现种群压缩的同时，使得种群朝向更优解移动。文中引入的免疫克隆选择机制具体步骤如下：",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "（1）粒子亲和度计算",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "在改进的GSA算法中，将粒子视为抗体，因此本文将粒子的适应度函数定义为粒子的亲和度函数，定义如下：",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\na f i t _ { i } ( t ) = f i t _ { i } ( t )\n$$",
        "text_format": "latex",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "其中： $f i f _ { i } ( t )$ 表示粒子 $i$ 在迭代 $t$ 时的适应度值， $i = 1 , 2 , \\cdots , N$ 。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "（2）克隆复制",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "选择当代种群中亲和度值最高的粒子，进行位置信息克隆复制操作，复制个数为 $M$ ，文中选取 $M = 1 0$ 。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "（3）克隆变异",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "对经过克隆复制产生的新粒子进行位置变异，文中引入基于高斯分布和柯西分布的突变算子，其概率密度函数描述分别如下：",
        "page_idx": 3
    },
    {
        "type": "equation",
        "text": "$$\nf _ { \\scriptscriptstyle N } ( \\boldsymbol { x } ) = \\frac { 1 } { \\sqrt { 2 \\pi \\sigma } } \\exp \\biggl [ - \\frac { ( \\boldsymbol { x } - \\boldsymbol { u } ) ^ { 2 } } { 2 \\sigma ^ { 2 } } \\biggr ]\n$$",
        "text_format": "latex",
        "page_idx": 3
    },
    {
        "type": "equation",
        "text": "$$\nf _ { C } ( x ) = \\frac { 1 } { \\pi } \\frac { \\gamma } { \\gamma ^ { 2 } + \\left( x - x _ { 0 } \\right) ^ { 2 } }\n$$",
        "text_format": "latex",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "通过分析可知，算法在迭代前期，应保持较大的变异步长，以扩大算法的全局寻优范围；在迭代后期，种群将逐渐聚集于全局最优解，变异步长应逐渐减小，以利于算法收敛。已知基于柯西分布的变异算子相比于高斯变异具有更大的变异尺度，适用于算法前期进化变异；基于高斯分布的变异算子适用于算法的后续迭代，使得算法能够更快地收敛。因此，受文献错误！未找到引用源。对于GSA算法进行混合变异处理的启发，提出一种改进的随迭代次数自适应调整的变异策略，定义如下：",
        "page_idx": 3
    },
    {
        "type": "equation",
        "text": "$$\nx ^ { \\prime } = x + \\lambda \\cdot x \\cdot \\left[ ( { \\frac { t ^ { 3 } } { T ^ { 3 } } } ) \\cdot N ( 0 , 1 ) + ( 1 - { \\frac { t ^ { 3 } } { T ^ { 3 } } } ) \\cdot C ( 0 , 1 ) \\right]\n$$",
        "text_format": "latex",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "其中： $x$ 表示克隆复制所得粒子位置信息； $x ^ { \\prime }$ 表示相应粒子变异后的新位置信息； $\\lambda$ 为调节系数，文中取 $\\lambda { = } 0 . 1$ ； $t$ 表示算法当前迭代次数； $T$ 表示算法最大迭代次数； $N ( 0 , 1 )$ 和 ${ \\cal C } ( 0 , 1 )$ 分别表示服从高斯分布与柯西分布的随机数。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "（4）克隆选择",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "经克隆变异之后的变异粒子和原始粒子组成新的粒子种群，表示为 $\\boldsymbol { x } ^ { \\prime \\prime } = \\left[ \\boldsymbol { x } ^ { \\prime } , \\boldsymbol { x } \\right]$ 。对于新种群 $x ^ { \\prime \\prime }$ ，根据粒子的位置信息分别计算其的亲和度值，并从中选取最优个体进入下一次迭代，实现种群压缩的同时，保证解的质量。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "3 基于改进GSA 算法的K-means 算法",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "针对 K-means 算法易受聚类中心而陷入局部最优解的问题，本文利用改进引力搜索算法优化聚类中心，且通过调整聚类数的取值得到不同聚类结果，提出了一种基于改进GSA算法的 K-means 算法，即 A2F-GSA-Kmeans。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "引力搜索算法是通过随机方式寻优不受初始解的影响，因此，本文首先为克服GSA算法易陷入局部最优解、发生早熟收敛现象等问题，提出了两种改进策略；然后，将全局搜索能力较强的改进GSA算法与K-means算法进行结合来优化聚类中心，提出一种新的聚类算法A2F-GSA-Kmeans 算法；最后，通过利用聚类评价函数对不同聚类结果进行评价，从而获取最佳聚类数。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "算法的具体步骤如下：",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "a)初始化参数。其中包括种群规模 $N$ ，算法最大迭代次数$T$ ，随机初始化粒子群体位置 $X _ { i }$ ，引力常量 $G _ { 0 }$ ，引力系数衰减因子 $\\alpha$ 中各个参数，最优粒子复制数 $M$ 。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "b)令算法最初的聚类数 $k = 2$ ，且 $k$ 的取值范围为 $\\left[ 2 , { k _ { \\operatorname* { m a x } } } \\right]$ ，其中 $k _ { \\mathrm { m a x } } \\leq { \\sqrt { n } }$ 。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "c)按照当前指定聚类数对数据集进行聚类，完成个体位置初始化，计算适应度值并选出当前最优解Gbest，并计算相应的聚类有效性指标。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "d)根据式（2）（3）更新粒子的惯性质量 $M _ { i } \\left( t \\right)$ 。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "e)根据式（7）（14）来更新万有引力系数 $G \\big ( t \\big )$ 。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "f)根据式（11）计算加速度 $a$ 。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "g)根据式（12）（13）更新粒子的速度和位置。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "h)克隆复制 $M$ 个当前种群最优粒子，根据式（21）进行变异操作，并从变异新种群中选择最优个体进入下一次迭代。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "i)判断是否达到最大迭代次数，如果是，则执行j)；否则，跳至c)。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "$\\mathrm { j } )$ 令 $k = k + 1$ ，直到 $k > k _ { \\mathrm { m a x } }$ ，转到 Step3。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "$\\mathbf { k } )$ 通过比较指标 $s i l$ 的大小，来寻找最佳的聚类数。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "4 实验结果与分析",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "本文采用MATLABR2015b开发环境进行仿真实验，并在Windous7操作系统的计算机上运行，来验证改进算法的有效性。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "4.1改进GSA算法性能分析",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "实验中，为了验证本文提出的A2F-GSA改进算法的性能，相关算法参数设置如表1所示，并引入12个基准测试函数（如表2所示）进行仿真实验，其中包括：连续单峰函数！ $( F _ { 1 } { \\sim } F _ { 4 } )$ ）、多峰高维函数（ $F _ { 5 } { \\sim } F _ { 8 }$ ）和多峰低维函数！ $( F _ { 9 } { \\sim } F _ { 1 2 } )$ 。",
        "page_idx": 3
    },
    {
        "type": "table",
        "img_path": "images/11ea859ff527ea2c7f39db558fc6560a54a6100f861e5c39830c19f449dea7b4.jpg",
        "table_caption": [
            "表1算法参数设置"
        ],
        "table_footnote": [],
        "table_body": "<html><body><table><tr><td>参数</td><td>描述</td><td>GSA</td><td>GG-GSA</td><td>A2F-GSA</td></tr><tr><td>N</td><td>种群规模</td><td>50</td><td>50</td><td>50</td></tr><tr><td>T</td><td>最大迭代次数</td><td>1000</td><td>1000</td><td>1000</td></tr><tr><td>G</td><td>引力常量初始值</td><td>100</td><td>100</td><td>100</td></tr><tr><td>α</td><td>引力系数衰减因子</td><td>20</td><td>30</td><td>一</td></tr><tr><td></td><td></td><td></td><td>𝐶 = 2−1.9(t /T)</td><td></td></tr><tr><td>𝐶、 C2</td><td>学习因子</td><td></td><td>c=t/T</td><td></td></tr></table></body></html>",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "表3展示了GSA 算法错误！未找到引用源。、GG-GSA 算法错误！未找到引用源·和 A2F-GSA算法运行 30次之后获得的基准测试函数值的平均值、最小值和标准差。图3展示了维度为30时，GSA算法与A2F-GSA算法优化基准测试函数时收敛过程对比图。图4为混合维度下，GSA算法与A2F-GSA算法优化基准测试函数时收敛过程对比图。",
        "page_idx": 3
    },
    {
        "type": "table",
        "img_path": "images/30a355c6a9f81e3e82566af8e9d5f768181a117de790f81f6f3197f092d335b0.jpg",
        "table_caption": [
            "表2基准测试函数"
        ],
        "table_footnote": [],
        "table_body": "<html><body><table><tr><td>函数名</td><td>表达式</td><td>维度</td><td>范围</td><td>理论</td></tr><tr><td>Schwefel 1.2</td><td>Dim F(X)=∑x² i=1</td><td>30</td><td>[-100,100]</td><td>0</td></tr></table></body></html>",
        "page_idx": 3
    },
    {
        "type": "table",
        "img_path": "images/e34678c4f66bd18620075146013da269acfc7eb5e39b863940e4ddea1bf84cfd.jpg",
        "table_caption": [
            "表3A2F-GSA与其他算法优化基准函数对比"
        ],
        "table_footnote": [],
        "table_body": "<html><body><table><tr><td>Schwefel 2.22</td><td>F(X)=∑｜x｜+Ix| i-1</td><td>30</td><td>[-10,10]</td><td>0</td></tr><tr><td>Schwefel 2.21</td><td>F(X)=max{|x |,1≤i≤D}</td><td>30</td><td>[-100,100]</td><td>0</td></tr><tr><td>Step</td><td>F(x)=∑(Lx +0.5]j²</td><td>30</td><td>[-100,100]</td><td>0</td></tr><tr><td>Ackley</td><td>-expDim +20+e Fx)=2exp(0 FM (∑cos(2πx））</td><td>30</td><td>[-32,32]</td><td>0</td></tr><tr><td>Griewank</td><td>F6(X)= + 4000 F7(X)= 1x²-Icos {sin²(3πy)</td><td>30</td><td>[-600,600]</td><td>0</td></tr><tr><td>Penalized</td><td>Dim +∑(y−1)[1i2(y +(yDom-1)} +u(x,10,100.4)</td><td>30</td><td>[-50,50]</td><td>0</td></tr><tr><td>Generalized Penalized</td><td>i-1 F8(X)=0.1{sin²(3𝜋x)+ ∑(x −1)[1+in²(3 +1)]+ (xDn-1)[1+sin(3 )} +∑u（(x,5.100.4) i=1</td><td>30</td><td>[-50,50]</td><td>0</td></tr><tr><td>Shekel</td><td>Fg(X)=</td><td>1 2</td><td>[-65.536.65 .536]</td><td>1</td></tr><tr><td>Goldstein-Pri ce</td><td>F0(X)=[1+(x + x+1)²(19-14x +3x² -14x+6xx+3x²)]×[30+(2x−3x² ×(18-32x +12x² +48x−36xx+27x2)]</td><td>2</td><td>[-2,2]</td><td>3</td></tr><tr><td>Hartman </td><td>F(x)=∑expt-∑a(x-)]</td><td>3</td><td>[0,1]</td><td>-3.86</td></tr><tr><td>Shekel's</td><td>𝑖=1 j=1 F(x)=-∑[(x-a)(x-a)+c]</td><td>4</td><td>[0,10]</td><td>-105</td></tr></table></body></html>",
        "page_idx": 4
    },
    {
        "type": "table",
        "img_path": "images/d7b9f05334d21e31dbe4f7874e4299e9f6325889b7af0382c6441988ac29f15c.jpg",
        "table_caption": [],
        "table_footnote": [],
        "table_body": "<html><body><table><tr><td>函数</td><td></td><td>GSA错误！未找到引</td><td>GG-GSA情误！未找到</td><td>A2F-GSA</td></tr><tr><td></td><td></td><td>用源。</td><td>引用源，</td><td></td></tr><tr><td>F1</td><td>Mean</td><td>2.244E - 17</td><td>5.417E - 23</td><td>7.032E - 32</td></tr><tr><td></td><td>Best</td><td>1.130E - 17</td><td>2.896E - 25</td><td>5.257E - 32</td></tr><tr><td></td><td>Std.Dev</td><td>6.862E - 18</td><td>2.201E - 22</td><td>3.017E - 32</td></tr><tr><td>F2</td><td>Mean</td><td>2.289E - 08</td><td>1.260E - 10</td><td>1.442E - 15</td></tr><tr><td></td><td>Best</td><td>1.802E - 08</td><td>3.510E - 12</td><td>1.282E - 15</td></tr><tr><td></td><td>Std.Dev</td><td>2.658E - 09</td><td>2.337E - 10</td><td>1.643E - 16</td></tr><tr><td>F3</td><td>Mean</td><td>3.567E - 02</td><td>1.741E - 09</td><td>3.443E - 15</td></tr><tr><td></td><td>Best</td><td>2.488E - 09</td><td>1.232E - 10</td><td>9.360E - 16</td></tr><tr><td></td><td>Std.Dev</td><td>1.318E - 01</td><td>1.877E - 09</td><td>3.004E - 15</td></tr><tr><td>F4</td><td>Mean</td><td>0.000E+00</td><td>0.000E+00</td><td>0.000E +00</td></tr><tr><td></td><td>Best</td><td>0.000E+00</td><td>0.000E+00</td><td>0.000E + 00</td></tr><tr><td></td><td>Std.Dev</td><td>0.000E+00</td><td>0.000E+00</td><td>0.000E + 00</td></tr><tr><td>F5</td><td>Mean</td><td>3.597E - 09</td><td>2.703E - 12</td><td>1.013E - 14</td></tr><tr><td></td><td>Best</td><td>2.407E - 09</td><td>4.343E - 13</td><td>7.994E - 15</td></tr><tr><td></td><td>Std.Dev</td><td>6.866E - 10</td><td>3.218E - 12</td><td>1.946E - 15</td></tr><tr><td>F6</td><td>Mean</td><td>4.343E + 00</td><td>1.170E + 00</td><td>4.045E - 02</td></tr><tr><td></td><td>Best</td><td>1.985E + 00</td><td>3.946E- 02</td><td>0.000E + 00</td></tr><tr><td></td><td>Std.Dev</td><td>1.735E + 00</td><td>8.023E- 01</td><td>4.322E - 02</td></tr><tr><td>F7</td><td>Mean</td><td>2.015E - 02</td><td>3.455E - 02</td><td>1.041E - 02</td></tr><tr><td></td><td>Best</td><td>7.913E - 20</td><td>1.277E - 27</td><td>1.571E - 32</td></tr><tr><td></td><td>Std.Dev</td><td>4.799E - 02</td><td>9.940E - 02</td><td>3.162E - 02</td></tr><tr><td>F8</td><td>Mean</td><td>1.590E - 03</td><td>7.325E - 04</td><td>3.663E- 04</td></tr><tr><td></td><td>Best</td><td>1.297E - 18</td><td>2.838E - 26</td><td>1.350E - 32</td></tr><tr><td></td><td>Std.Dev</td><td>5.395E - 03</td><td>2.788E - 03</td><td>2.006E - 03</td></tr><tr><td>F9</td><td>Mean</td><td>3.726E + 00</td><td>2.241E + 00</td><td>2.247E + 00</td></tr><tr><td></td><td>Best</td><td>9.980E- 01</td><td>9.980E- 01</td><td>9.980E - 01</td></tr><tr><td></td><td>Std.Dev</td><td>2.726E + 00</td><td>9.922E - 01</td><td>1.327E + 00</td></tr><tr><td>F10</td><td>Mean</td><td>3.000E+00</td><td>3.000E+00</td><td>3.000E + 00</td></tr><tr><td></td><td>Best</td><td>3.000E+00</td><td>3.000E+00</td><td>3.000E + 00</td></tr><tr><td></td><td>Std.Dev</td><td>4.807E - 15</td><td>2.566E - 15</td><td>5.470E - 16</td></tr><tr><td>F11</td><td>Mean</td><td>-3.863E+ 00</td><td>-3.863E+ 00</td><td>-3.863E + 00</td></tr><tr><td></td><td>Best</td><td>-3.863E + 00</td><td>-3.863E + 00</td><td>-3.863E+ 00</td></tr><tr><td></td><td>Std.Dev</td><td>2.710E - 15</td><td>2.710E - 15</td><td>2.220E - 16</td></tr></table></body></html>",
        "page_idx": 4
    },
    {
        "type": "table",
        "img_path": "images/bd36b23d5036639ed02b68c925326621a3aa518e0dc36ad6f8e3bf11d393b737.jpg",
        "table_caption": [],
        "table_footnote": [],
        "table_body": "<html><body><table><tr><td>F12</td><td>Mean</td><td>-1.029E + 01</td><td>-1.054E + 01</td><td>-1.054E + 01</td></tr><tr><td></td><td>Best</td><td>-1.054E + 01</td><td>-1.054E + 01</td><td>-1.054E + 01</td></tr><tr><td></td><td>Std.Dev</td><td>1.323E + 00</td><td>9.034E - 15</td><td>1.546E - 15</td></tr></table></body></html>",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "从表3可以看出，在12个基准测试函数中，针对单峰函数的优化求解，A2F-GSA算法对于函数 $F _ { 1 ^ { - } } F _ { 3 }$ 的收敛精度均明显优于其他算法，而对于步进函数 $F _ { 4 }$ ，经典GSA及其改进算法均可取得其理论最优解，且由图3(a)\\~(c)可知，收敛速度相对于经典的GSA算法显著提高。表明本文提出的自适应引力系数衰减方法能够有效平衡算法的全局探索能力和局部开发能力，从而有效提升算法的求解效果与效率。",
        "page_idx": 4
    },
    {
        "type": "image",
        "img_path": "images/4657e1fe5444b859a8d5ee7bf1c79006c585f80c83e18630a6dd56bf7012c94f.jpg",
        "img_caption": [
            "图3A2F-GSA与GSA优化基准测试函数（维度为30）收敛曲线"
        ],
        "img_footnote": [],
        "page_idx": 4
    },
    {
        "type": "image",
        "img_path": "images/e946660611201c4bb65141da860c6e26002088f1c920fe8d03a1362b42aacdaa.jpg",
        "img_caption": [
            "图4A2F-GSA与GSA优化基准测试函数（混合维度）收敛曲线"
        ],
        "img_footnote": [],
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "针对具有多个局部极值的多峰函数的优化求解，从表3和图3(d)\\~(f)可知，在维度为30的测试条件下，A2F-GSA算法对于函数 $F _ { 5 ^ { - } } F _ { 8 }$ 的优化精度与速度显著优于其他算法，表明将免疫克隆选择机制引入A2F-GSA 算法中，能够使得算法有效跳出局部最优，改善算法早熟收敛现象。而在混合维度下，函数$F _ { 9 }  – F _ { 1 2 }$ 相比于高维多峰函数具有较少的局部极值点，由表3和图 4(a)(b)可知，A2F-GSA 算法对于F11、 $F _ { 1 2 }$ 、 $F _ { 1 3 }$ 的优化求解均取得相应的理论最优解，且标准差值均低于其他算法，只是对于函数 $F _ { 9 }$ 的优化效果略劣于GG-GSA算法，但相比于经典GSA算法仍有显著提高。",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "综上所述，对于文中选取的12个基准测试函数，本文提出的A2F-GSA算法具有最优的求解精度、收敛速度和鲁棒性。",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "4.2改进聚类算法性能分析 ",
        "text_level": 1,
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "为了验证本文提出的基于改进的引力搜索算法的K-means算法的有效性，从而寻找最佳聚类数，本文采用公开测试数据集 UCI错误！未找到引用源。库中的数据集 Normal07、Cancer、Iris、Wine、Glass、Abalone 进行实验仿真。且数据集的特征分布如表4所示。",
        "page_idx": 5
    },
    {
        "type": "table",
        "img_path": "images/970af1bee8200e48672106b0ae376fdc435bfc722e11b0b3fff2c7ccc7ce2832.jpg",
        "table_caption": [
            "表4数据集特征描述"
        ],
        "table_footnote": [],
        "table_body": "<html><body><table><tr><td>数据集</td><td>大小</td><td>特征数</td><td>类别数</td></tr><tr><td>Normal07</td><td>7000</td><td>2</td><td>7</td></tr><tr><td>Cancer</td><td>569</td><td>30</td><td>2</td></tr><tr><td>Iris</td><td>150</td><td>4</td><td>3</td></tr><tr><td>Wine</td><td>178</td><td>13</td><td>3</td></tr><tr><td>Glass</td><td>214</td><td>9</td><td>6</td></tr><tr><td>Abalone</td><td>4177</td><td>7</td><td>23</td></tr></table></body></html>",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "算法中的参数设置采用A2F-GSA算法的基本参数设置，聚类数的搜索范围为 $\\left[ 2 , { k _ { \\operatorname* { m a x } } } \\right]$ ，其中 $k _ { \\mathrm { m a x } } \\leq \\sqrt { n }$ 。实验中，使用本文提出的A2F-GSA-Kmeans 算法和经典的GSA算法对所选取的测试数据集各自运行20次，分别记录20次中得到正确聚类结果的次数，通过计算得到算法的聚类准确率，计算公式如下：",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "聚类准确率（%）=得到正确聚类结果的次数 $\\times 1 0 0 \\%$ 实验运行总次数",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "并与文献错误！未找到引用源。中基于改进蜂群算法的K-means算法进行比较，实验结果如表5所示。",
        "page_idx": 5
    },
    {
        "type": "table",
        "img_path": "images/c2d62a638f59d6455e8d8e83ba12559ceb00664f59184dc46b253b429b5da407.jpg",
        "table_caption": [
            "表5算法准确率对比"
        ],
        "table_footnote": [],
        "table_body": "<html><body><table><tr><td rowspan=\"2\">算法</td><td colspan=\"6\">聚类准确率%</td></tr><tr><td>Normal07</td><td>Cance</td><td>Iris</td><td>Wine</td><td>Glass</td><td>Abalone</td></tr><tr><td>KsAns</td><td>100</td><td>50</td><td>90</td><td>70</td><td>40</td><td>30</td></tr><tr><td>Improved- ABC- Kmean错误！ 未找到引用源。</td><td></td><td></td><td>90</td><td></td><td>50</td><td>一</td></tr><tr><td>A2F-GSA- Kmeans</td><td>100</td><td>95</td><td>100</td><td>95</td><td>90</td><td>70</td></tr></table></body></html>",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "由表5可知，对于数据维度低且分布明显分离的Normal07，每次运行均能得到正确的聚类数；对于数据分离不明显的Iris和Wine，A2F-GSA-Kmeans算法得到聚类准确率略优于经典的GSA聚类算法。而对于复杂数据集Glass、高维数据集Cancer,A2F-GSA-Kmeans 算法的聚类准确率明显优于其他算法，从而验证了本文改进算法的有效性。然而，对于带有噪声的数据集Abalone，均未能取得较好的聚类准确率，有待进一步的研究。",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "5 结束语",
        "text_level": 1,
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "本文首先提出一种自适应引力系数衰减因子函数来代替常量值，使得引力系数 $G$ 从大到小非线性变化，有效提高算法的全局探索能力和局部开发能力；同时，将免疫克隆选择机制引入GSA算法中，能够使算法有效跳出局部最优，且改善算法早熟收敛现象。在12个基准测试函数上的仿真实验结果，验证了本文所提出的A2F-GSA 算法相比于其他算法具有更好的优化收敛性能。然后结合A2F-GSA 算法和K-means 算法提出一种新的A2F-GSA-Kmeans 聚类算法。并在6个UCI测试数据集上进行实验表明，相比于基于经典GSA和改进蜂群算法的K-means算法，本文提出的A2F-GSA-Kmeans算法的聚类质量有明亚捉向。",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "参考文献：   \n[1]Chen T W,Ikeda M. Design and implementation of low-power hardware architecture with single-cycle divider for on-line clustering algorithm [J]. IEEE Trans on Circuits& Systems I Regular Papers,2O13,60 (8): 2165-2176.   \n[2]杨菊蜻，张达敏．基于改进BA算法的K-means聚类[J].计算机应用研 究，2018,35(05):1454-1457.(Yang Juqing，Zhang Damin.K-means clustering algorithm based on improved BA algorithm [J].Application Research of Computers,2018,35 (05): 1454-1457. )   \n[3] 于佐军，秦欢．基于改进蜂群算法的 K-means 算法[J].控制与决策， 2018,33(1):181-185.(Yu Zuojun,Qin Huan.K-meansalgorithm based on improved artificial bee colony algorithm [J].Control and Decision, 2018, 33 (1): 181-185. )   \n[4]Rashedi E,Nezamabadi-Pour H,Saryazdi S.GSA: a gravitational search algorithm [J]. Information Sciences.2009,179 (13): 2232-2248.   \n[5]Liu Chao,Niu Peifeng,Li Guoqiang,et al.Ahybrid heat rate forecasting model using optimized LSSVM based on improved GSA [J].Neural Processing Letters,2017,45 (1): 299-318.   \n[6]Sun Genyun, Zhang Aizhu,Wang Zhenjie,et al.Locally informed gravitational search algorithm [J]. Knowledge-Based Systems,2016,104 (C): 134-144.   \n[7]Mirjalili S,Gandomi A H.Chaotic gravitational constants for the gravitational search algorithm [J].Applied Soft Computing，2017,53: 407-419.   \n[8]Mirjalili S,Lewis A. Adaptive gbest-guided gravitational search algorithm [J]. Neural Computing & Applications,2014,25 (7-8): 1569-1584.   \n[9]Darzi S,Kiong T S,Islam M T,et al.A memory-based gravitational search algorithm for enhancing minimum variance distortionless response beamforming [J]. Applied Soft Computing,2016,47(C): 103-118.   \n[10] Vijay K B,K.V.Arya,An effective gbest-guided gravitational search algorithm for real-parameter optimization and its application in training of feedforward neural networks [J].Knowledge-Based Systems,2O18,143: 192-207.   \n[11]朱连江，马炳先，赵学泉．基于轮廓系数的聚类有效性分析[J].计算 机应用，2010,30 (S2): $1 3 9 - 1 4 1 + 1 9 8$ (Zhu Lianjiang,Ma Bingxian,Zhao Xuequan.Clustering validity analysis based on silhouette coefficient [J]. Journal of Computer Applications,2010,30 (S2): 139-141 $+ 1 9 8$ ）   \n[12]范炜锋．万有引力搜索算法的分析与改进 [D]．广州：广东工业大学， 2014.(Fang Weifeng.Analysis and improvementof gravitational search algorithm [D]. Guangzhou: Guangdong University of Technology,2014.) ",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "[13]蒋建国，谭雅，董立明，等．改进的万有引力搜索算法在边坡稳定分析 中的应用[J].岩土工程学报,2016,38(3):419-425.(Jiang Jianguo,Tan Ya,Dong Liming，et al.Application of modified gravitational search algorithm in slope stability analysis [J].Chinese Journal of Geotechnical Engineering,2016,38 (3): 419-425.) ",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "[14]赵辉，李牧东，翁兴伟．分布式人工蜂群免疫算法求解函数优化问题 [J].控制与决策,2015,30(7):1181-1188.(Zhao Hui,Li Mudong,Weng Xingwei.Distributed artificial bee colony immune algorithm for the problems of function optimization [J].Control and Decision,2O15,30(7): 1181-1188.) ",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "[15]吴建辉，章兢，李仁发，等．多子种群微粒群免疫算法及其在函数优化 中应用[J].计算机研究与发展，2012,49(9):1883-1898.(Wu Jianhui, Zhang Jing,Li Renfa,et al.A multi-subpopulation PSO immune algorithm and its application on function optimization [J].Journal of Computer Research and Development,2012,49 (9): 1883-1898.) ",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "[16] DeCastro L N,Zuben V. Learning and optimization using the clonal seletion.Issue on Artificial Immune System (AIS).2002,6(3): 239-351.   \n[17]舒万能，丁立新．克隆选择算法的优化和品质因数[J].软件学报, 2016,27 (11): 2763-2776.(Shu Wanneng,Ding Lixin. Optimization and quality factor of clonal selection algorithm [J]. Journal of Software,2016, 27 (11): 2763-2776. )   \n[18]Mohammadi M,RaahemiB,Akbari A,et al.Improving linear discriminant analysis with artificial immune system-based evolutionary algorithms [J]. Information Sciences,2012,189(7): 219-232.   \n[19] Zhang Nan,Li Chaoshun，Li Ruhai,et al.A mixed-strategy based gravitational search algorithm for parameter identification of hydraulic turbine governing system [J].Knowledge-Based Systems,2O16,109: 218-237.   \n[20] University of California, Irvine.UCI machine learning repository [DB/OL]. [2013-06-19]. http://archive.ics.uci. edu/ml/datasets. html ",
        "page_idx": 6
    }
]