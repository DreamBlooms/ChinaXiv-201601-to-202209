[
    {
        "type": "text",
        "text": "1 纵向汉明距离判别法：对潜在属性的发展追踪",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "2 刘耀辉」 陈琦鹏」徐慧颖」詹沛达1.,2\\*\\*  \n3 ('浙江师范大学教师教育学院心理系，金华321004;  \n4 2浙江省智能教育技术与应用重点实验室，金华 321004)",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "6 摘要 研究通过在纵向诊断数据分析中引入计算简单、耗时少的汉明距离判别法(HDD)，提出了纵向  \n7 HDD (Long-HDD)。与 HDD 相比，Long-HDD 额外使用汉明距离刻画个体在相邻时间点上对属性掌握  \n8 的相依性，以利用前一时间点信息提高当前时间点的分类准确性。三个模拟研究的结果主要表明：在  \n9 分析纵向诊断数据时，与参数化模型相比，Long-HDD 的分类准确性几乎不受样本量影响，在样本量较小时表现更优；且其计算耗时更少，更有利于提供及时性诊断反馈。实证研究结果表明 Long-HDD可用于分析实践测评数据，且其追踪诊断结果与参数化模型的存在一致性。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "关键词认知诊断；非参数分类法；纵向数据分析；汉明距离",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "1引言",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "追踪学生知识和技能的变化，不仅有利于评估教学方法的有效性，还可以绘制出学生的发展轨迹，有利于优化教学过程和实施补救教学(詹沛达等,2021)。对学生发展轨迹的追踪依赖于多次测量所收集的纵向数据。近年来，纵向认知/学习诊断，即评估学生的潜在属性(如，知识和技能)并确定其在一个时期内优势与不足，逐渐受到研究者和教育者的关注(e.g.,Zhan,2020b；王立君等,2020)。学者们提出了不同的纵向诊断分类模型(diagnostic classification models,DCMs)为纵向诊断数据分析提供方法支持(见 Zhan,2020b；詹沛达等,2021)，如，基于高阶潜在结构模型的纵向DCM和基于潜在转换分析的纵向 DCM。这些研究结果表明，参数化纵向DCMs可以有效诊断学生个体或群体的学习成长轨迹。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "然而,参数化模型的实际应用可能会遇到一些障碍，特别是在纵向诊断最适用的小规模教育测评(如,班级或学校水平的测评)中。例如，专家判定的认知假设(如，连接或分离缩合规则)与学生实际应用的存在偏差，进而选用了基于错误认知假设的DCM；需要大样本以保证参数估计和结果分类的准确性(Chiu&Kohn,2015)；在应用相对复杂的模型时，分析人员也需要一定的编程能力。此外，参数化模型通常需要较多的计算时间，特别是对于一些使用马尔科夫链蒙特卡洛(MCMC)算法的纵向 DCMs。这些障碍无疑提高了一线教育工作者应用参数化模型的难度，不利于其在实践教学环境中的应用和推广。",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "为避免上述问题，研究者们提出了一些非参数分类(nonparametric classfication，NPC）法(Chiu,Douglas,et al.,2009; Chiu& Douglas,2013; Chiu,et al.,2018; Wang & Douglas,2015；康春花等,2019)。与参数化DCM相比，NPC 法因不需要进行参数估计，所以它对样本量没有明确要求；即 NPC 法的应用摆脱了对大样本量的依赖，即使样本量为1也可以使用。此外，NPC 法不需要考虑参数化模型可能存在的参数估计不收敛问题，并且在各种认知假设下均有良好的表现(Chiu& Douglas,2013;Wang &Douglas,2015; Chiu et al.,2018; Akbay,2016)。同时，由于NPC 法计算简单，其对应用者的编程水平要求相对较低，并且可以实现对被试的快速分类，便于提供及时性诊断反馈。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "然而，目前尚未有研究试图使用 NPC 法来分析纵向认知诊断数据；即 NPC 法在追踪学生发展方面的心理测量学表现还不明晰。随着“为学习而测评”理念的普及(詹沛达等,2021)，考虑到实践教学对纵向认知诊断的需求以及NPC 法的简便性，将两者结合并探究NPC 法在追踪学生发展方面的心理测量学表现是值得尝试的。为此，本研究的主要目的是提出一种纵向 NPC 法，以期实现对个体属性掌握情况变化的追踪。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "首先，回顾两种相关方法：一个是有代表性的参数化纵向 DCM——纵向高阶 DINA (Long-DINA)模型(Zhan,Jiao,Liao,&Li,2019)；另一个是应用于横断诊断数据的汉明距离判别法(Hamming distancediscrimination,HDD)(Chiu& Douglas,2013)。其次，介绍了拟提出的纵向 NPC 法—纵向 HDD(longitudinal HDD,Long-HDD)。接着通过模拟研究评估新方法在纵向诊断测评数据分析中的表现，并与横断 HDD 和Long-DINA模型进行对比研究。然后，以一则实证数据分析为例呈现新方法的实践可应用性。最后，总结该研究的一些发现并讨论未来研究方向。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "2 相关方法简介",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "2.1 Long-DINA模型",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "已有研究表明，Long-DINA 模型在纵向认知诊断数据分析中具有良好的心理测量学表现(Zhan,2020b;Zhan,Jiao,Liao,&Li,2019)。该模型可表示为：",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "一阶：",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\nP ( y _ { n i t } = 1 | \\mathbf { a } _ { n t } , g _ { i t } , s _ { i t } ) = g _ { i t } + ( 1 - g _ { i t } - s _ { i t } ) { \\prod } _ { k = 1 } ^ { K } \\mathbf { a } _ { n k t } ^ { q _ { i k t } } ~ ,\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "二阶：",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\nP ( \\mathfrak { a } _ { n k t } = 1 | \\theta _ { n t } , \\beta _ { k } , \\delta _ { k } ) = \\frac { \\exp ( \\beta _ { k } \\theta _ { n t } - \\delta _ { k } ) } { 1 + \\exp ( \\beta _ { k } \\theta _ { n t } - \\delta _ { k } ) } ,\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "三阶：",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "$$\n\\boldsymbol { \\Theta } _ { n } = ( \\mathsf { \\Theta } _ { n 1 } , . . . , \\mathsf { \\Theta } _ { n T } ) ^ { \\prime } \\sim M V N _ { T } ( \\boldsymbol { \\mathsf { \\mu } } , \\boldsymbol { \\Sigma } ) ,\n$$",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "其中, $g _ { i t }$ 和 $s _ { i t }$ 分别表示时间点 $\\mathbf { \\chi } _ { t }$ 上题目 $i$ 上的猜测和失误参数; $\\mathbf { { a } } _ { n t } = ( \\mathbf { { a } } _ { n 1 t } , . . . , \\mathbf { { a } } _ { n K t } ) ^ { \\top }$ 表示时间点 $\\mathbf { \\chi } _ { t }$ 上被试 $n$ 的属性掌握向量， $\\mathfrak { a } _ { n k t } \\in \\{ 0 , 1 \\}$ ·， $q _ { i k t }$ 表示时间点 $t$ 上题目 $i$ 是否考查属性 $k$ ， $q _ { i k t } \\in \\{ 0 , 1 \\}$ ; $\\theta _ { n t }$ 为时间点 $t$ 上被试 $n$ 的高阶能力； $\\beta _ { k }$ 和 $\\delta _ { k }$ 分别表示所有时间点上属性 $k$ 的斜率和难度参数； $\\mathbf { \\mu } = ( \\mu _ { 1 } , . . . , \\mu _ { T } ) ^ { \\dagger }$ 为多元正态分布的均值向量， $\\pmb { \\Sigma }$ 是该分布下的协方差矩阵，",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\n\\begin{array} { r } { \\Sigma = \\left[ \\begin{array} { c c c } { \\sigma _ { 1 } ^ { 2 } } & { } & { } \\\\ { \\vdots } & { \\ddots } & { } \\\\ { } & { } & { \\ddots } \\\\ { \\sigma _ { 1 T } } & { \\cdots } & { \\sigma _ { T } ^ { 2 } } \\end{array} \\right] , } \\end{array}\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "其中 $\\sigma _ { I T }$ 表示时间点1的和时间点 $T$ 的高阶能力之间的协方差。另外，作为纵向测验的起点及后续时间点的参考点， $\\theta _ { n 1 }$ 被约束为服从标准正态分布。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "2.2 HDD 法",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "如未明确说明，文中“HDD”仅指代横断 HDD。HDD是一种易于理解且常见的 NPC 法，它比较观察作答向量(ORP)和理想作答向量(IRP)之间的汉明距离。其中，汉明距离是两个相同长度的向量在相应位置上不同元素的个数：",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\n\\begin{array} { r } { d _ { h m } ( { \\bf A } , { \\bf B } ) = \\sum _ { i = 1 } ^ { I } \\lvert A _ { i } - B _ { i } \\rvert , } \\end{array}\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "其中 $A _ { i } - B _ { i } \\vert = 1$ 表示向量 $\\mathbf { A }$ 中第 $i$ 个元素与向量 $\\mathbf { B }$ 中的第 $i$ 个元素不相等，反之 $\\mid A _ { i } - B _ { i } \\mid = 0$ 则表示相等。  \n例如，(1,1,0,1)和(1,0,0,1)之间的汉明距离为1。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "HDD 使用与 ORP 距离最近的 IRP 所对应的属性向量作为学生的属性掌握向量(AMP)(Chiu &Douglas,2013；罗照盛等,2015)。HDD 中，学生 $n$ 的ORP与第 $c ( c { = } 1 , 2 , . . . , 2 ^ { K } )$ 个IRP之间的汉明距离可以表示为：",
        "page_idx": 2
    },
    {
        "type": "equation",
        "text": "$$\n\\begin{array} { r } { d _ { h m } ( O R P _ { n } , I R P _ { c } ) = \\sum _ { i = 1 } ^ { I } \\lvert \\ y _ { n i } - \\mathbf y _ { c i } ^ { * } \\rvert , } \\end{array}\n$$",
        "text_format": "latex",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "其中， $y _ { n i }$ 表示学生 $n$ 在题目 $i$ 上的作答结果， $y _ { \\ c i } ^ { * }$ 为第 $\\boldsymbol { c }$ 个IRP的第 $i$ 个元素。当仅有一个IRP与ORP的距离最短时，与这个IRP所对应的属性向量则被视为该学生的AMP；而当有多个IRP与ORP 的距离最短时，则可以通过R方法(随机抽取法)、B方法(贝叶斯方法)和W方法(加权汉明距离法)(对应图1中的矩形虚线部分)，筛选出其认为最有可能的AMP(Chiu＆ Douglas，2013；罗照盛等，2105；康春花等，2017)。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "需要注意的是HDD也可用于分析纵向诊断数据，这与使用横断参数模型分析纵向诊断数据的做法类似(Zhan,2020a)。具体而言，使用 HDD 分析纵向诊断数据时，有两种计算策略：一种是重复使用 HDD分别分析不同时间点的数据(即独立计算策略的HDD，记为HDD-D)，另一种是将所有时间点数据整合为一个数据并使用 HDD 进行一次性分析(即同时性计算策略的 HDD，记为 HDD-T)。理论上两种计算",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "1 策略的结果相同；基于模拟研究的数据分析结果也表明两者的表现几乎一样且HDD-D的计算耗时更少  \n2 （理论说明及数据分析结果见附录）。为精简，下文仅使用HDD-D。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "43Long-HDD 方法的提出",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "通常，纵向研究中，在不同时间点上指代同一潜在特质的多个潜在变量(如，公式2中指代同一潜在特质——高阶能力——的多个潜在变量 $\\left. \\Theta _ { n t } \\right.$ 之间是高相关的。在Long-DINA中，这种相关性可由多元正态分布来表示(见公式3)。同样，在NPC 法中，如何在不涉及模型参数的情况下，处理相邻时间点间AMP 的相关性是一个亟需解决的问题。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "在对虚拟测评过程性数据的分析中(刘耀辉等,2022)，有研究者使用了距离判别的方法来处理不同行为序列之间的关联性，如汉明距离(Bergner et al.,2014)和编辑距离(Hao et al.,2015)。在解决问题时，不同个体的动作序列之间距离越近，表明他们的动作序列越一致、解决问题能力越接近。换句话说，动作序列之间距离越近，它们之间相关性就越高，越倾向于被分为同一类。受此启发，在提出的纵向 NPC法中，汉明距离将被再次用来表示同一学生在不同时间点上AMP之间的关联性。本研究假设同一学生在相邻时间点上的AMP 是高度相关的，因此该学生在两个相邻时间点上AMP之间的汉明距离也应是最小的。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "Long-HDD 用汉明距离来表示同一学生相邻时间点上对属性掌握情况的相关性或依赖性，以利用前一个时间点的信息来提高当前时间点的分类精度。Long-HDD 中，同一学生相邻时间点上AMP之间的相关性或依赖性可表示为：",
        "page_idx": 3
    },
    {
        "type": "equation",
        "text": "$$\n\\begin{array} { r } { d _ { h m } ( A M P _ { n t } , \\mathbf { \\vec { \\alpha } } _ { n c ( t + 1 ) } ^ { * } ) = \\sum _ { k = 1 } ^ { K } \\bigl | \\alpha _ { n k t } - \\alpha _ { n c k ( t + 1 ) } ^ { * } \\bigr | , } \\end{array}\n$$",
        "text_format": "latex",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "其中, $\\mathrm { A M P } _ { n t }$ 为被试 $n$ 在时间点 $\\mathbf { \\chi } _ { t }$ 上的AMP, $\\boldsymbol { \\mathbf { \\check { a } } } _ { n c ( t + 1 ) } ^ { * }$ 为时间点 $^ { t + 1 }$ 上与学生 $n$ 的 ORP具有最小汉明距离的 IRP集合所对应的属性模式集合中的第 $\\mathbf { \\Psi } _ { c }$ 个属性向量， $\\boldsymbol { \\mathfrak { a } } _ { n c k ( t + 1 ) } ^ { * }$ 则为该第 $\\mathbf { \\Psi } _ { c }$ 个属性向量中的第 $k$ 个属性的状态(0 或1)。 ${ \\bf { a } } _ { n k t }$ 为时间点 $\\mathbf { \\chi } _ { t }$ 上学生 $n$ 对属性 $k$ 的掌握状态(即时间点 $t$ 上学生 $n$ 的AMP中的第 $k$ 个属性)。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "如图1所示，在某一特定的时间点内，Long-HDD与HDD在计算方式上是一致的。两者的主要区别是在判断学生 $n$ 在时间点2的AMP(即 $\\mathbf { A M P } _ { n 2 } .$ )时，须额外计算IRP集合2中每个IRP所对应的属性向量与该学生在时间点1的AMP(即 $\\mathrm { A M P } _ { n 1 } \\$ )之间的汉明距离(见公式7)；然后使具有最小汉明距离的属性向量作为该学生时间点2上的 $\\mathbf { A M P } ^ { 2 }$ 。总的来说，该方法通过多次使用汉明距离来联接学生在相邻时间点上AMP之间的关联性。当 $T = 1$ 或在时间点1上，Long-HDD 等同于HDD",
        "page_idx": 3
    },
    {
        "type": "image",
        "img_path": "images/0ba974a93f26bea81c0b3a364a0f3221fdff79b93775f96243d18d4b5cf76b4d.jpg",
        "img_caption": [
            "图1 Long-HDD 应用流程图."
        ],
        "img_footnote": [],
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "4模拟研究",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "本文开展三个模拟研究来探究Long-HDD 在纵向诊断数据分析中的表现，即探究在追踪学生发展时它是否能提供准确的分类结果；并且比较Long-HDD、HDD 和Long-DINA 模型的分类准确性。",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "4.1 模拟研究1",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "4.1.1 研究设计及数据生成",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "本部分研究包含5个自变量：(1)考虑到NPC 法的适用情境，本研究侧重于小规模测评，样本量 $N =$ 25、50、100和300；(2)每个时间点上的题目数量 $I = 2 5$ 和 50；(3)每个时间点上所考查的属性数量 $K =$ 3 和5；(4)测试时间点数量 $T = 2$ 和3；(5)数据分析方法 $M =$ Long-HDD、HDD 和 Long-DINA。",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "1 在每个时间点Q矩阵中，将构成可达/单位矩阵的前 $K$ 道题目设定为锚题，并在所有时间点固定不  \n2 变(Zhan,Jiao,Liao,&Li,2019)。除锚题外，其他题目所考察的属性向量是以相同概率从包含 ${ \\geq } 2$ 个属性  \n3 的属性向量中随机提取。考虑到实际测验中，题目的猜测和失误概率可能呈现负相关(Zhan,Jiao,Liao,&  \n4 Bian,2019)，在每个时间点上题目 $i$ 的猜测参数 $g _ { i t }$ 和失误参数 $s _ { i t }$ 由二元正态分布产生：",
        "page_idx": 5
    },
    {
        "type": "equation",
        "text": "$$\n\\binom { l o g i t ( g _ { i t } ) } { l o g i t ( s _ { i t } ) } \\sim N ( \\mu , \\Sigma ) = N ( \\binom { - 2 . 1 9 7 } { - 2 . 1 9 7 } , \\binom { 1 } { - 0 . 6 } \\quad \\hat { 1 } ^ { - 0 . 6 } ) ) .\n$$",
        "text_format": "latex",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "6 该设定下所有题目的猜测和失误概率服从正偏态分布(平均值 ${ \\approx } 0 . 1$ ，最小值 ${ \\approx } 0 . 0 1$ ，最大值 ${ \\approx } 0 . 6 )$ 。各时  \n7 间点上锚题的猜测和失误概率均被固定为0.1。",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "为保证方法之间对比的公平性，本研究未直接采用Long-HDD 或 Long-DINA模型作为数据生成模型。被试的属性掌握增长按如下方法生成：在第一个时间点，每个学生的真实AMP是以相同的概率从所有可能的 $2 ^ { K }$ 个属性向量中随机抽取。在随后的时间点,每个学生的真实AMP的生成参考了Li等(2016)的研究。具体而言，设定所有属性的相邻时间点之间的转移概率相等：",
        "page_idx": 5
    },
    {
        "type": "equation",
        "text": "$$\n\\begin{array} { r } { \\mathrm { P } ( \\alpha _ { n k t }  \\alpha _ { n k ( t + 1 ) } ) = \\{ \\begin{array} { l l } { \\mathrm { P } ( 0  0 ) = 0 . 8 } \\\\ { \\mathrm { P } ( 0  1 ) = 0 . 2 } \\\\ { \\mathrm { P } ( 1  0 ) = 0 . 0 5 ^ { \\cdot } } \\\\ { \\mathrm { P } ( 1  1 ) = 0 . 9 5 } \\end{array}  } \\end{array}\n$$",
        "text_format": "latex",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "最后，根据生成的真实AMP、题目参数(异常反应概率)和Q矩阵，分别在各时间点上使用 DINA模型生成观察数据。每种模拟条件下生成50 批数据。",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "4.1.2分析",
        "text_level": 1,
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "每个模拟条件下均使用 Long-HDD、HDD-D 和 Long-DINA 分析数据。对 HDD-D 而言，重复使用HDD 分析每个时间点上的数据。对Long-HDD 而言，对每个时间点的数据逐一进行分析，即基于HDD,结合前一个时间点的分类结果，辅以判定当前时间点上学生的 AMP。对Long-DINA 模型而言，采用同时性参数估计策略(Zhan,2020a)，这涉及到将多个时间点的作答数据重新整合为一个作答矩阵，然后将其作为一个整体进行分析。使用 MCMC 算法实现对Long-DINA模型的参数估计：包含两条链，每条链采样 8,000次，前 5,000 次用于预热；根据潜在量尺缩减因子 $( \\mathrm { P S R F } ) { < } 1 . 1$ 的标准，待估计参数均已收敛。使用属性向量正确分类率(PCCR)和纵向 PCCR(LPCCR)(Zhan,Jiao,Liao,&Li,2019)评估各方法的分类准确性： $\\begin{array} { r } { \\mathrm { P C C R } _ { t } \\ = \\ \\sum _ { r = 1 } ^ { R } \\sum _ { n = 1 } ^ { N } \\frac { I [ \\widehat \\alpha _ { n t r } - \\alpha _ { n t } ] } { N R } , \\ \\mathrm { L P C C R } \\ = \\ \\sum _ { r = 1 } ^ { R } \\sum _ { n = 1 } ^ { N } I [ \\forall t , \\widehat \\alpha _ { n t r } = \\alpha _ { n t } ] / N R } \\end{array}$ ，其中，I-]是一个指示函数， $N$ 是样本量， $R$ 是迭代次数， $t$ 为第 $\\mathbf { \\chi } _ { t }$ 个时间点， $\\widehat { \\mathbf { d } } _ { n t }$ 和 ${ \\bf { \\alpha } } _ { { \\bf { \\alpha } } _ { n t } }$ 分别表示学生 $n$ 在时间点 $t$ 的估计AMP 和真实AMP。",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "4.1.3 结果",
        "text_level": 1,
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "图2呈现了三种方法在不同模拟条件下各时间点的PCCR和LPCCR。首先，与已有研究的发现类似(Chiu &Douglas,2013;Zhan,Jiao,Liao,&Li,2019；康春花等,2017)，随着所测属性数量的增加和测验时间点数量的增加，三种方法的分类准确性均有所下降。相比之下，随着题目数量的增加，三种方法的分",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "1 类准确性均有所上升。其次，样本量对 HDD-D 和 Long-HDD 的影响较小。且在所有条件下，Long-HDD  \n2 的分类准确性均高于HDD-D的，表明在分析纵向数据时，考虑相邻时间点AMP之间的相关性或依赖性  \n3 是必要的。然后，当Long-HDD 和 Long-DINA 进行比较式时，前者的相对优势在样本量较小的时候更  \n4 为明显，而后者在样本量增加至100 以上时显示出与前者匹配的分类准确性，且后者的相对优势随样本  \n5 量的继续增加而增加。",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "4.2 模拟研究2",
        "text_level": 1,
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "4.2.1 研究设计、数据生成和分析",
        "text_level": 1,
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "9 研究2为进一步考察在小样本条件下Long-HDD在不同大小的属性转移概率下的表现。更高的属  \n.0 性转移概率意味着有更大比例的学生对属性的掌握状态发生变化。本研究包含4自变量：(1）同一属性在相邻时刻间的转移概率 $\\operatorname* { P } ( 0 \\to 1 ) = 0 . 5$ (中等水平)和 $\\operatorname { P } ( 0 \\to 1 ) = 0 . 8$ (高水平)，见公式(10);(2）每个时间点上的题目数量 $I = 2 5$ 和50；(3）每个时间点上所考查的属性数量 $K = 3$ 和5；(4）数据分析方法 $M =$ Long-HDD、HDD-D 和 Long-DINA。另外， $\\scriptstyle { T = 3 }$ 和 $N { = } 2 5$ ; $\\mathrm { ~ Q ~ }$ 矩阵和题目参数的设置、观察数据的生成，以及分析方法同研究一保持一致。",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "中等水平增长： $\\begin{array} { r } { \\mathrm { P } ( \\alpha _ { n k t }  \\alpha _ { n k ( t + 1 ) } ) = \\{ \\begin{array} { l l } { \\mathrm { P } ( 0  0 ) = 0 . 5 } \\\\ { \\mathrm { P } ( 0  1 ) = 0 . 5 } \\\\ { \\mathrm { P } ( 1  0 ) = 0 . 0 5 } \\\\ { \\mathrm { P } ( 1  1 ) = 0 . 9 5 } \\end{array}  } \\end{array}$ ?高水平增长：P(αnkt →αnk(t+1))= $\\begin{array} { r } { \\mathrm { P } ( \\alpha _ { n k t }  \\alpha _ { n k ( t + 1 ) } ) = \\{ \\begin{array} { l l } { \\mathrm { P } ( 0  0 ) = 0 . 2 } \\\\ { \\mathrm { P } ( 0  1 ) = 0 . 8 } \\\\ { \\mathrm { P } ( 1  0 ) = 0 . 0 5 } \\\\ { \\mathrm { P } ( 1  1 ) = 0 . 9 5 } \\end{array}  } \\end{array}$ ：",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "4.2.2 结果",
        "text_level": 1,
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "图3呈现了三种方法在不同模拟条件下的PCCR和LPCCR。结果表明三种方法的判准率的相对优劣在中等水平增长和高水平增长条件下相对稳定；其中，Long-HDD 的判准率仍然是最高的。结合研究1和研究2的结果表明，在小样本条件下，Long-HDD 的判准率优于HDD-D和Long-DINA的，且该优势几乎不受出现掌握状态变化的学生的比例的影响。",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "4.3 模拟研究3",
        "text_level": 1,
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "4.3.1 研究设计、数据生成和分析",
        "text_level": 1,
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "本研究拟在小样本条件下采用Long-DINA生成数据；此时，若Long-HDD的表现仍优于或不输于Long-DINA的，则可进一步凸显在小样本测验情境下使用Long-HDD 的相对优势。对此，本研究仅包含1个自变量：属性数量 $K = 3$ 和5；并将样本量、时间点数和每个时间点上题目数量分别固定为 $N = 2 5$ ，$T = 3$ 和 $I { = } 2 5$ ，Q矩阵和题目参数的生成方式与研究1保持一致。另外，参照詹沛达等人(2021)的研究，",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "1 在Long-DINA二阶模型（公式2）中，固定属性难度参数 $\\boldsymbol { \\mathfrak { \\beta } } = ( - 1 , - 0 . 5 , 0 , 0 . 5 , - 1 ) ^ { \\flat }$ ，属性区分度参数 $\\xi _ { k }$   \n2 固定为1.5；在三阶模型（公式3）中，相邻时刻间一般潜在能力 $\\theta _ { n }$ 的均值变化设定为0.5，量尺变化(即  \n3 标准差增加的倍数)设定为 $\\sqrt { 1 . 2 5 }$ 。作答结果数据依据 $y _ { n i t } \\sim$ Bernoulli( $P ( y _ { n i t } = 1 )$ ）生成，其中 $P ( y _ { n i t } = 1 )$ 为  \n4 公式1。分析方法同研究1保持一致。",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "4.3.2 结果",
        "text_level": 1,
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "6 图4呈现了三种方法在不同模拟条件下的PCCR和LPCCR。结果显示三种方法的判准率差异较小；  \n7 这表明即便在相对不公平的对比条件下（使用Long-DINA模型作为数据生成模型），Long-HDD 方法  \n8 也能提供与数据生成模型相当的判准率。另外，三种方法对 50 组数据的平均计算耗时和排序分别为：  \n9 $K = 3$ 时Long-DINA (138.95 秒) $>$ Long-HDD (0.11 秒) $>$ HDD-D (0.07 秒)； $K = 5$ 时Long-DINA（174.78  \n10 秒) $>$ Long-HDD (0.44 秒) $>$ HDD-D(0.29 秒)。显然，属性数量会影响参数估计时间；另外，非参数方  \n11 法的计算耗时要远小于参数化模型的；并且，由于Long-HDD方法针对“一对多”的情况需要额外计  \n12 算汉明距离，所以其计算耗时略多于HDD-D。表1呈现了50 组数据中 HDD-D中出现“一对多”的比  \n13 例。可以看到 $K = 3$ 时各时间点中“一对多”的平均比例约 $5 \\%$ 左右； $K = 5$ 时各时间点中“一对多”的  \n14 平均比例约 $10 \\%$ 左右。即属性数量的增加会导致“一对多”比例的增加。但需要强调的是HDD-D 中出  \n15 现“一对多”的比例受题目参数的影响（罗照盛等,2015），而本研究中题目参数的生成是基于二元正  \n16 态分布随机生成的（即无法固定题目参数的影响），因此该比例结果仅供参考。",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "综上所述，模拟研究结果表明(1)Long-HDD 在纵向诊断数据分析中具有较高的分类准确性;(2)Long-HDD 的表现几乎不受样本量的影响，在小样本情况下表现优于Long-DINA；(3)Long-HDD 的表现几乎不受出现掌握状态变化的学生的比例的影响；(4)小样本条件下，即便以 Long-DINA 作为数据生成模型，Long-HDD 的表现也不输于Long-DINA 的；和(5)Long-HDD 的计算耗时低于Long-DINA的。",
        "page_idx": 7
    },
    {
        "type": "image",
        "img_path": "images/7819d0a4b8256c1227cc29949c8f56fddf4ae4fa701dd4d83f3d3714a85a358d.jpg",
        "img_caption": [
            "图2模拟研究1中 Long-HDD,HDD-D 和 Long-DINA 的分类准确率."
        ],
        "img_footnote": [],
        "page_idx": 8
    },
    {
        "type": "image",
        "img_path": "images/b926a96caaf28cd06c928c78a94a3f7aba8ae421b35901f2d4bb9507f93f0059.jpg",
        "img_caption": [
            "图3模拟研究2 中Long-HDD,HDD-D 和Long-DINA 的分类准确率."
        ],
        "img_footnote": [],
        "page_idx": 9
    },
    {
        "type": "image",
        "img_path": "images/90a49c28491c94a60b0f73908d1282f540b317e28532df5935fc2a267008747f.jpg",
        "img_caption": [
            "图4模拟研究3 中Long-HDD,HDD-D 和Long-DINA 的分类准确率."
        ],
        "img_footnote": [],
        "page_idx": 9
    },
    {
        "type": "table",
        "img_path": "images/9f38828f09ad30fc262e257439f197eafe125d38b785e49360da9a0df05c24e9.jpg",
        "table_caption": [
            "表1模拟研究3中HDD-D方法中不同时刻出现\"一对多\"的比例."
        ],
        "table_footnote": [
            "注：最大值、最小值和平均值分别为50 组数据中的最大、最小和平均的“比例”。"
        ],
        "table_body": "<html><body><table><tr><td>K</td><td>“一对多”比例</td><td>t=1</td><td>t=2</td><td>t=3</td></tr><tr><td rowspan=\"4\">3</td><td>最大值</td><td>0.16</td><td>0.20</td><td>0.12</td></tr><tr><td>最小值</td><td>0.00</td><td>0.00</td><td>0.00</td></tr><tr><td>平均值</td><td>0.05</td><td>0.06</td><td>0.03</td></tr><tr><td>最大值</td><td>0.24</td><td>0.28</td><td>0.20</td></tr><tr><td rowspan=\"2\">5</td><td>最小值</td><td>0.00</td><td>0.00</td><td>0.00</td></tr><tr><td>平均值</td><td>0.13</td><td>0.12</td><td>0.09</td></tr></table></body></html>",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "5实证数据分析 ",
        "text_level": 1,
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "5.1 数据说明",
        "text_level": 1,
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "实证数据来源于某中学七年级90 名学生的数学测验(Tang& Zhan,2021)。为避免记忆/练习效应，该纵向测验包括三套测试题目不同的平行测试；分三次施测，相邻两次施测时间间隔为一周。三套平行测试具有相同的Q矩阵(见图5),每次测试包含18道题目,共测量6个属性。分别使用Long-HDD、",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "HDD-D 和Long-DINA 模型分析该数据，并计算每个施测时间点下，每种方法下学生在不同属性上的掌握占比(即掌握人数占总人数的比例)。",
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "5.2 结果",
        "text_level": 1,
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "图6呈现了三种方法下六个属性的掌握占比随时间发展趋势。首先，整体而言，学生对各属性的掌握占比均有提升，但不同属性有不同的变化趋势。其次，不同方法对属性变化趋势的追踪略有差异。具体而言，对属性1、3和4，三种方法的追踪结果较为一致；而对于属性2、5和6,Long-HDD与 HDD-D 的追踪结果更一致，两者与Long-DINA 模型的追踪结果存在一定差异。另外，在分析该实证数据时，HDD-D 方法中出现“一对多”的比例在三个时间点上分别为0.88，0.72和0.48；而Long-HDD方法中第二次计算最小汉明距离时出现“一对多”的比例为0和0.11(第二次计算最小汉明距离对应图1中比较 $\\mathbf { A M P } n _ { 1 }$ 和“对应的属性掌握模式2”的汉明距离)。这不仅表明了Long-HDD在实际的数据分析中存在很大的应用空间，而且也说明再次使用最小汉明距离可以有效缩小 $t$ （ $( t > 1 )$ （20时刻学生可能的AMP 范围，获得较为稳定的判准结果。但遗憾的是，由于非参数法无法像参数化模型一样提供模型-数据拟合指标值，因此，我们并无法对比三种方法对该数据的拟合或匹配程度。总之，实证研究表明 Long-HDD 可用于分析实践测评数据且Long-HDD 的追踪诊断结果与Long-DINA模型的存在一定的一致性。",
        "page_idx": 10
    },
    {
        "type": "image",
        "img_path": "images/055ac6526c7a1ad18cac5b51ea1efe0d0d13e29ce19dd58708984d7e7e0e784b.jpg",
        "img_caption": [
            "图5有理数测验的Q矩阵"
        ],
        "img_footnote": [],
        "page_idx": 10
    },
    {
        "type": "image",
        "img_path": "images/81b9025b45f40a9b53016b125ea990a0b0e00092049f3f83d235ad2d22c53e6c.jpg",
        "img_caption": [
            "注：空白部分表示0，灰色部分表示1."
        ],
        "img_footnote": [],
        "page_idx": 10
    },
    {
        "type": "image",
        "img_path": "images/75f662dad50ea2a6202340a90b74ff8b4050290af55b531069aea7de174f46c5.jpg",
        "img_caption": [
            "图6六个属性的掌握占比随时间发展趋势，"
        ],
        "img_footnote": [],
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "6讨论、展望与研究结论",
        "text_level": 1,
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "6.1 讨论与展望 ",
        "text_level": 1,
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "本研究通过在纵向诊断数据分析中引入计算简单、耗时少的HDD，提出了Long-HDD，以期促进纵向认知诊断在实践教学中的应用。与HDD 相比，Long-HDD 使用汉明距离刻画个体在相邻时间点上对属性掌握情况的相关性或相依性，以利用前一个时间点的信息来提高当前时间点的分类准确性。该方法不仅降低了纵向诊断数据分析的难度，还拓宽了NPC 法的应用范围。模拟研究结果主要表明 Long-HDD 可用于分析纵向诊断数据，也能刻画学生的潜在属性变化；且由于其计算简单耗时少，更有利于实现即时性诊断反馈，这在班级和学校层面的小规模测评中尤为重要。实证研究表明Long-HDD 可用于分析实践测评数据且其追踪诊断结果与Long-DINA模型的存在一定的一致性。另外，在纵向数据的分析中，Long-HDD 通过多次汉明距离的比较，可获得较为稳定的判准结果，相对于采用随机化方法的HDD来说，有更高的诊断分类一致性。",
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "作为一种非参数方法，Long-HDD 缺少相关的数据拟合指标，即无法评估其对数据的拟合程度。实际上，在班级水平小规模测评中，诊断结果的准确性并不是实践者关注的首要问题。即便不进行诊断性测评，任课教师也可以根据学生的原始作答来推断每一个学生对知识点的掌握情况。从该角度看，基于方法的诊断结果更多地是为了降低老师工作量，为一对一有针对性干预提供参考性建议；而至于老师是否要依据诊断结果为学生提供干预，最终仍由老师决定。反之，在实践应用中如果样本量足够(如，大于300人)且无计算耗时压力，仍推荐使用可提供模型-数据拟合程度的参数化模型。",
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "由于能力和精力有限，本文仍有一些局限性值得后续做进一步探究。首先，Long-HDD 是HDD的拓展，因此，HDD 的理论局限性也存在于Long-HDD 中。例如，本文中 HDD 只考虑了最简单的汉明距离。在实践中，不同的属性可能有不同的权重，后续研究中可以考虑将加权HDD(Chiu&Douglas,2013)纳入Long-HDD中。其次，本研究假设属性遵循连接缩合规则，即学生只有在掌握题目所考察的所有属性时，才会有较高的正确作答概率。而这一假设可能在一定程度上制约了Long-HDD 的实践应用。未来，可尝试将广义NPC 法（Chiu et al.,2018)纳入Long-HDD中，以提高新方法在不同认知假设下的适用性。然后，本研究中每个属性在相邻时间点之间的转移概率被设定为相等。尽管作者认为该设置对本研究的结论没有影响，但Long-HDD 在可变的转移概率下的具体表现仍值得进一步探索。然后，理论上Long-HDD仅在时间点 $t \\left( t > 1 \\right)$ 的 IRP 集合中包含多个IRP时(即存在“一对多”)才起作用。而当IRP集合中只有一个IRP时，Long-HDD的分类结果等同于HDD 的。Wang 和Douglas (2015)认为增加题目数量会减少“一对多”情况的发生，然而，本研究结果发现，即便题目数量从25增加到50，似乎并没有减少Long-HDD 相对于HDD 的优势。罗照盛等人(2015)探究了在不同属性层级结构和作答失误概率对出现“一对多”的影响；其研究发现随着作答失误概率的增加，在任一属性层级结构中会出现更多的“一对多”。此外，康春花等人(2017)研究表明Q矩阵中所含可达矩阵的数量也会影响 HDD的分类准确性。因此，作者认为除题目数量外，“一对多”情况的发生还受到Q矩阵的复杂性、题目质量及属性层级等因素的影响，而具体的影响程度也值得后续做进一步探究。",
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "6.2 研究结论",
        "text_level": 1,
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "Long-HDD 在纵向诊断数据分析中可以提供较高的分类精度，且由于不受样本量的影响、计算简单、耗时少，其相对于参数化纵向DCM（如,Long-DINA)，更有利于提供即时性诊断反馈，更适用于如班级和学校层面的小规模纵向测评。",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "参考文献",
        "text_level": 1,
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "康春花，杨亚坤，曾平飞.(2017).海明距离判别法分类准确率的影响因素.江西师范大学学报(自 科学版).41(04),394-400.   \n康春花，杨亚坤，曾平飞.(2019).一种混合计分的非参数认知诊断方法：曼哈顿距离判别法.心理禾 学,42(2), 455-462.   \n刘耀辉，徐慧颖，陈琦鹏，詹沛达.(2022).基于过程数据的问题解决能力测量及数据分析方法．心 科学进展,30(3),522-535.   \n罗照盛，李喻骏，喻晓锋，高椿雷，彭亚风.(2015).一种基于Q矩阵理论朴素的认知诊断方法.心 理学报(02),264-272.   \n王立君，唐芳，詹沛达.(2020).基于认知诊断测评的个性化补救教学效果分析：以\"一元一次方程” 为例.心理科学,43(06),1490-1497.   \n詹沛达，潘艳方，李菲茗.(2021).面向“为学习而测评”的纵向认知诊断模型．心理科学,44(1), 214-222.   \nAkbay,L. (2016). Relative eficiency of the nonparametric approach on atribute classification for small sample cases. Journal Of European Education,6(1).   \nBergner, Y., Shu, Z.,& von Davier, A.A. (2014). Visualization and confirmatory clustering of sequence data from a simulation-based assessment task. Proceedings of the 7th International Conference on Educational Data Mining (pp. 177-184).   \nChiu, C. Y.,& Douglas, J. (2013). A nonparametric approach to cognitive diagnosis by proximity to ideal response patterns.Journal of Classification, 30(2), 225-250.   \nChiu, C. Y., Douglas, J. A.,& Li, X.D. (2009). Cluster analysis for cognitive diagnosis: Theory and applications.Psychometrika, 74(4), 633-665.   \nChiu, C.Y.& Kohn, H.F. (2015). A general proof of consistency of heuristic classification for cognitive diagnosis models. British Journal of Mathematical and Statistical Psychology, 68(3),387-409.   \nChiu, C.Y., Sun, Y.& Bian, Y. (2018). Cognitive diagnosis for small educational programs: The general nonparametric classification method. Psychometrika 83,355-375.   \nHao, J., Shu, Z., & von Davier, A. (2015). Analyzing process data from game/scenario-based tasks: An edit distance approach. Journal of Educational Data Mining, 7(1), 33-50.   \nTang,F.,& Zhan,P.(2O21). Does diagnostic feedback promote learning? Evidence from a longitudinal cognitive diagnostic assessment. AERA Open,7.   \nWang, S.Y.,& Douglas, J. (2015). Consistency of nonparametric classfication in cognitive diagnosis. Psychometrika, 80(1), 85-100.   \nZhan, P. (202Oa). A Markov estimation strategy for longitudinal learning diagnosis: providing timely diagnostic feedback. Educational and Psychological Measurement, 80(6),1145-1167.   \nZhan, P. (2O2Ob).Longitudinal learning diagnosis: minireview and future research directions. Frontiers in Psychology,11,1185.   \nZhan,P., Jiao,H.,Liao,D.,&Li,F. (2019). A longitudinal higher-order diagnostic classification model.Journal of Educational and Behavioral Statistics, 44(3),251-281.   \nZhan,P., Jiao, H.,Liao, M.,& Bian, Y. (2019). Bayesian DINA modeling incorporating within-item characteristic dependency. Applied Psychological Measurement, 43(2), 143-158. ",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "Longitudinal Hamming Distance Discrimination: Developmental Tracking of Latent Attributes ",
        "text_level": 1,
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "Liu Yaohui1, Chen Qipeng1,Xu Huiying1, Zhan Peida1,2 (lDepartment of Psychology, College of Teacher Education, Zhejiang Normal University; 2Key Laboratory of Intelligent Education Technology and Application of Zhejiang Province, Zhejiang Normal University, Jinhua 321004, China) ",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "Abstract ",
        "text_level": 1,
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "Longitudinal cognitive diagnostics can assess students’ strengths and weaknesses over time, profile students’ developmental trajectories,and can be used to evaluate the effectiveness of teaching methods and optimize the teaching process. Researchers have proposed diferent longitudinal diagnostic classification models,which provide methodological support for the analysis of longitudinal cognitive diagnostic data. Although these parametric longitudinal cognitive diagnostic models can effectively assess students’ growth trajectories,their requirements for coding ability and sample size hinder their application among frontline educators,and they are time-consuming and notconducive to providing timely feedback. On the one hand, the nonparametric approach is easy to calculate, efcient to apply,and provides timely feedback; on the other hand,it is free from the dependence on sample size and is particularly suitable for analyzing assessment data at the classroom or school level. Therefore,this study attempts to apply nonparametric method to longitudinal cognitive diagnostic assessments for tracking student's learning trajectories. ",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "This study extended the longitudinal Hamming distance discriminant (Long-HDD) based on the Hamming distance discriminant (HDD),which uses the Hamming distance to represent the dependence between attribute mastery patterns of the same student at adjacent time points.To explore the performance of Long-HDD in longitudinal cognitive diagnostic data, we conducted three simulation studies and an empirical study and compared the clasification accuracy of the HDD,Long-HDD,and Long-DINA models. The purpose of simulation study 1 was to compare the performance of performance of three methods under different simulation conditions. Simulation study 2 focused on the classification accuracy of the three methods at moderate attributes transfer probability level $( \\mathrm { p } ( 0 \\to 1 ) { = } 0 . 5$ $\\mathtt { p } ( 1 \\to 0 ) { = } 0 . 0 5 )$ and high attributes transfer probability level $( \\mathsf { p } ( 0 \\to 1 ) { = } 0 . 8$ 0 $\\mathsf { p } ( 1 \\to 0 ) { = } 0 . 0 5$ ). To further highlight the advantages of the Long-HDD in smal-scale assessments,the Long-DINA model was used as the data generation model in Study 3.At this point, if Long-HDD still outperforms or does not lose out to Long-DINA model's, the relative advantage of using Long-HDD in a smal-scale assessments can be further highlighted. Furthermore,an empirical study was conducted to illustrate the application of the Long-HDD. ",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "Under the comparison of the three methods,the results of the simulation studies showed that (1) Long-HDD had higher classification accuracy in longitudinal diagnostic data analysis; (2) Long-HDD performed almost independently of sample size and performed better with a smaller sample size compared to Long-DINA; and (3) Long-HDD consumed much less computational time than Long-DINA. In addition, the results of the empirical study showed that there was good consistency between the results of the ",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "Long-HDD and the Long-DINA model in tracking changes in attribute development. The percentage of mastery of each attribute increased with the increase of time points. ",
        "page_idx": 15
    },
    {
        "type": "text",
        "text": "In summary, the long-HDD proposed in this study extends the application of nonparametric methods to longitudinal cognitive diagnostic data and can provide high classification accuracy. Compared with parameterized longitudinal DCM, it can provide timely diagnostic feedback due to the fact that it is not affected by sample size, simple calculation,and less time-consuming. It is more suitable for small-scale longitudinal assessments such as class and school level. ",
        "page_idx": 15
    },
    {
        "type": "text",
        "text": "Keywords: cognitive diagnosis； nonparametric classification; longitudinal data analysis； Hammingdistance",
        "page_idx": 15
    },
    {
        "type": "text",
        "text": "附录",
        "text_level": 1,
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "S1两种计算策略HDD结果的一致性",
        "text_level": 1,
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "假设有两个时间点，每个时间点用 $I$ 个题目测量 $K$ 个属性。首先，解释一些下文会用到的缩写： $\\mathrm { O R P } _ { 1 }$ 、 $\\mathrm { O R P } _ { 2 }$ 、 $\\mathbf { A M P } _ { 1 }$ 、 $\\mathbf { A M P } _ { 2 }$ 、IRP集、IRP集合1、IRP集合2分别代表学生在时间点1的观察作答向量、时间点2的观察作答向量、时间点1的属性掌握向量、时间点2下的属性掌握向量、筛选出的与ORP 距离最短的IRP的集合、在时间点1与 $\\mathrm { O R P } _ { 1 }$ 距离最短的IRP集合和在时间点2与 $\\mathrm { O R P } _ { 2 }$ 距离最短的IRP集合。",
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "S1.1采用独立计算策略的HDD-D",
        "text_level": 1,
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "这种情况下，在每个时间点可得到 $2 ^ { K }$ 个IRP，每个IRP 的长度等于 $I _ { \\circ }$ 通过比较每个时间点的ORP 和IRP的汉明距离。可以得到IRP集合1和IRP集合2。假设从IRP集合1中随机选择的 $\\mathrm { I R P r } _ { 1 }$ 和 $\\mathrm { O R P _ { 1 } }$ 之间的汉明距离为 $\\mathbf { s } _ { 1 }$ ，从IRP集合2中随机选择的 $\\mathrm { I R P r } _ { 2 }$ 和 $\\mathrm { O R P } _ { 2 }$ 之间的汉明距离为 $\\mathbf { s } _ { 2 }$ ，那么 $( \\mathrm { O R P _ { 1 } }$ ， $\\mathrm { O R P } _ { 2 } \\mathrm { . }$ 和 $( \\mathrm { I R P } _ { 1 } , \\mathrm { I R P } _ { 2 } )$ 之间的总汉明距离为 $\\mathbf { s } _ { 1 } \\mathbf { + } \\mathbf { s } _ { 2 }$ 。例如， $\\mathrm { O R P } _ { 1 }$ 为(0,1,1), $\\mathrm { O R P } _ { 2 }$ 为(0,1,0),$\\mathbf { I R P } _ { 1 }$ 是(1,1,1)， $\\mathbf { I R P } _ { 2 }$ 是(1,1,1)，那么(ORP1,ORP2) (即(0,1,1,0,1,0))和(IRP1,IRP2) (即(1,1,1,1,1))的汉明距离为3，且等于 $\\mathrm { O R P _ { 1 } }$ 和 $\\mathbf { I R P } _ { 1 }$ 之间的距离 $\\mathbf { s } _ { 1 }$ 加上 $\\mathrm { O R P } _ { 2 }$ 和 $\\mathbf { I R P } _ { 2 }$ 之间的距离 $\\mathbf { s } _ { 2 }$ 。如图 S1所示，如果IRP集1有 $x$ 个元素，IRP集2有 $\\mathbf { \\nabla } _ { m }$ 个元素，那么最后判准的结果为某个 $( { \\mathrm { A M P } } _ { 1 } , { \\mathrm { A M P } } _ { 2 } $ 的概率是 $1 / x m$ 。",
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "S1.2 采用同时性计算策略的HDD-T",
        "text_level": 1,
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "在这种情况下，纵向数据被作为一个整体数据进行分析，Q矩阵的表示就略有不同。假设每个时间点的测试中有5个题目，3个属性，两个时间点，其Q矩阵可表示为图S $\\begin{array} { r l } { \\backslash 2 \\ \\circ } & { { } I _ { I } , I _ { 2 } , \\dotsc I _ { 5 } } \\end{array}$ 是在第一个时间点测量的题目， $I _ { 6 } , I _ { 7 } , \\dots I _ { I 0 }$ 是在第二个时间点测量的题目。 $K _ { I I }$ 、 $K _ { 2 I } , K _ { 3 I }$ 代表在第一时间点测量的三个属性， $K _ { I 2 }$ ， $K _ { 2 2 }$ ， $K _ { 3 2 }$ 代表在第二时间点测量的同样三个属性。",
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "图 S3 显示了在纵向数据中使用HDD与同时性计算策略的流程。通过两个时间点，可以得到$2 ^ { 2 K }$ 个属性向量，从而再得到 $2 ^ { 2 K }$ 个 IRP。同样，可得到一个IRP集合，其中的 IRP 与 $( \\mathrm { O R P } _ { 1 } , \\mathrm { O P R } _ { 2 } ,$ 保持最小的汉明距离。因为汉明距离计算的是两个等长的字符串之间对应位上不同元素的数量。ORP 和 IRP在不同时间下的汉明距离是相互独立的。不难得到 IRPr和(ORP1，ORP2)之间的距离是 $\\mathbf { s } _ { 1 } \\mathbf { + } \\mathbf { s } _ { 2 }$ ，等于 $( \\boldsymbol { y } ^ { * } \\boldsymbol { \\imath } , \\boldsymbol { y } ^ { * } \\boldsymbol { \\imath } , . . . \\boldsymbol { y } ^ { * } \\boldsymbol { \\imath } )$ 和 $( \\mathrm { O R P _ { 1 } } )$ 之间的距离加上 $( y ^ { \\ast } _ { I ^ { + 1 } } , . . . y ^ { \\ast } _ { 2 I } )$ 和 $( \\mathrm { O R P } _ { 2 } )$ 的距离。IRPr是从IRP集合中随机选择的，该集合等于IRP集合1和 IRP集合2 的所有组合(在图 S1中)(即 ${ \\boldsymbol { w } } = x { \\boldsymbol { m } } $ 。最后，判准结果为某个（ $\\mathbf { \\mathrm { \\cdot } } \\mathbf { \\mathrm { A M P } } _ { 1 }$ ， $\\mathbf { A M P } _ { 2 } \\mathrm { . }$ )的概率也是 $1 / x m$ 。",
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "S1.3小规模模拟研究",
        "text_level": 1,
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "为进一步研究HDD-D 和HDD-T 在数据分析中是否也存在一致性，我们基于模拟研究3中的条件,对比了HDD-D和HDD-T的属性判准率和计算耗时。表 S1呈现了HDD-D 和HDD-T的 PCCR和LPCCR，发现两者之间的差异很小(约 $0 . 5 \\%$ )。但两者的计算耗时具有较大差异，当 $K = 3$ 时，HDD-D 和HDD-T的平均计算耗时分别为0.07秒和4.25秒；当 $K = 5$ 时，HDD-D 和 HDD-T 的平均计算耗时分别为0.29秒和 232.37秒（超过了Long-DINA模型的174.78秒）。表明两者的计算时间都受到属性数量的影响，但HDD-T所受的影响更大。其主要原因在于 $T = 3$ 和 $K = 5$ 条件下HDD-T中有 $2 ^ { 1 5 } \\mathrm { = } 3 2 7 6 8$ 种属性模式需要进行距离计算。总之，数据分析结果表明 HDD-D与HDD-T的属性判准率几乎一样，且前者计算耗时更少。",
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 17
    },
    {
        "type": "image",
        "img_path": "images/4b35ac3955294f45075f75501fe47a7d0dc01eb84925909f67955f337c4a5686.jpg",
        "img_caption": [
            "图S1 独立计算策略HDD-D示意图"
        ],
        "img_footnote": [],
        "page_idx": 17
    },
    {
        "type": "table",
        "img_path": "images/c41eb4b3da6d3575f10676f2824aee81eaa59d80d34f4b6c3dbdaebefc585552.jpg",
        "table_caption": [],
        "table_footnote": [],
        "table_body": "<html><body><table><tr><td></td><td></td><td></td><td>13</td><td>I4</td><td>I5</td><td>16</td><td>1</td><td>Is</td><td></td><td>10</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>α21</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>α31</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>α12</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>a22</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>α32</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table></body></html>",
        "page_idx": 18
    },
    {
        "type": "image",
        "img_path": "images/e2d671f0941b5723b5d2c3717c28bb52673f834e767d8705d55f16fa4a233af9.jpg",
        "img_caption": [
            "图S2 同时性计算策略HDD 的纵向Q矩阵",
            "图S3 同时性计算策略HDD示意图"
        ],
        "img_footnote": [],
        "page_idx": 18
    },
    {
        "type": "table",
        "img_path": "images/537e9a28316322957ca027a32391ec11be4b4b60f049bffcfb4a078b2783b259.jpg",
        "table_caption": [
            "表S1模拟研究3条件下HDD-D与HDD-T的属性判准率."
        ],
        "table_footnote": [],
        "table_body": "<html><body><table><tr><td rowspan=\"2\">K</td><td rowspan=\"2\">HDD 计算策略</td><td colspan=\"3\">PCCR</td><td rowspan=\"2\">LPCCR</td></tr><tr><td>t=1</td><td>t=2</td><td>t=3</td></tr><tr><td>3</td><td>HDD-D</td><td>0.867</td><td>0.900</td><td>0.937</td><td>0.737</td></tr><tr><td rowspan=\"3\">5</td><td>HDD-T</td><td>0.870</td><td>0.893</td><td>0.936</td><td>0.731</td></tr><tr><td>HDD-D</td><td>0.779</td><td>0.834</td><td>0.876</td><td>0.615</td></tr><tr><td>HDD-T</td><td>0.784</td><td>0.838</td><td>0.879</td><td>0.619</td></tr></table></body></html>",
        "page_idx": 18
    }
]