# 科学基金同行评议中随机机制的应用研究1

刘亚辉1,2 杨立英」沈哲思1（1．中国科学院文献情报中心北京100190;

2.中国科学院大学经济与管理学院图书情报与档案管理系北京100190)

摘要：当前科学基金项目评审主要采用同行评议，而评议过程的公正性和评议结果的可靠性决定着真正有价值的研究能否得到资助。但在整个评议流程中常出现的专家利益冲突、非共识、评审偏见等情况使得评审结果具有一定的不可靠性和随机性，而科学领域中的马太效应在未来资源分配时进一步放大这种隐性的随机。学术界正通过多种举措来提高评审的质量，其中具有变革性的一项措施就是在评议过程中引入随机机制，即在资源有限的情况下，随机筛选那些经专家预选后学术价值相近、专家非共识、非常规但具有开创性的项目申请进行资助。本文系统梳理了采用随机机制的科学基金资助计划，分析其使用范围和接受情况。随机机制在科学基金同行评议中的应用处于萌芽阶段，其适用范围、使用成效和对评价制度的影响尚不明确，未来需要加强对随机机制本身的研究以及实施后的潜在影响和成效研究，探讨其作为实现更公正、更高效的评审手段的可能性。

关键词：基金资助；同行评议；随机机制；预选 分类号：G31

# 1引言

科学基金设立的目的是借助一定的评价机制筛选出具有发展前景和潜在学术价值的项目进行资助，从而推动科学均衡、协调发展，促进学科建设，发现和培养多样化优秀科技人才[I。基金项目的评审资助机制在很大程度上决定了真正有价值的研究能否获得强有力的资金支持，使有限资源得以有效配置。同行评议制度源于15世纪欧洲对专利申请的审查，17世纪英国皇家协会编纂首本期刊《哲学汇刊》，借助同行专家进行论文评审[2]。20 世纪40 年代以后，美国陆续成立国立卫生研究院和国家科学基金会，同行评议开始成为评估项目申请的主要手段[3]。同行评议制度从确立以来得到了科学界的普遍支持，被认为是各类评价工作的“金标准”，贯穿于科技活动中的政策制定、资源分配和人才遴选等各个环节。科学基金评审是同行评议制度的一个重要应用场景，即同行专家依据专业知识和过往经验，按照既定标准对项目申请的学术价值进行评估。但在整个评议流程中常出现的专家利益冲突、非共识、评审偏见等情况使得评审结果具有一定的不可靠性和随机性，加剧了科学领域中的马太效应。美国、英国曾多次掀起反对使用同行评议的浪潮，质疑评议的公正性，美国参议院及英国议会分别委托相关机构展开调查，调研报告中肯定了基金评审中同行评议的不可替代性和改善的必要性[4-5]。因此如何改善现有的同行评议制度，在保障评审效率的前提下促进科学基金的公平合理分配成为亟待解决的问题。

研究人员不断寻求科学基金同行评议制度的改善措施，如通过构建丰富的专家库、回避利益冲突、定期培训专家等措施促进专家的精准匹配，同时探索双盲评审、申请人间自组织分配等多种评议方式增强评议过程的公正性。但仍旧存在评审偏见、开创性研究被拒、评审结果具有随机性等问题。鉴于此，本文首先对随机机制进行了介绍，即添加更正式、更显性的随机性平衡现有制度决策结果的潜在随机性，帮助筛选学术价值接近、专家非共识、非常规但具有开创性想法的项目申请，提高评审效率，增强结果的公平性。然后调研了随机机制应用于科学基金同行评议的相关案例，总结了随机机制的适用范围，并对随机机制用于基金评审的反馈情况进行了梳理。最后提出未来可以进一步研究和探讨的方向。

# 2科学基金同行评议存在的问题及改进措施

# 2.1科学基金同行评议制度存在的问题

科学基金同行评议活动是科学共同体中“精英科学家”群体的民主化决策过程，主要包括评议专家、审查标准和提交的项目申请这三个要素，具体过程为某领域专家依据各自的专业知识及过往经验，按照同一既定标准，对项目申请的学术价值、可行性和潜在影响进行评估[-10]。理想中的科学基金同行评议制度希望可以高效、准确地筛选出值得资助的项目。但是在具体评议过程中，由于不同专家对评判标准的理解及对项目申请的价值判断存在差异，往往无法获取正确的群体决策结果。因此，科学基金同行评议的问题存在于同行评议的全流程，包括评议专家的遴选、具体评议过程及评议效果的评估等。

# 2.1.1评议专家的遴选

同行评议活动的评价主体是同行专家，同行评议赋予了科学共同体中少数学者充当价值评判“仲裁人”的权威地位，因此评议专家的精准遴选尤为重要。但在实际选择评议专家时常出现领域、方向不匹配，利益冲突等情况，具体如下：

（1）专家遴选。同行评议制度的科学性源于评议专家特有的学术鉴别能力，为了提高评审质量，在遴选专家时尽可能保证专家的研究方向与评审项目的主题相匹配。但是Abramo 等通过调研意大利教育、大学和研究部（MIUR）遴选的专家对基金项目主题了解的充分性，发现 $40 \%$ 的专家专业能力低于全国中位数，$1 5 \%$ 的专家5年没有活跃在生产一线。同时各个细分学科专家的覆盖程度不够，$8 \%$ 的细分学科完全没有相应的专家， $12 \%$ 的细分学科只有一位专家，无法做到“小同行”评议[I]。此外，随着现代科学技术朝向纵深发展，学科领域既细分又交叉，交叉科学研究也面临难以遴选合适的专家的困境：长期以来的学科分化造成的学术壁垒，找到契合跨学科研究知识背景的专家很困难[12]；许多新兴交叉科学研究处于发展阶段，还未聚集足够体量的“同行”[13]。Lyall和King总结交叉学科评议存在的问题：遴选的专家通常不具备判断交叉研究价值的专业知识，在评估不熟悉的领域或学科方向时，专家可能过于苛刻，呼吁融合“大同行”和“小同行”以增强评价的科学性[14]。Bammer强调跨学科研究项目的评价可以借助学术社区，使跨学科研究人员和同行专家充分交流，帮助专家实现更客观更有效的审查[15]。

（2）利益冲突。在遴选评议专家时，除了考量过硬的专业知识，还需要其具备良好的个人品德和职业道德，以便公正地完成评审工作。利益冲突是指专家和专家、专家和提交申请的研究人员之间存在利益关联或不良竞争情况，多数源于学者扮演的多重角色[16]。Sandstrom和Hallsten 调研了同行专家对瑞典医学研究委员会相关基金项目申请的评分情况，发现与评议专家有利益关联的申请人提交项目的评分要高出 $1 5 \% ^ { [ 1 7 ] }$ 。Juznic等对斯洛文尼亚2003年、2005年、2008 年的同一类型项目申请，将同行评议和定量指标的评分对比进行事后评估，发现提升评议专家的国际程度有助于避免利益冲突[18]。Li结合美国国立卫生研究院R01的项目申请、参与评审的同行专家及生命科学研究的论文产出数据，分析可知专业领域相近的评议专家评估使得申请人获得资助的机会增加 $2 . 2 \%$ ，即专家习惯为自己领域争夺资金和科学优先权等稀缺资源，产生不良竞争[19]。

# 2.1.2具体评议过程

理想中的同行评议过程应该是在对项目申请进行评议时避免不一致性、避免偏见保持公正，同时控制经济投入。但在具体实施时，评议机制的一致性、公正性、经济性常常无法得到保障，具体如下：

（1）一致性。一致性是指： $\textcircled{1}$ 不同专家运用同样的评审标准对同一项目申请的科学价值、创新性等方面有共识性的看法； $\textcircled{2}$ 同一专家对同一项目申请在不同轮次的评价中评审意见也是一致的。在具体评议过程中，同行专家往往产生非一致性的判断，无法达成共识，使得评议结果具有随机可变性。很多研究运用二次评议或者对比不同的专家小组对同一项目申请的评审结果，得出同行专家的打分情况存在明显差异，资助决策更多地取决于参与评审的同行专家，而不是提交的项目申请本身的学术价值[20-23]。当评审意见有分歧时，通常会采用少数服从多数的原则，这虽然体现了决策的民主性，但无法保证结果的正确性[24]。

（2）公正性。公正性是指待评估的项目申请得到客观、无偏见的评审，即只考虑项目本身的学术价值，与申请人自身年龄、性别、种族、机构和学术地位等因素无关。但在具体评议过程中常常存在评审偏见：

$\textcircled{1}$ 对申请人自身的偏见。此类偏见首先是源于专家所在的学术关系网和利益冲突情况，专家在评审时遵守潜在的“任人唯亲”原则[25]，同行评议制度成为互惠互利的交易手段。此外偏见还源于专家对特定研究领域、机构、种族、性别的偏爱或不喜欢：多项研究发现男性申请人项目申请成功率高于女性[26-28]，黑人和少数族裔获得美国国立卫生研究院资助的可能性显著较低[29-30]，同等质量情况下专家倾向于选择知名、成熟科学家的研究[31-32]。

$\textcircled{2}$ 对研究本身的偏见。同行评议制度常常扼杀新思想和科学突破，即对变革性和交叉型等非常规研究本能地进行排斥，科学常困于同行专家判断意见的“庭院”内部进行发展，形成封闭的系统自组织认知结构[33]。因此他们有强烈的“领土意识”，习惯给更接近自己专业领域及高度新颖的项目申请打低分[34-35]。此外，专家在评审非常规的项目申请时容易产生分歧，为了规避风险，基金资助机构往往选择所有专家一致赞同的，拒绝那些意见分歧较大的项目申请[36-37]。

（3）经济性。经济性是指在评议过程中投入较少的时间、精力、财力筛选出值得资助的项目申请。但是目前的评审机制不够高效，专家在评议过程中需要花费很多时间和精力。2015年美国国家科学基金会邀请16255名科学家对51588份项目申请进行评估，完成一份评审意见平均花费专家3.9个小时，每个评审员平均每年需花费 360 个小时（不包括小组讨论时间）[38]。研究者的努力也逐渐偏离科学研究本身，大量的时间和精力放在写项目申请书上。Herbert等学者调查了澳大利亚国家健康和医学研究委员会的项目申请情况，发现准备一份项目申请平均花费32天，3727份将花费所有研究人员550年的工作时间，货币价值约为6600 万澳元[39]。

# 2.1.3评议效果的评估

评议效果的评估是验证资助决策的可靠性，可靠性是指同行评议专家能够准确评估项目申请的学术价值，有效识别筛选出高质量的研究，保证评议结果是准确、可信赖的。但是通过调研资助项目的后续表现，同行评议的可靠性遭受质疑。Roumbanis指出同行专家是依靠旧知识评价新知识，对科学研究创新性的事前评价从根本上来讲是不确定的[40]。Tetlock对比了同行专家、消息灵通的非专家及普通人在政治经济学领域的预测结果，发现专家在预测研究的潜在价值时的表现并没有优于另外两个群体[41]。Nicholson 和Ioannidis调研了美国国立卫生研究院（NIH）2001-2012年资助的项目，结果表明高被引论文的作者中得到NIH资助的仅占 $3 9 . 7 \% ^ { [ 4 2 ] }$ 。同样地，Stavropoulou 等人发现 2006-2018 年间被高度引用的作者中仅有 $3 6 . 2 \%$ 获得过英国公共和慈善健康基金（MRC、WellcomeTrust和NIHR）的资助，而获得资助的665位研究人员中仅有7人（ $1 . 1 \%$ ）发表了高被引论文[43]，同行评议的可靠性有待提升。

# 2.2科学基金同行评议制度的改善措施

为了获取更为公正客观的资助结果，科学共同体及科研管理机构从精准遴选评议专家、增强评议过程的公正性出发，采取了一系列举措尝试以提升评议结果的可靠性。具体措施如下：

# 2.2.1促进评议专家的精准匹配

（1）获取专家学术关系网，构建丰富的专家库。要实现评议专家的精准匹配，建立数量充足、更新及时、结构合理的专家库成为首要需求。美国国家科学基金会选择评审专家的要求：尽量在地区、研究机构类型及其代表性等方面进行权衡；避免过多地聘任同一人和在同一机构内选择评审专家[44]。评议专家的跨地域性、跨民族性在一定程度上也可以避开熟人关系网。因此在征集专家时除了细化专家领域和研究方向，获取基础信息，研究人员还运用合作网络分析和超文本挖掘技术从数据库的学者库、机构自建知识库、机构的学者个人主页和公共社交媒体中抽取专家学术关系网[45-46]，以此为基础发现潜在的利益冲突关系。

（2）回避利益冲突，精准遴选、匹配评议专家。在遴选匹配评议专家时，研究人员尝试基于社会网络分析筛选[47]、参考专家概念知识网[48]、构建关系量化模型[49]等方法模型有针对性地回避利益相关的专家。在专家充足的前提下，有研究证明实行专家轮换制，定期更换评议专家能够减少项目申请人与专家之间提前“打招呼”及评审专家之间相互关照的机会[50-51]。随着基金项目申请数量激增、学科交叉程度增强，专家的遴选指派工作愈加困难。中国国家自然科学基金运用人工智能技术比较申请书和专家库中潜在评议人的研究方向，提升匹配的精准度，排除人为遴选时主观因素的干扰[52-53]。

（3）定期培训评议专家，对专家进行反评估资质审核。Sattler等人对比75位公共卫生领域专家在培训前后对美国国立卫生研究院项目申请的评审情况，发现培训提高了专家对评审标准理解的准确性和评议结果的可靠性，凸显了定期培训专家的必要性[54]。后续研究进一步证实对专家进行评审前培训能够帮助建立组内共识，提高评议结果的可靠性[5]。此外，对专家评审质量的监督和评价同等重要。研究人员从离散率、命中率、评分可信度等方面对专家的评审行为进行定量分析[56-58]，准确反映专家行为特征，评估专家的评审质量。国家自然科学基金委2021年开始选取 $3 5 \%$ 的学科在通讯评审环节开展“负责任、讲信誉、计贡献”（RCC）评审机制试点，坚持“价值”导向，减少专家不负责任、不讲信誉的行为，充分发挥专家的质量控制作用[59]。还有学者通过构建多级评价指标体系对专家评审行为进行综合评估[60-61]，监督专家评议结果的准确性，并以此作为后续遴选专家考量的因素。

# 2.2.2增强评议过程的公正性

除了促进专家的精准匹配，研究人员和资助机构还积极探索双盲评审和自组织分配等多种同行评议方式，增强评议过程的公正性。目前多数基金资助采用单盲评审，但是单盲评议方式常常导致评审偏见，尤其是对年轻学者[62]。Lee 等对韩国科学与工程基金会(KOSEF)的提案进行回顾性比较试验，5名专家3人单盲，

2人双盲运用同样的标准进行评估，结果表明申请人学校排名、职业年龄和学术地位等是导致评分显著不同的主要因素，建议KOSEF和其他资助组织尽扩大双盲评审的使用范围[63]。Solans-Domenech 等对比分析加泰罗尼亚卫生质量和评估局运用双盲和单盲评审生物医学领域项目申请的专家意见，结果显示双盲转为单盲评审后有 $1 8 . 5 \%$ 的评审意见发生了变化，更改依据主要是申请人身份及过往的成就，研究建议运用双盲评议方式，改善专家有意识或无意识的评审偏见[64]。美国国家科学基金会试行了名为“TheBigPitch”的双盲评审资助计划，要求申请人在提交完整申请的同时，提交一份两页的匿名申请书，两类申请的最终筛选结果重合度较低（55项中仅有3项被共同选中），试验结果显示双盲评审时专家更能专注于研究本身的新颖性[65]。丹麦Villum和Velux基金会在2018年发起 TheVillumExperiment资助计划中采用双盲评审，突出对研究理念而不是申请人本身的关注[6]。此外，Bollen 提出了自组织资金分配，在平均分配的基础上基于“科学家更了解谁做的研究好”这一假设，对彼此的研究作出评判，将现有经费按一定比例给值得研究的项目[67]。该方式中平均分配的前提为早期职业研究人员提供稳定资金来源，而公认更值得做的研究获得更多的资助可以鼓励开展开创性、风险较大的研究。

但是上述改善措施没有改变同行评议制度中决策结果取决于专家定性判断的本质，但仍旧存在评审偏见、开创性研究被拒、评审结果具有随机性等问题加速了科学领域中的马太效应：资源分配出现显著集中和分层的现象[68]。当过去的成绩成为资源分配的主要依据时，拥有科学界更多承认和声望的科研人员更容易获得能促进其研究的资源，而有实力但最初没那么幸运的普通学者无法获取资助进行下一步的研究[69]。这种优势和劣势的积累使科研人员的群体差距不断扩大，加剧了同行承认和资源分配的不平等，阻碍科学进步和知识创新。同时，非一致性和评审偏见问题往往使得决策结果具有潜在随机性，因此考虑在同行评议中引入随机机制，尝试添加更正式的随机性来平衡现有制度中已经出现的潜在随机性问题。

# 3随机机制及其在科学基金同行评议中的应用

# 3.1随机机制的相关介绍

随机机制最早由Greenberg在1998年提出，其建议将英国国家卫生研究院

$1 5 - 2 0 \%$ 的科学基金以随机抽签的方式发放给那些通过质量审查的项目申请人，该机制没有否定机会在基金资助中的重要性，反而将它视为决定因素[70]。随机机制在基金同行评审中发挥效用具有一定的前提条件，需要同行专家对提交的项目申请进行预选，那些一致认为质量高的将直接被资助，一致认为没有学术价值的会被拒绝，对于价值“不明确”的考虑运用抽签方法进行分配。随机机制主要用于以下三种情况：

（1）学术价值等同或相近，不好排序的项目申请。同行专家在审查项目申请书时，很容易分辨出那些质量很好的或者质量很差的研究，但是通常需要花费大量时间来整理排名中等的项目申请的具体顺序[71]。在学术价值相近的前提下，评审人在排序时容易依据个人偏好或受所属学术关系网的影响，决策不够客观，结果具有潜在的随机性。

（2）专家意见不一致，无法达成共识的项目申请。同行专家由于专业背景和实际经验存在差异，或者对评审规则的理解把握不同，在评审某些项目申请时会产生不一致甚至截然相反的意见。若采取少数服从多数或者保险起见直接拒绝资助的做法可能会错失有价值的研究。

（3）非正统但具有开创性想法的项目申请。诺贝尔医学奖、物理学和化学奖获得者的 $30 \%$ 关键论文背后的研究都是在没有直接资助的情况下完成的[72],同行专家对开创性的想法常常存在保守偏见，科学基金资助的项目往往都是相对“主流”、“更安全”的研究[73]。一个良好的资助系统应该尽可能广泛分配资金，增加科学领域知识的多样性，孕育科学变革。

在实际的基金评议过程中，运用随机机制做出资助决策通常经过三个阶段：

（1）预选阶段。运用传统的同行评议过程评估申请书的学术价值，将符合上述情况的项目申请编号准备抽签，对不合格的申请书提供详细的反馈意见，可以修改后重新提交；

（2）抽签阶段。将编完号的项目申请按一定的规则进行抽取，在资金预算允许的范围内，向尽可能多的项目提供支持。未中签的申请自动进入下一次的抽签，研究人员不用每年都写新的申请书;

（3）资助结果均衡阶段。随机分配机制对管理人员有更高的要求，因为基金资助结果具有高度的不确定性。对那些获得抽签机会但由于运气不好长期未获得资助的个人或者学科领域，可以提供特定的资金予以扶持。此外，考虑对年轻学者进行单独抽签，或者同行专家在预选过程中保留更多的代表，以提高他们获得基金资助的机会[74]。

# 3.2随机机制在科学基金评审中的应用案例

# （1）美国基础问题研究所（FQXi）小额资助计划

位于纽约的基础问题研究所(Fundamental Questions Institute)是一个接收个人和基金会捐赠的非营利性组织，自2006 年以来致力于促进、支持和传播物理学和宇宙学基础问题的研究，特别是不太可能得到传统资金支持的对现实深刻理解所不可或缺的创新思想。目前该组织的资助分为大额资助和小额款项资助，对于大额款项的资助FQXi会召集专家审查小组，经过标准的专家同行评审竞争过程，决定是否予以资助。小额资助计划每年两次，主要面向研究所的会员，不对外开放[75]。通过简化的申请程序，运用随机抽签方法来发放价值从1000 美元到1.5万美元不等的小额资金。

成为FQXi会员主要有三种途径： $\textcircled{1}$ 成功获得大额资助计划的申请人（PI)自动成为组织会员； $\textcircled{2}$ 每半年向现任成员征集提名，经FQXi同行专家评议后批准，具有多项提名且其工作符合FQXi使命的个人将被邀请为成员； $\textcircled { 3 } \mathrm { F Q X i }$ 举办的顶级比赛获胜者（如一等奖获得者）被提名为会员，并将接受与会员提名者相同的审查过程[76]。

# （2）新西兰健康研究理事会“ExplorerGrants”计划

新西兰健康研究理事会从2013年开始将随机机制用于“探索者基金计划（ExplorerGrants）”，吸引和资助具有重大影响的变革性研究，减轻同行评议人员和管理人员的负担，减少评审偏见。该计划要求申请人提供一份简短的项目申请书（大约6页纸），采用双盲方式进行评估，将评估重点放在研究项目本身的质量上。具体评估过程如下：

$\textcircled{1}$ 评审委员会专家小组对申请书进行评估。每一份申请由三名评审专家依据是否具有潜在的变革性和方案的可行性进行评定，每位专家会给出“是”或“否”的结果，当获得两票及两票以上“是”的申请才可以进入随机抽签环节；

$\textcircled{2}$ 运用计算机随机数生成器为待抽签的项目分配一个随机数，然后按从最小到最大随机数的顺序，选择可用预算范围内的申请[77]。

新西兰健康研究理事会正在追踪获得资助的申请人后续的研究工作，历年来获得探索者资助的研究人员已经在遗传性疾病的治疗、危重病人的氧化应激设备发明以及65岁以上的医疗保健转型研究等方向取得了较大进展，探索者资助计划为变革性想法提供了落地机会。

# （3）新西兰科学促进技术创新计划“SeedProjects”项目

科学促进技术创新计划（The Science for Technological Innovation challenge，SfTI)是新西兰11项“国家科学挑战”计划之一，该计划于2015年启动，聚焦物理与工程科学领域，旨在促进新西兰高科技领域技术创新和经济增长[78]。从2016 年开始，SfTI运用随机机制为“种子项目（SeedProjects）”提供基金资助，面向新西兰科研人员主导的、小型且技术复杂的研究，为SfTI带来新的想法和新的极具潜力的研究人员。每项被选中的项目申请最多可获得20万美元的资金支持，为期2年。申请人依据发布的项目征集(CfP)，提交符合资格、评估标准和支持机制的申请书，具体评估过程如下：

$\textcircled{1}$ 初步筛选阶段。评审专家小组审查项目申请，讨论并决定申请书是否符合技术研究主题的科学质量标准，符合要求的才可以进到投票程序；

$\textcircled{2}$ 随机抽签阶段。这一阶段需要经过三轮抽取，首先充分满足毛利愿景（VisionMatauranga）标准将被选定进行VM抽签，被抽中的项目申请直接获得资助，未被抽中的将参与接下来的优先抽签。对于那些不符合资格的，直接进到普通抽签环节。优先抽取是依据预先设定的优先标准如早期研究人员或者开创性研究，这一环节是对VM抽签环节未抽中的和满足优先标准的项目申请一起抽取，被选中的获得资助，没有被抽中的进行下一轮普通抽签环节。普通抽签环节后所有剩余可用的资金被分配完毕[79]。

整个过程结束后，所有申请人都会通过电子邮件收到受否被资助的通知，包括反馈意见。自2016年以来，SfTI已资助了84个种子项目。2021年种子项目基金是“国家科学挑战”十年期限内（2014-2024年）的最后一轮资助。

# （4）德国大众汽车基金会“Experiment！”资助计划

大众汽车基金会（TheVolkswagen Foundation）从2012年开始为"Experiment!”计划提供资金支持，该计划面向科学与工程以及生命科学领域，旨在发掘变革性和高风险研究，如违反直觉的假设、非常规的技术或全新的研究方法，质疑或改变所涉领域现有范式。每个获得资助的项目有机会获得高达12万欧元的经费，限制在18个月内结项，不要求必须成功，意外发现和失败都是可接受的结果[80]。从2017年开始，在筛选项目申请予以资助时采用随机抽签方式，该计划要求申请人提交简短的申请书，一般包括3页项目描述和1页自我评估，同样采用双盲评审的方式，申请人的个人信息对专家匿名。具体评估过程如下：

$\textcircled{1}$ 基金会工作人员进行初步筛选，选取符合该计划要求和质量标准的项目申请，这个阶段从600份申请书过滤到120-140份；

$\textcircled{2}$ 将初步筛选出的120-140份申请书提交给跨学科的专家评审团（8-10位）进行审查，专家小组依据研究的学术价值进行讨论，筛选出80-100份质量过关的申请书，同时从中选定15-20个质量很好的项目申请。所有符合条件的进入随机抽签环节，包括选定了的质量很好的项目申请；

$\textcircled{3}$ 这一环节随机抽取出10-15个项目申请，最终一共确定30-40个项目进行资助。申请人将不知道他们提交的项目申请是被专家组成员选中的还是通过抽奖选中的，这样操作可以对比两种审查程序的结果，评估随机机制的效果[81]。

引入随机抽签方式后，该计划已经资助99个研究项目，随机抽签机制还在测试阶段，基金会计划依据该项目的经验对随机机制进一步完善。

# （5）瑞士国家科学基金会“Postdoc.Mobility”资助计划

瑞士国家科学基金会（SNSF）从2018年开始面向全部学科领域，在博士后流动基金（Postdoc.Mobility）中试验了随机抽签的策略。针对那些已经获得博士学位并希望在瑞士从事学术事业的初级研究员，获得资助的博士生将会从育儿津贴、生活保障、研究、差旅等各方面收到补贴，进行为期2年，最短12个月的研究[82]。该资助计划要求申请人提交研究计划、个人简历、职业规划和两名推荐人的推荐信。具体评估过程如下：

$\textcircled{1}$ SNSF行政人员在截止日期前通过mySNF平台接收研究人员的申请，筛选满足既定标准和个人要求的项目申请书，并相应地通知申请人；

$\textcircled{2}$ 对项目申请进行质量评估。仅根据提交的文件对项目申请的科学性、原创性、方法的可行性进行评估，将申请书分为三组：资助（学术价值较高的）、讨论、拒绝（质量较差的），该阶段可能会征求外部专家评审意见；

$\textcircled{3}$ 抽签确定最终资助结果。项目申请具有同等的科学质量不能进一步区分时，采取抽签方式决定。随后，研究会主席会确认预算和程序的合法性，得到最终的决策决定[83]。

瑞士国家科学基金会（SNSF）将抽签方式逐步扩大到所有资助计划，2021年3月份开始在决胜局（相当于基金项目申请的会议评审阶段）使用随机选择机制对质量相当的项目申请进行选择。当无法用客观标准决定两个或多个项目申请的排名时为其分配编号，由工作人员进行抽签，抽出来的顺序就是这些项目申请的排名，资助与否取决于这个排名[84]。2021年运用随机方式对278项项目申请中的9项确定了资助排名，占 $3 . 2 \%$ 。

通过调研上述基金资助计划可知，当前随机机制在基金同行评议中主要作用于小额度、规模一般、持续时间较短的项目，极少用于非常大型、经费很高的项目。绝大多数用于风险较高、探索性强的项目，鼓励开创性研究，没有用于紧急专项项目的资助计划（表1）。

表1随机机制在基金评议中的应用案例  

<html><body><table><tr><td>资助计划</td><td>开始时间</td><td>资助类型</td><td>资助金额</td><td>随机抽签策略</td></tr><tr><td rowspan="3">美国基础问题研究 所（FQXi）小额资助 计划</td><td>2010年</td><td>面向物理学和宇 宙学基础问题的 研究，特别是不太</td><td rowspan="3">1500-15000</td><td rowspan="3">对研究所会员 进行随机抽签</td></tr><tr><td>可能被传统资金</td><td></td></tr><tr><td>支持的对现实深 刻理解不可或缺 的创新思想</td><td>美元不等 发放资助</td></tr><tr><td>新西兰健康研究理 事会“Explorer2013年 Grants”计划</td><td>研究</td><td>面向生命科学领 域，旨在改善新西 兰人生活质量，吸 引和资助具有重 大影响的变革性</td><td>15万美元</td><td>运用随机数生 成器对待抽签 项目进行优先 级排序</td></tr></table></body></html>

<html><body><table><tr><td>资助计划</td><td>开始时间</td><td>资助类型</td><td>资助金额</td><td>随机抽签策略</td></tr><tr><td>新西兰科学促进技 术创新计划“Seed Projects”项目</td><td>2016年 究</td><td>聚焦物理与工程 科学领域，面向新 西兰科研人员主 导的、小型且技术 复杂的创新性研</td><td>20万美元</td><td>三轮：毛利愿 景VM 抽签; 优先抽签；普 通抽签</td></tr><tr><td>德国大众汽车基金 会“Experiment！” 资助计划</td><td>2017年</td><td>面向科学与工程 以及生命科学领 域，旨在发掘变革 性和高风险研究</td><td>12万欧元</td><td>将待抽签项目 编号，写在球 上进行实物抽 取，机会均等</td></tr><tr><td>瑞士国家科学基金 会"Postdoc.Mobility” 资助计划</td><td>2018年</td><td>域，在博士后流动 基金中试验随机 抽签策略</td><td>费十旅费十 研究和会议分时，通过编 费用）</td><td>面向全部学科领不定（生活申请质量相近 无法进一步区 号抽签来决定</td></tr></table></body></html>

# 3.3随机机制应用于科学基金同行评议的反馈

为了获取随机机制用于科研项目分配方案的反馈，Philipps 对德国物理和生命科学领域的32位研究人员（包含博士生、博士后和教授）进行半结构化访谈，其中有9人获得了大众基金会的“Experiment！”资助计划。所有受访者均接受将随机机制和同行评审过程结合起来，但反对纯粹的随机资助[85]。Liu等人通过问卷调查调研了2013-2019年新西兰健康研究理事会的申请人对随机分配方式的可接受性以及该方式是否改变了研究人员的申请方法。在325份调查邀请中，收到126份回复： $\textcircled{1}6 3 \%$ 的申请人认为探险者项目采用随机机制分配科研经费是一种可接受的方法， $78 \%$ 获得探险者资助的被调查者认为随机是可以接受的，但那些被专家组拒绝的申请人中只有 $44 \%$ 认为随机机制是可以接受的； $\textcircled{2}$ 对随机分配用于其他经费的支持较少， $40 \%$ 赞成， $3 7 \%$ 反对。这种情况出现可能与探险者项目的性质有关，它的资助金额比其他项目要小，主要针对风险更大的创新性研究;$\textcircled{3} 7 0 \%$ 的申请人表示，即使知道基金采取随机分配，他们的申请方法及准备申请的时间（约为10天）也没有受到影响。原因可能是项目申请必须通过初步的同行评审才能进入随机抽签阶段，所以申请人仍然需要在申请书中体现出项目的优点[86]。2020 年布鲁塞尔自由大学的社会科学家 Beerli通过随机分配从 SNSF 获得了约10万瑞士法郎的博士后流动补助金，Beerli表示随机机制解决了从质量相似的项目申请中做出最终决定的难题，因为在不同的学科中，有些想法可能同等重要[84]。

虽然多数研究人员支持将这种分配方式进行推广，但也存在一些反对的声音。作为通过随机机制获得资助的年轻学者，Ackerley认为基金的主要目标是寻求确定最佳的项目申请进行资助，运用随机抽签方式的前提是同行专家在识别此类申请上是无效的。但是新西兰基金会专家组的绝大多数成员都是严谨的学院派，他们勤奋工作致力于筛选出值得资助的研究。这种方式对那些自愿付出时间提升研究质量却无法被看到的学者来说是一种打击[87]。同样地，Beattie 表示随机机制是科学共同体“懒惰”的表现。科学基金申请的审查取决于对项目质量的评估，这需要证据和理性判断的结合，而不是抽签决定。因此随机机制需要被抵制，保证那些精心准备的高质量项目申请获得资助[88]。此外，Vindin担心随机机制会阻碍职业发展和创新想法的实现，同行专家的积极评价和建议对刚起步的研究人员来说至关重要。他希望自己未来的发展建立在认可的基础上，而不是靠运气。随机机制的普遍使用可能导致具有潜在变革性的想法被任意搁置，学术研究随之受到影响[89]。

在基金评审中引入随机机制的初衷是最大限度地保障资助过程和结果的公平公正，并且提高评审效率。传统的同行评议因其存在的缺陷会加速马太效应，对于想要改变当前权力结构的人来说，随机分配机制值得尝试。该方式赋予研究人员同等的资助机会，机会对于科学研究能否开展是极其重要的[90]。“科学向所有人开放”的做法可以防止资源过于集中，分散资助增加了研究的多样性，有利于科学创新[91-92]。同时，专家对“中间地带”的项目申请进行质量排序的过程耗时耗力，多数学者倾向于在保障申请书质量的基础上（经过预选阶段）运用随机抽签方法提高评审效率[40]，更快地投入科学研究。

对随机机制持怀疑态度甚至强烈反对的人们认为基金的资助决策需要经过科学严谨的流程，而随机机制是不理性、不谨慎的，结果不具有说服力。同行专家有能力以他们的知识和经验做出最好的判断，不能因为实施过程中没有达到理想状态就直接放弃[93]。反对意见主要集中在： $\textcircled{1}$ 科学基金要保证学术价值较高的项目申请获得资助，随机机制可能会导致资助的低质量项目数量增加，好的想法无法被抽中，造成资源浪费； $\textcircled{2}$ 随机抽签方式可能会造成机制的滥用，面对同行审查制度申请人会尽全力撰写申请书，若明确资助是随机分配的，项目申请书的质量可能会整体下降； $\textcircled{3}$ 随机机制无法做到完全排除特定利益的影响，如何保障申请人获得平等机会，哪些项目申请得到较多的资金，偏见和偏袒同样会出现。问题转化为愿意接受同行专家的评审偏见，还是政客和管理人员的职权偏见[94]。

# 4思考与建议

当前随机机制主要用于学术价值“不明确”的项目申请的筛选，即同行专家对项目申请进行预选后，将学术价值相近不好排序的、意见不一致无法达成共识的和非正统但具有开创性想法的项目申请抽签决定资助与否，以提高评审效率，使结果相对公正。但目前，随机机制在基金评议中的应用仍只是小范围的探索，受到不同研究人员的欢迎和反对，随机机制的适用性和对评价制度的影响尚不明确，因此未来需要加强对随机机制本身的研究以及实施后的潜在影响和成效研究。

# 4.1开展随机机制的接受度调研

科研人员对于随机抽签方式存在着主观抵触和质疑，这种质疑不会随着随机机制决策结果的可靠性被验证而消失，还取决于决策程序是否合法。依据科学标准进行批判性审议后得到对于有限资源分配决定，这样的过程（同行评议制度）被认为是合法的，也表明了决策的科学产生方式与公众舆论、随意断言之间的区别[93]。人们接受随机机制的前提是决策过程和结果具有科学性和可解释性。已有研究在比较随机机制和传统的同行评议时关注的主要是评审时投入的各项成本和获得的效果，较少关注研究人员对随机机制的态度和接受度。但是对于随机机制的接受度决定着该机制能否得以持续应用甚至是进一步扩展应用范围。所以未来研究需要开展对于随机机制的接受度调研，如通过定性访谈或问卷调查的形式，了解处于各个职业生涯的研究人员（包含项目申请人和基金评审专家）对于实施随机机制的反馈，总结他们赞成或反对的原因，以及他们认为在什么情况下或满足什么条件时运用随机分配方式是合理的、可接受的。

# 4.2加强随机机制的适用性研究

当前引入随机机制进行资助决策的基金类型多数为： $\textcircled{1}$ 高风险、探索性较强的创新项目资助计划：鼓励提出意想不到的假设、运用全新的研究方法、质疑甚至企图改变领域现有范式； $\textcircled{2}$ 小额度、规模一般、时间较短的项目资助计划：小额度拨款提供试错机会，最终结果不成功也明确了一些方向，不会造成很大的资源浪费。多数科学突破都源于一些不为常人所理解的尝试，随机机制的运用有助于鼓励科学创新，孕育重大突破。但是随着瑞士国家科学基金会2021年将随机机制应用到所有资助计划，引起我们的思考：基础科学研究通常需要长期持续的资金支持，将随机机制直接扩展到所有类型的资助计划是否合理？是否会产生更高的资源浪费风险？对项目申请的准备过程会造成什么样的改变？因此未来需要加强随机机制的适用性研究，进行回顾性比较实验，通过对比分别运用随机机制和传统同行评议对基金项目申请的资助过程和结果，探讨随机机制作用于某类基金资助计划的适用性和有效性。

# 4.3追踪随机机制的实施效果

由前文的调研可知研究人员和公众反对随机机制的应用很大一部分原因是担心随机机制可能会导致资助的低质量项目申请数量增加，好的想法无法被抽中，造成资源浪费。但可以明确的是科学研究中存在着大量的不确定性，运用传统的同行评议制度确定资助的项目，也可能无法取得预期成果，需要后续相关的监督检验。所以对于随机机制实施后成效的担忧可以通过追踪后续研究开展情况和项目成果产出来缓解。未来研究可以考虑从两个方面开展： $\textcircled{1}$ 建立健全相关的监督管理体系和信用评价体系。该举措主要是为了确保研究项目完成进度的真实性及经费使用的合理性，如通过要求定期提交进展报告、坚持定向检查、随机抽查，保持积极持续的沟通和监管，及时发现问题、调整资助决策，防止资源浪费； $\textcircled{2}$ 比较分析通过同行评议直接筛选出的项目、预选后经随机抽签筛选的项目及未被资助的项目后续的成果产出情况。如将产生的出版物的文献计量指数（类似高被引)作为衡量指标[95]，估算项目的产出质量如何，以此检验随机机制的应用效果。

# 4.4分析随机机制对评价制度的改变

在当前的评审制度中，科研奖励、基金资助、人才称号等已成为职业晋升的必要条件，是否获得基金资助（而不是优质的完成项目）已经成为职称评定的重要依据。但是能否拿到基金资助并不是完全取决于科研人员的研究基础和研究能力，还受到学术地位、职务大小等影响。这种循环加速了科学领域中的马太效应，使得科研人员的群体差距不断扩大[68]。而基金同行评审中随机机制的引入，相当于加入更显性、正式的随机因素，使得获得基金不再成为判断科研人员成功与否的显性标准，将有可能打破职业晋升的马太效应。评价制度的调整和评价制度造成的影响是复杂的系统性问题。针对随机性的引入，我们需要思考如何调整评价制度？而相应的调整又会如何影响研究人员的科研行为？这一系列研究的前提是随机机制的全面实施，但是现在国际上只有少量的应用案例，无法获取充足的数据支撑。所以后续研究可以考虑通过复杂动力学模拟、多主体模拟等计算社会科学的方式进行仿真模拟，量化分析随机机制对评审制度的影响及研究人员科研行为的相应调整。

# 4.5探索随机机制用于其它评价场景的可能性

随机机制除了应用于基金项目的评审，在期刊论文的评审[96]、候选人的任命[97]和名额分配[98-99]等场景中也有学者提出了尝试。在论文评审中引入随机机制同样是专家对论文进行预选后对具有争议的论文进行随机抽签决定发表与否，此类举措可能会淡化成果评价对于发表渠道的依赖性，让大家更注重对研究内容本身的评价，引导科研人员从跟踪热点向创新性研究转变。未来研究可以探讨随机机制在论文评审中的适用性，如通过追踪在某期刊上被录用和拒稿论文的影响力，经对比分析后验证方法的可靠性。此外，随机机制还被用于从同等优秀的候选人中确定当选者，进行名额分配。当前的奖励制度下，职位、称号等常常与诸多机会直接绑定，造成“赢者通吃”的局面，随机机制的引入有可能打破这一现象，让荣誉回归本质。当然也会有名额浪费风险，未来可以通过设置考察期，持续追踪验证是否胜任该职位（开展高质量的研究、发表高质量的论文等），以及是否出现职权滥用的情况。

# 4.6探究适用于我国国情的随机机制

在随机机制的应用案例中，大部分都是采用均等机会，即进入到抽签环节的项目申请得到资助的概率均等，这种方法虽然简单高效，但是在一定程度上没有办法满足国家科学整体发展的需求。以我国国家自然科学基金为例，要求面向世界科技前沿，优先考虑国家重大战略需求，支持与战略性、前瞻性领域关键核心技术相关的研究，同时关注学科交叉领域及有望获得突破性原创成果的研究项目。此外还强调继续强化对青年人才、领军人才的稳定支持[100]。因此要想达到随机机制应有的成效，面对不同的科研环境或战略需求时需要做相应的调整。后续研究需要探究适用于我国国情的随机机制，考虑设置什么样的随机抽签策略是科学合理的，能有效推动我国科技发展。不断增加的项目申请竞争有限的资助资金，若依据优先标准在抽签环节为不同类型的申请赋予不同的权重使资助机会向特定领域或特殊研究群体倾斜，是否会加剧其他的申请人之间的竞争？设置优先资助标准的同时如何避免加入过多的人为因素，凸显随机机制的公平优势？

# 5总结

科学基金已逐步成为促进国家基础研究和培养高端科技人才的重要物质保障，随着资助规模不断扩大，如何完善基金评审机制，客观、准确、高效地测度项目本身的学术价值和发展潜力是研究的关键课题。同行评议是当前评估项目申请的主要方法，但以主观判断为主的评审机制常受到一些非学术因素的影响，如专家利益冲突、非共识、评审偏见等，使评审结果具有一定的不可靠性和随机性，加剧科学领域的马太效应。研究人员从构建丰富的专家库、回避利益冲突、定期培训专家、探索多种评议方式等方面做出改善，其中具有变革性的一项举措是在评议过程中引入随机机制，尝试添加更正式的随机性降低非学术因素的影响，平衡同行评议制度中已经出现的潜在随机性。系统梳理随机机制在基金评审中的应用案例后发现，随机机制在基金同行评议中的应用处于萌芽阶段，其适用范围、使用成效和对评价制度的影响尚不明确。未来可以围绕开展随机机制的接受度调研、加强随机机制的适用性研究、追踪随机机制实施后的效果、分析随机机制对评审制度的改变、探索随机机制用于其他评价场景的可能性及探究适用于我国国情的随机机制等方面做进一步的探讨。

# 参考文献

[1]国务院关于成立国家自然科学基金委员会的通知[J].中华人民共和国国务院公 报,1986(07):164-165.   
[2] Csiszar A.Peer review:Troubled from the start[J].Nature News,2016,532(7599):306.   
[3]Baldwin, Melinda. In referees we trust?[J]. Physics Today, 2017, 70(2):44-49.   
[4]United States General Accounting Office. University funding:In formation on the role of peer review at NSF and NIH[R].Washington,1987.   
[5]英国研究理事会咨询委员会（ABRC）.同行评议——同行评议调查组给研究理事会咨询 委员会的报告[R].国家自然科学基金会政策局译（内部资料）,1992.   
[6] Chubin D E.Grants peer review in theory and practice[J].Evaluation review,1994,18(1): 20-30.   
[7] 郭碧坚,韩宇.同行评议制——方法、理论、功能、指标[J].科学学研究,1994(03):63-73+2.   
[8] 吴述尧.同行评议方法论[M].北京:科学出版社,1996,(2):3.   
[9] Benos D J,Bashari E,Chaves JM,et al.The ups and downs of peer review[J].Advances in Physiology Education,2007,31(2):145-152.   
[10]国务院办公厅.国家自然科学基金条例[EB/OL].(2007-03-06).[2021-11-09]. http://www.nsfc.gov.cn/publish/portal0/tab471/info70222.htm.   
[11] Abramo G, D'Angelo C A, Viel F. Selecting competent referees to assess research projects proposals: a study of referees' registers[J]. Research Evaluation, 2013,22(1): 41-51.   
[12] Lamont M, Mallard G, Guetzkow J.Beyond blind faith: overcoming the obstacles to interdisciplinary evaluation[J]. Research Evaluation, 2006,15(1): 43-55.   
[13]张琳,孙梦婷．突破交叉科学研究同行评议困境[N]．中国社会科学报,2021-11-23(001).   
[14] Lyall C，King E. International good practice in the peer review of interdisciplinary research[J]. University of Edinburgh,2013.   
[15] Bammer G. What constitutes appropriate peer review for interdisciplinary research?[J]. Palgrave Communications, 2016, 2(1): 1-5.   
[16] Oleinik A. Conflict (s) of interest in peer review: Its origins and possible solutions[J]. Science and Engineering Ethics, 2014, 20(1): 55-75.   
[17] Sandstrom U, Hallsten M. Persistent nepotism in peer-review[J]. Scientometrics,2008,74(2): 175-189.   
[18] Juznic P, Peclin S, Zaucer M, et al. Scientometric indicators: peer-review, bibliometric methods and conflict of interests[J]. Scientometrics, 2010, 85(2): 429-441.   
[19] Li D. Expertise versus Bias in Evaluation: Evidence from the NIH[J]. American Economic Journal: Applied Economics, 2017, 9(2): 60-92.   
[20]杨列勋.对基金项目同行二次通讯评议的案例分析[J].中国科学基金,2003(01):52-55.   
[21] Cole S,Cole, Simon G. Chance and consensus in peer review[J]. Science,1981, 214(4523): 881-886.   
[22] Fogelholm M,Leppinen S,Auvinen A,et al.Panel discusson does not improve reliability of peer review for medical research grant proposals[J]. Journal of Clinical Epidemiology, 2012, 65(1): 47-52.   
[23] Pier E L,Brauer M,Filut A, et al. Low agreement among reviewers evaluating the same NIH grant applications[J]. Proceedings of the National Academy of Sciences， 2018,115(12): 2952-2957.   
[24]钟书华.同行评议:科学共同体的民主决策机制解析[J].社会科学管理与评 论,2002(01):40-46.   
[25] Lee C J, Sugimoto C R, Zhang G, et al. Bias in peer review[J]. Journal of the American Society for Information Science and Technology,2013, 64(1): 2-17.   
[26] Bornmann L ，Mutz R ，Daniel H D .Gender differences in grant peer review: A meta-analysis[J]. Journal of Informetrics, 2007,1(3):226-238.   
[27] Van der Lee R, Ellemers N. Gender contributes to personal research funding success in The Netherlands[J]. Proceedings of the National Academy of Sciences， 2015，112(40): 12349-12353.   
[28] Guglielmi G. Gender bias goes away when grant reviewers focus on the science[J]. Nature, 2018, 554(7690): 14-16.   
[29] Donna K. Ginther,Walter T. Schaffer,Joshua Schnell,Beth Masimore,Faye Liu,Laurel L. Haak,Raynard Kington. Race,Ethnicity，and NIH Research Awards[J]. Science,2011, 333(6045): 1015-1019.   
[30] Hayden E C .Racial bias continues to haunt NIH grants[J]. Nature,2015, 527(7578):286.   
[31] Li D,Agha L. Big names or big ideas: Do peer-review panels select the best science proposals?[J]. Science, 2015, 348(6233): 434-438.   
[32] Daniels R J. A generation at risk: young investigators and the future of the biomedical workforce[J].Proceedings of the National Academy of Sciences, 2015,112(2): 313-318.   
[33] Geisler E.The Metrics of Science and Technology[M].Westport:Quorum Books,2000.   
[34] Bromham L, Dinnage R, Hua X. Interdisciplinary research has consistently lower funding success[J].Nature, 2016, 534(7609): 684-687.   
[35] Boudreau, Kevin J.，et al.Looking across and looking beyond the knowledge frontier: Intellectual distance, novelty, and resource allocation in science[J]. Management science, 2016,62(10):2765-2783.   
[36] Brezis E S.Focal randomisation:An optimal mechanism for the evaluation of R&D projects[J]. Science and Public Policy,2007, 34(10):691-698.   
[37] Stephan P, Veugelers R, Wang J. Reviewers are blinkered by bibliometrics[J]. Nature News, 2017, 544(7651): 411.   
[38] National Science Board (US). Report of the National Science Board on the National Science Foundation's Merit Review System[M]. National Science Foundation, 2016.   
[39] Herbert D L, Barnett A G, Clarke P, et al. On the time spent preparing grant proposals: an observational study of Australian researchers[J]. BMJ open, 2013, 3(5): e002800.   
[40] Roumbanis L.Peer Review or Lottry?A Critical Analysis of Two Different Forms of Decision-making Mechanisms for Allocation of Research Grants[J].Science,Technology and Human Values,2019,44(6):994-1019.   
[41] Sniderman P .Expert Political Judgment: How Good Is It? How Can We Know?[J]. Political Psychology,2010,28(2):260-262.   
[42] Nicholson JM, Ioannidis JPA.Conform and be funded[J]. Nature, 2012, 492(7427): 34-36.   
[43] Stavropoulou C,Somai M, Ioannidis J P A. Most UK scientists who publish extremely highly-cited papers do not secure funding from major public and charity funders: A descriptive analysis[J]. PLoS One, 2019,14(2): e0211460.   
[44] National Science Foundation. Proposal and award policies and procedures guide[EB/OL]. (2007-6-1). [2022-1-11]. htps://www.nsf.gov/pubs/policydocs/papp/nsf07140.pdf.   
[45]潘云涛,苏成,赵筱媛,王运红,程薛柯,袁军鹏.专家识别推荐模块技术框架研究[J].情报学 报,2016,35 (09):923-931.   
[46]曹洪飞,顾复,张今,陈芨熙.基于专家主页的专家信息抽取方法研究[J].情报探 索,2019(12):1-9.   
[47]张志清,凡艳,苏顺华.基于 SNA 的科研项目评审专家选择与回避策略研究[J].武汉理工大 学学报(信息与管理工程版),2016,38(03):367-371.   
[48] 朱伟珠,李春发.基于概念知识网络的“小同行”评议专家遴选方法实证研究[J].情报杂 志,2017,36(07): 78-83+88.   
[49]戴石钰,石进,李明.基于论文合作关系的科研项目专家回避模型研究[J].图书情报工 作,2021,65(18): 125-132.   
[50] Quaglio G L, Guardabasso V, Olesen O F, et al. The selection of experts evaluating health projects for the EU Sixth Framework Program[J]. Journal of Public Health, 2011,19(5): 445-452.   
[51] Shepherd J, Frampton G K, Pickett K, et al. Peer review of health research funding proposals: A systematic map and systematic review of innovations for effectiveness and eficiency[J]. PloS one,2018,13(5): e0196914.   
[52] Cyranoski D. Artificial intelligence is selecting grant reviewers in China[J]. Nature, 2019, 569(7756): 316-318.   
[53]窦豆,李萃,江虎军,郝艳妮,李东,徐岩英,孙瑞娟.科学基金同行评议智能指派的实践探索 [J].中国科学基金,2021,35(03):458-461.   
[54] Sattler D N, McKnight P E， Naney L，et al. Grant peer review: improving inter-rater reliability with training[J]. PloS one,2015,10(6): e0130450.   
[55] Derrick G， Samuel G .The future of societal impact assessment using peer review: pre-evaluation training， consensus building and inter-reviewer reliability[J]. Palgrave Communications, 2017,3(1):1-10.   
[56] Zhao Y .Reliability analysis of group experts and testing of evaluation outcomes[J].Journal of University of Science and Technology of China, 2016, 46(2):165-172.   
[57]李旭彦,宋英华,杨晓秋.基于PageRank 的评审专家信誉度度量方法[J].科研管理,2016, 37(03): 133-142.   
[58]张尧,林春.专家评审特征分析及专家反评估方法研究[J].工业工程,2020,23(06): $1 2 4 - 1 3 0 + 1 5 4$ ：   
[59]国家自然科学基金委员会.2021年“负责任、讲信誉、计贡献”评审机制试点工作. (2021-03-29)[2022-06-14].https://www.nsfc.gov.cn/publish/portal0/tab434/info80801.htm.   
[60]贺晓宇.基于TOPSIS 的科技项目评审专家信用评价模型研究[JJ.科技管理研 究,2020,40(03):32-38.   
[61] 汪建,王裴裴,丁俊.科技项目专家评审的元评价综合模型研究[J].科研管理,2020,41(02): 183-192.   
[62] Silver A. Taiwan considers double-blind peer review for grants[J]. Nature,2019.   
[63] Lee M, Om K, Koh J.The bias of sighted reviewers in research proposal evaluation: a comparative analysis of blind and open review in Korea[J]. Scientometrics, 20o0， 48(1): 99-116.   
[64] Solans-Domenech M, Guillmón I， Ribera A,et al.Blinding applicants in a first-stage peer-review process of biomedical research grants:An observational study[J].Research Evaluation, 2017,26(3): 181-189.   
[65] Bhattacharjee,Y.NSF's"Big Pitch"Tests Anonymized Grant Reviews.Science,2012,336(6084): 969-970.   
[66] The Velux Foundations.The significance of an anonymous application[EB/OL]. (2019-2-19). [2022-1-12].The significance of an anonymous application| (veluxfoundations.dk).   
[67] Bollen J. Who would you share your funding with?[J]. Nature,2018, 560(7717): 143-144.   
[68] Merton, R. K . The Matthew Effect in Science: The reward and communication systems of science are considered[J]. Science,1968,159(3810): 56-63.   
[69] Bol T,de Vaan M, van de Rijt A. The Mathew effect in science funding[J]. Proceedings of the National Academy of Sciences, 2018, 115(19): 4887-4890.   
[70] Greenberg D S . Chance and grants.[J]. The Lancet, 1998, 351(9103):686.   
[71] Adam D. Science funders gamble on grant lotteries[J]. Nature, 2019, 575(7785): 574-5.   
[72] Tatsioni A, Vavva E, Ioannidis JP A.Sources of funding for Nobel Prize - winning work: public or private?[J]. The FASEB journal, 2010, 24(5): 1335-1339.   
[73] Avin S. Policy considerations for random allcation of research funds[J].RT.A Journal on Research Policy and Evaluation, 2018, 6(1):1-27.   
[74] Fang F C, Casadevall A .Research Funding: the Case for a Modified Lotery[J]. mBio, 2016, 7(2):e00422-16.   
[75] Ioannidis J. Fund people not projects[J]. Nature,2011, 477(7366):529-531.   
[76] Fundamental Questions Institute.FQXi Membership[EB/OL]. [2022-1-12]. https://fqxi.org /members.   
[77] Health Research Council of New Zealand.2021 PEER REVIEW MANUAL for research applications in the 2022 Annual Contestable Funding Round[EB/OL]. (2021-9-23). [2022-1-12].htps:/gateway.hrc.govt.nz/funding/downloads/2021_Peer_Review_Manual.pdf.   
[78]谢成锁.新西兰国家科学挑战计划概况[J].全球科技经济瞭望,2014,29(05):32-39+76.   
[79] National Science Challenges.Seedproject development process[EB/OL].[2022-1-12]. https://www.sftichallenge.govt.nz/for-researchers/funding-and-get-involved/seed-project-dev elopment-process/.   
[80] VolkswagenStiftung.Experiment!-In search of bold research ideas (completed)[EB/OL]. [2022-1-14].htps://www.volkswagenstiftung.de/en/funding/our-funding-portfolio-at-a-glance /experiment.   
[81] VolkswagenStiftung.This is how it works: The partially randomized selection process within the initiative "Experiment![EB/OL]. [2022-1-14]. htps://www.volkswagenstiftung. de/en/funding/our-funding-portfolio-at-a-glance/experiment/infografic-partially-randomizedselection.   
[82] National Research Council.Regulations on the awarding of mobility fellowships to post docs("Postdoc.Mobility fellowships")[EB/OL].(2021-5-5).[2022-1-16]. https://www.snf.ch/ media/en/7ec22xUFqQOtJmE7/Reglement_PM_ab2021_en.pdf.   
[83] SwissNational Science Foundation. Evaluation procedure:the main stagesata glance[EB/OL].[2022-1-16].https://www.snf.ch/en/MnwA9gE4ykW1cWzT/page/evaluationprocedures/careers.   
[84] Chawla D S.Swiss funder draws lots to make grant decisions[J]. Nature， 2021. doi:10.1038/d41586-021-01232-3.   
[85] Philipps A. Science rules! A qualitative study of scientists’approaches to grant lottery[J]. Research Evaluation, 2021,30(1): 102-111.   
[86] Liu M, Choy V, Clarke P, et al. The acceptability of using a lottery to allocate research funding: a survey of applicants[J]. Research integrity and peer review, 2020, 5(1): 1-7.   
[87] Ackerley D.Grant lotery systems: a winner responds[J]. Nature, 2020, 579(7799):343-343.   
[88] Beattie A. Grants: lottery is laziness[J]. Nature,2020,577(7791): 472-472.   
[89] Vindin H. Grants: don't leave it to luck[J]. Nature, 2020,577(7791):472-472.   
[90] Gildenhuys P.Lotteries make science fairer[J]. Journal of Responsible Innovation,2020, 7(S2): S30-S43.   
[91] Brezis E S. Focal randomisation: An optimal mechanism for the evaluation of R&D projects[J]. Science and Public Policy,2007,34(10): 691-698.   
[92] D Gilles. Selecting applications for funding: why random choice is better than peer review[J]. Rt A Journal on Research Policy & Evaluation, 2014, 2(1):1-14.   
[93] Reinhart M, Schendzielorz C. The lottery in Babylon—On the role of chance in scientific success[J]. Journal of Responsible Innovation, 2020,7(S2): S25-S29.   
[94] Bedessem B. Should we fund research randomly? An epistemological criticism of the lottery model as an alternative to peer review for the funding of science[J]. Research Evaluation, 2020,29(2): 150-157.   
[95] Lindner M D, Nakamura R K. Examining the predictive validity of NIH peer review scores[J]. PLoS One,2015,10(6): e0126938.   
[96] Osterloh M, Frey B S. How to avoid borrowed plumes in academia[J]. Research Policy, 2020, 49(1): 103831.   
[97] Burckhardt,A. Ueber die Wahlart der Basler Professoren, besonders im 18. Jahrhundert[J]. Basler Zeitschrift fur Geschichte und Altertumskunde,1916,15:28-46.   
[98] Bennett M, Wakeford R. Health policy, student selection and curriculum reform[J]. Health policy and education, 1982, 3(2): 173-181.   
[99]新华社.中共中央 国务院关于深化教育教学改革全面提高义务教育质量的意见[EB/OL]. (2019-7-8). [2022-1-22]. http://www.gov.cn/zhengce/2019-07/08/content_5407361.htm.   
[100]国家自然科学基金委.2022 年度国家自然科学基金改革举措.[EB/OL].(2022-1-19). [2022-2-23]. https://www.nsfc.gov.cn/publish/portal0/tab1099/.

# Research on the Application of Partial Randomisation Mechanism in Grant Peer Review

Liu Yahui1.2Yang Liying1 Shen Zhesil

(1.National Science Library，Chinese Academy of Sciences，Beijing100190; 2.DepartmentofLibrary，InformationandArchives Management，ScholofEconomicsandManagement，UniversityofChinese Academy of Sciences，Beijing 100190）

Abstract: Currently, peer review is playing the key role in research funding. The fairness of the review process and the reliability of the review results determine whether truly valuable research can be funded. However, conflicts of interest, non-consensus among reveiwers and review bias often occur in the review process, which makes the funding decisions unreliable and random to a certain extent. And the Matthew effect in science further amplifies this implicit randomness in future resource allocation. A list of changes and modifications have been proposed and tested to solve the aforementioned problems of peer review in funding allocation，among which a transformative initiative -- partical randomisation or lottery-style mechanism -- attracts growing attention. Specifically, funding institutions randomly fund those proposals with similar academic value, non-consensus among experts, and original innovation that have been pre-selected by peer experts.In this paper,we systematically review the funding schemes that have adopted the randomisation mechanism,and analyze the applicability and acceptance of this idea. The application of partial randomisation in grant peer review is still in an embryonic stage,and its scope of application, effectiveness and impact on the evaluation system are still unclear. Future research could focus on the theoretical mechanism of random allocation itself and its potential implementation impact to explore the possibility of applying this mechanism to foster fair and efficient funding allocation.

Keywords: research funding; peer review; randomisation mechanism; preselection