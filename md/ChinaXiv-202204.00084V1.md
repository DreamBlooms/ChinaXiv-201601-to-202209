# 一种基于质量评价的无人机航拍图像拼接方法

王欢‘，周颖玥a,b，王学渊ä，王欣宇a(西南科技大学 a.信息工程学院;b.特殊环境机器人技术四川省重点实验室，四川 绵阳 621010)

摘要：针对大视差无人机航拍图像拼接中出现的错位、伪影问题，提出一种基于质量评价寻找最佳拼接缝的方法QEB-U。首先通过常规拼接缝估计得到初始拼接缝，然后根据无人机航拍图像的特点，综合考虑结构相似性、色差、纹理复杂度，提出一种新的质量评价函数对拼接缝上的每个像素进行评价，进而根据评价结果更新差异代价，之后再重新估计拼接缝。估计和评价过程重复执行，直到拼接缝趋于稳定则停止迭代，最后通过梯度融合生成最终结果。实验结果表明，所提方法可以避免大视差无人机航拍图像拼接中出现错位、伪影，优于目前几种无人机航拍图像拼接方法，且得到的拼接缝优先穿过道路、林地等区域，更加符合人类视觉感知，在常见的图像清晰度评价指标上均表现良好。

关键词：图像拼接；拼接缝估计；质量评价；无人机航拍图像 中图分类号：TP391.41 doi:10.19734/j.issn.1001-3695.2022.02.0039

Quality evaluation-based image stitching for UAV images

Wang Huana, Zhou Yingyuea, bt, Wang Xueyuana, Wang Xinyua (a.School of InformationEngineering,b.SichuanProvincialKeyLaboratoryofRobotTechnology Used forSpecial Environment,Southwest University of Science& Technology,Mianyang Sichuan 621010, China)

Abstract: Aiming atsolving problemsof dislocation and artifacts inthe stitching oflarge parallax UAVimages,this paper proposeda methodtofind thebeststitching seam basedon quality evaluation QEB-U.First,the initial seam was estimated byconventionalseam estimation.Then,anew quality evaluationfunction was proposed forevaluating each pixelon the seam according tothecharacteristicsof the UAVimage likethe structuralsimilarity,color diference,andtexturecomplexity.The diference cost was updated according to the evaluation result and the seam was acquired afterthat.The estimation and evaluation processwasrepeateduntil theseambecomesstable that theiteration wasstopped.Finally,thestitching UAV image was generated by gradient fusion.The experimentalresults showed thatthe proposed method canavoid dislocation and artifacts inthe stitching oflarge parallx UAV images,which wassuperior to several current UAV image stitching methods. Besides,theobtained stitching seam preferentiallypassed through roads,woodlands,etc.It was more inlinewith human visual perception and performed well in common image clarity evaluation indicators.

Key words: image stitching; seam estimation; quality evaluation; UAV images

# 0 引言

随着无人机遥感技术的发展，其研究已广泛应用于地理信息学、灾害监测与评估、国防等领域，尤其是灾害应急响应和灾害调查I。无人机遥感能够在短时间内获得目标区域最直观的高分辨率图像，为决策提供视觉依据。然而受无人机飞行高度和相机性能的限制，很难从单幅无人机航拍图像中获取整个感兴趣区域的景象。因此，有必要研究将具有重叠区域的无人机航拍图像快速拼接成具有更大视野的高分辨率图像的技术[2]。

图像拼接一般来说，有两种方法：一种是基于单应变换的对齐技术，使图像尽可能精确对齐[3-7]；另一种就是基于拼接缝引导的切割技术，即根据预定义的能量函数，寻找一条使得能量函数达到最小的拼接缝[2.8\~I2]。基于单应变换的对齐技术最终目的都是让图像尽可能对齐，但是当遇到大视差的环境，该类方法会产生局部伪影或失真的情况。基于拼接缝引导的图像拼接方式最早是由Gao 等人提出[8]，首先通过随机抽样一致性算法得到若干单应变换矩阵，对每个单应变换矩阵计算拼接缝，然后根据质量评价结果选择最好的拼接缝作为最终结果。Lin等人通过自适应特征加权将局部对齐计算和拼接缝估计紧密耦合，并通过超像素特征分组有效减少迭代时间。Li等人[10]将人类感知的非线性和非均匀性考虑到能量最小化中，用显著性权重来模拟人眼更倾向于关注的对象，使得拼接结果更符合人类视觉感知。Liao等人[I指出以往拼接缝驱动的方法都是评估拼接缝的平均性能，无法找到人类视觉感知上最佳的拼接缝，因此他们更加细致的评估拼接缝上的每一个像素，并引入混合成本来评估拼接缝沿线的像素，然后根据评估结果重新估计拼接缝，结果显示该方法避免了伪影，并且总体上效果更好。Yuan等人[2]提出一种基于超像素的无人机航拍图像拼接方法，拼接时间的到显著提升，并在能量函数中融入纹理复杂度信息，使得拼接缝穿过特定的低纹理复杂度区域，拼接结果更加符合人类视觉感知。Fang等人[12]在图像拼接的融合阶段进行创新，提出一种颜色混合方法来消除拼接结果中的颜色不一致问题，并利用超像素分割大大降低计算复杂度提高拼接效率。Zhao等人[13]则利用多个平面代替映射点进行优化，将重构结果直接用于图像融合，实现了一种新的具有较高精度和较快速度的航拍图像拼接方法。Pham等人[14]首先根据航拍图像的地理位置信息估计出重叠区域，然后将特征匹配限制在该区域，以避免不必要的计算和误差累计，使得拼接更加精确快速。Ren 等人[15]利用航拍图像的位置信息进行粗配准计算出全局变换矩阵，并通过多层感知机将全局变换矩阵进行快速校正，因此该方法很好地结合了基于参数和基于特征的方法，实现了拼接速度和精度的理想折中。Guo等人[16]结合局部配准技术提出了一种全局的对齐策略，使得拼接结果在保持形状的前提下获得较好的对齐精度。Mo等人[17]利用神经网络进行深度特征的提取与匹配，实现了一种新的具有鲁棒性的航拍图像拼接方法，为其他学者探索结合深度学习的图像拼接方法提供帮助。

通常接缝驱动的方法都是根据预定义的拼接缝质量指标找到一条最佳的拼接缝，但是这些方法中定义的质量指标都是评估拼接缝的整体质量。文献[11]已证明，在许多情况下，整体质量最好的拼接缝不一定符合人类视觉感知。本文针对大视差无人机航拍图像，提出一种新的拼接缝迭代估计方法(qualityevaluation-based image stitching for UAV images，QEB-U)，其中迭代过程由拼接缝上的每个像素来引导。首先进行常规拼接缝估计得到初始拼接缝，然后根据无人机航拍图像的特点，综合考虑结构相似性、色差、纹理复杂度的特点，提出一种新的质量评价函数对拼接缝上的每个像素进行评价，进而根据评价结果更新差异代价并重新估计拼接缝。估计和评价过程重复执行，直到拼接缝趋于稳定则停止迭代，最后通过梯度融合生成最终结果。实验结果表明，所提方法对大视差无人机航拍图像的拼接有较好的效果，得到的拼接缝优先穿过道路、林地等区域，更加符合人类视觉感知，在常见的图像清晰度评价指标上均表现良好。

# 1 所提方法

针对大视差无人机航拍图像这种特殊情况下的图像拼接，为了找到符合人类视觉感知的最佳拼接缝，笔者更加细致地去评估拼接缝上的每个像素，提出一种新的基于质量评价寻找最佳拼接缝的方法QEB-U，在解决错位伪影问题的同时使得拼接缝更加符合人类视觉感知。

# 1.1方法流程

本文提出的方法流程如图1所示。

拼接缝传统 评估 更新对应 趋于稳定拼接缝估计 拼接缝 差异代价 最佳拼接缝4迭代

首先采用常规拼接缝估计[8]得到初始拼接缝，之后对拼接缝进行质量评价。以往的质量评价方法都是基于拼接缝的整体质量，而本文方法则是对拼接缝上的每个像素进行质量评价，不符合期待的像素会具有较大成本，符合期待的像素则具有较小成本。成本较大的像素是拼接缝应避免穿过的，因此后续拼接缝重新估计中，在能量函数中对它们进行更大的惩罚。当拼接缝趋于稳定则停止迭代，通过梯度融合[18]生成最终结果。下面将关键步骤进行详细说明。

# 1.2常规拼接缝估计

设两幅初步配准的待拼接图像分别为 $I _ { 0 }$ 和 $I _ { 1 }$ ， $\boldsymbol { L } \in ( 0 , 1 )$ 是一个标签集。令 $p$ 代表重叠区域 $P$ 中任意一个像素点，拼接缝的意义是将一个标签 $l _ { p } \in L$ 赋给每个像素 $p$ 0 $l _ { p } = 0$ 代表 $p$ 的值是从 $I _ { 0 }$ 复制过来，而 $l _ { p } = 1$ 代表 $p$ 的值是从 $I _ { 1 }$ 复制过来。常规拼接缝搜索的过程就是能量函数最小化的过程，能量函数定义为

$$
E ( l ) = \sum _ { p \in P } D _ { p } \left( l _ { p } \right) + \sum _ { ( p , q ) \in N } S _ { p , q } \left( l _ { p } , l _ { q } \right)
$$

其中 $N$ 代表四邻域， $q$ 是 $p$ 的相邻像素点。常规拼接缝估计的平滑项定义为

$$
S _ { p , q } \left( l _ { p } , l _ { q } \right) = \frac { 1 } { 2 } \big | l _ { p } - l _ { q } \big | ( I _ { d } \left( p \right) + I _ { d } \left( q \right) )
$$

$$
I _ { d } \left( \cdot \right) = \left\| I _ { 0 } \left( \cdot \right) - I _ { 1 } \left( \cdot \right) \right\| ^ { 2 }
$$

其中差异代价 $I _ { d }$ 代表欧几里德色差[19]。数据项 $D _ { \boldsymbol { p } } \left( \boldsymbol { l } _ { \boldsymbol { p } } \right)$ 用来衡量标签分配给像素 $p$ 的代价，更多细节请参考文献[10]。最后通过图割[20]最小化能量函数 $E ( l )$ 来估计拼接缝。

# 1.3拼接缝选代估计

# 1.3.1质量评价

本文结合无人机航拍图像特点，综合考虑结构相似性、色差、纹理复杂度的特点，提出一种新的质量评价函数。首先重叠区域未对齐部分结构上通常不一致，因此在质量评价函数中引入结构相似性指数(SSIM)[2I]来评估拼接缝。其次引入接缝两侧的色差来更加细致的评估拼接缝。最后，对于无人机航拍图像，发现符合人类视觉感知的拼接缝更倾向穿

![](images/38df3559fe9624f4ed3d745870edde90e083dba8ec077eee7a851c03f0e2c0d3.jpg)  
图1QEB-U方法流程图  
Fig.1Flowchart of the QEB-U method   
图2Gabor特征的一些可视化示例Fig.2Some visualization examples of Gabor features

过一些特定区域，如道路、林地、湖泊等。根据这些区域纹理较弱的事实，在质量评价中引入纹理复杂度，使得在低纹理复杂区域的像素具有更小的成本，引导拼接缝穿过这些区域。考虑到Gabor滤波器[22]可以很好地表征基础纹理信息，因此采用Gabor 特征描述符[23]来描述纹理复杂度。图2展示了Gabor特征的一些可视化示例，图像的亮度代表纹理复杂度。对于拼接缝上的像素 $p _ { i }$ ，混合成本 $E \big ( p _ { i } \big )$ 定义式为

$$
E \left( p _ { i } \right) = \lambda \cdot E _ { p a t c h } \left( p _ { i } \right) \cdot E _ { p o i n t } \left( p _ { i } \right) \cdot E _ { g a b o r } \left( p _ { i } \right)
$$

其中 $\lambda$ 是一个常数，保持 $E \big ( p _ { i } \big )$ 总体的大小， $E _ { p a t c h } \left( p _ { i } \right)$ 表示以像素 $p _ { i }$ 为中心的局部面片在 $I _ { 0 }$ 与 $I _ { 1 }$ 之间的SSIM指数，$E _ { p o i n t } \left( p _ { i } \right)$ 表示像素 $p _ { i }$ 与其相邻像素 $q _ { i }$ 的色差， $E _ { g a b o r } \left( p _ { i } \right)$ 表示像素 $p _ { i }$ 的Gabor 特征。

SSIM 的范围为[-1,1]，当两个局部区域越相似，SSIM会趋向于1，显然拼接缝上未对齐的像素会具有较大的值。$E _ { p a t c h } \left( p _ { i } \right)$ 的表达式如下所示。

$$
E _ { p a t c h } \left( p _ { i } \right) = \frac { 1 - S S I M \left( p _ { i } \right) } 2
$$

$E _ { p o i n t } \left( p _ { i } \right)$ 具体计算如下:

$$
E _ { p o i n t } \left( p _ { i } \right) = \frac { \left\| I _ { 0 } \left( p _ { i } \right) - I _ { 1 } \left( p _ { i } \right) \right\| ^ { 2 } + \left\| I _ { 0 } \left( q _ { i } \right) - I _ { 1 } \left( q _ { i } \right) \right\| ^ { 2 } } { 2 }
$$

1.3.2更新差异代价

通常，拼接缝上未对齐的像素或者位于较复杂区域的像素具有较大的混合成本 $E \big ( p _ { i } \big )$ 。因此，利用像素 $p _ { i }$ 的混合成本$E \big ( p _ { i } \big )$ 对差异代价 $I _ { d } \left( p _ { i } \right)$ 进行修正，得到新的差异代价 $\overline { { I _ { d } } } ( p _ { i } )$ ：

$$
\begin{array} { r } { \overline { { I _ { d } } } \left( p _ { i } \right) = \left\{ \begin{array} { r l r l } { f \left( E \left( p _ { i } \right) \right) \cdot I _ { d } \left( p _ { i } \right) } & { } & { p _ { i } \in N \left( s e a m \right) } \\ { I _ { d } \left( p _ { i } \right) } & { } & { o t h e r w i s e } \end{array} \right. } \end{array}
$$

其中 $f ( E ( p _ { i } ) )$ 定义为

$$
f \left( E ( p _ { i } ) \right) = e ^ { \sigma ( E ( p _ { i } ) - \varepsilon ) }
$$

其中 $N ( s e a m )$ 是包含接缝在内的带状区域，通过向接缝左右扩展5个像素生成。 $\sigma$ 是一个控制 $f$ 变化幅度的常数， $\varepsilon$ 是合理成本的阈值。当混合成本 $E \big ( p _ { i } \big )$ 越小时， $f ( E ( p _ { i } ) )$ 会趋近于0，新的差异代价 $\overline { { I _ { d } } } ( p _ { i } )$ 也会越小；若混合成本 $E \big ( p _ { i } \big )$ 越大时，$f ( E ( p _ { i } ) )$ 会增大，新的差异代价 $\overline { { I _ { d } } } ( p _ { i } )$ 也会越大。然后利用新的差异代价重新计算能量函数，并通过图割重新估计拼接缝。估计和评价过程反复进行，直到拼接缝趋于稳定。这里的“稳定”意味着当前拼接缝可以完全包含在先前拼接缝的带状区域。得到最佳拼接缝后，通过梯度融合[18]生成最终结果。

# 1.4算法伪代码

算法1 QEB-U输入：两幅初步配准的图像 $I _ { 0 }$ 和 $I _ { \mathrm { 1 } }$ 输出：最终的拼接缝 $\boldsymbol { S } _ { f }$ 1 初始化 $B = \emptyset$ ：2 计算差异代价矩阵 $I _ { d }$ ，计算平滑项 $S _ { p , q }$ ，并通过图割最小化能量函数 $E ( l )$ 得到初始拼接缝 $S _ { \mathrm { { l } } }$ ：3 while $S _ { 1 } \not \in B$ 4 计算拼接缝 $S _ { 1 }$ 上每个像素的混合成本 $E _ { p }$ ：5将接缝 $S _ { 1 }$ 扩展为带状区域 $N \big ( S _ { 1 } \big )$ ，并重新计算该带状区域像素的差异代价 $\overline { { I _ { d } } }$ ：6将新的差异代价 $\overline { { I _ { d } } }$ 带入计算平滑项 $S _ { p , q }$ ，并通过图割最小化能量函数 $E ( l )$ 得到新的拼接缝 $S _ { 2 }$ ：7令 $B = B \cup N \left( S _ { 1 } \right)$ ， $S _ { 1 } = S _ { 2 }$ ：8 end9return $S _ { f } = S _ { 1 }$ ：

# 2 实验

为了验证本文所提方法的有效性，本文选用公开的具有较大视差的无人机航拍图像来进行算法性能测试，其中数据来源于文献[2]以及[24]共290幅图像。实验中，为了获得最优性能，将相关参数设置如下：在计算局部片面间的结构相似性时，

将局部片面大小设置为 $2 1 \times 2 1$ ，式(4)中的 $\lambda$ 设为10，式(8)中的 $\sigma$ 和 $\varepsilon$ 设为5和0.12。首先通过文献[9]提供的对齐方法将输入图像初步对齐，然后采用所提方法进行拼接缝迭代估计得到最终拼接缝，最后通过梯度融合[18]生成最终结果。算法实现平台为MatlabR2020a，主机为2.9GHZ八核CPU笔记本电脑。

# 2.1与其他拼接方法的视觉比较

分别与 Zaragoza 等 提 出 的 APAP(as-projective-as-possible)[3]，Chang 等提出 的 SPHP(shape-preserving half-projective)[5]，Lin 等提出的 AANAP(Adaptive As-Natural-As-Possible)[6]，Li 等提出的 ELA(parallax-tolerant image stitchingbased on robust elastic warping)[25]以及 Liao 等提出的SPW(single-perspective warps in natural image stitching)[26]方法进行比较。图3(a)是一组具有较大视差的机场无人机航拍图像。图3(b)是APAP算法所得的拼接结果，图3(c)是SPHP算法所得的拼接结果，图3(d)是AANAP算法所得的拼接结果，图3(e)是ELA算法所得的拼接结果，图3(f)是SPW算法所得的拼接结果，图3(g)是所提算法得到的拼接结果。可以明显看出图3(b)-(f)的机翼和机尾有明显的伪影(红框部分)，以及明显的分界(绿框部分)，而本文所提方法获得的图3(g)所对应的拼接结果清晰无伪影，且更加自然。

图4是一组具有较大视差的房屋无人机航拍图像及几种方法的拼接结果图，可以看到图4(b)-(f)的房屋出现了伪影和失真模糊(红框部分)，图4(b)(d)(e)出现了明显分界(绿框部分)，而图4(g)所对应的拼接结果清晰自然，无伪影无失真。

![](images/dfdd00e633d21467d0bb887afe35410671d20ed1f8dc16dd5f8211f80fc9a000.jpg)  
图3几种拼接方法对于有较大视差的机场无人机航拍图像的拼接结果示意图

![](images/d51139eac6e08f1a0f22a321c90a0b05f58b2fcb52b4cd62e2502dec25deba8c.jpg)  
Fig.3Schematic diagramof the stitching results several stitching methods for airport drone aerial images with large parallax   
图4几种拼接方法对于有较大视差的房屋无人机航拍图像的拼接结果示意图  
Fig.4Schematic diagram of the stitching results several stitching methods for aerial images of house with large parallax

# 2.2与其他拼接缝搜索算法的视觉比较

为了验证本文所提拼接缝搜索策略的有效性，本文与最新的拼接缝搜索算法进行了对比，主要包括Perceptionbased(PB)[10]，Quality evaluation-based(QEB)[11]和 Fast androbust(FARSE)[27]方法。

如图5所示，红线标记了各个方法检测到的最佳拼接缝位置。可以看到，由PB，QEB，FARSE方法寻找到的最佳拼接缝会穿过突出物体，例如房屋等建筑物(绿框部分)，而所提方法寻找到的拼接缝可以避开房屋等突出物体，优先穿过道路、林地等，使得拼接效果更加符合人类视觉感知。

# 2.3与其他拼接缝搜索算法的效率比较

同时，本文与最新的拼接缝搜索算法PB、QEB、FARSE在拼接时间上进行了对比，本文选用[24]提供的三组分辨率为 $3 6 8 0 ^ { * } 2 4 5 6$ 的高清航拍图像进行对比实验分析。表1是三组实验的具体数据，可以看出在对4k高分辨率航拍图像进行拼接时，PB、QEB、FARSE以及本文所提方法的拼接用时都在一分钟以上。本文所提方法在拼接效率上与PB和QEB相似，但不及FARSE，因此所提方法的拼接效率还有待提高，后续考虑使用超像素分割来减少迭代计算量，从而提高拼接效率。

# 2.4 客观指标评价

为了更加精准客观地比较不同方法拼接后的图像质量优劣，本文使用一些常见的图像清晰度评价指标，如Brenner梯度函数、Tenengrad梯度函数、Laplacian梯度函数、灰度方差函数以及能量梯度函数。上述几种函数计算的值越大，表明拼接图像的清晰度越高，拼接效果越好。下面对这几个函数的计算做简要描述。

Brenner梯度函数 $D _ { B } ( f )$ 定义为

$$
D _ { B } ( f ) = \sum , \sum _ { x } \bigl | f ( x + 2 , y ) - f ( x , y ) \bigr | ^ { 2 }
$$

其中 $f ( x , y )$ 表示图像 $f$ 对应像素点 $\scriptstyle ( x , y )$ 的灰度值。

![](images/94839bef5e2e2241ea4eb08efa58edcc63b18d8d2732b93f92c7693dcbe4a4d5.jpg)  
图5不同拼接缝搜索算法的最佳拼接缝位置比较  
Fig.5Comparison of optimal seam positions for different seam search algorithms

表1不同拼接缝搜索算法的拼接效率对比  
Tab.1Comparison of stitching efficiency of different stitching seam search algorithms   

<html><body><table><tr><td>分组</td><td>不同拼接算法</td><td>拼接用时(s)</td></tr><tr><td>第一组</td><td>PB</td><td>256</td></tr><tr><td>图像大小：4.28MB与4.34MB</td><td>QEB</td><td>162</td></tr><tr><td>分辨率：3680*2456</td><td>FARSE</td><td>65</td></tr><tr><td></td><td>QEB-U</td><td>158</td></tr><tr><td>第二组</td><td>PB</td><td>146</td></tr><tr><td>图像大小：4.72MB与4.62MB</td><td>QEB</td><td>300</td></tr><tr><td>分辨率：3680*2456</td><td>FARSE</td><td>76</td></tr><tr><td></td><td>QEB-U</td><td>287</td></tr><tr><td>第三组</td><td>PB</td><td>148</td></tr><tr><td>图像大小：3.75MB与3.73MB</td><td>QEB</td><td>172</td></tr><tr><td></td><td>FARSE</td><td>84</td></tr><tr><td>分辨率：3680*2456</td><td>QEB-U</td><td>154</td></tr></table></body></html>

Tenengrad梯度函数 $D _ { \boldsymbol { r } } ( \boldsymbol { f } )$ 定义如下：

$$
D _ { T } ( f ) = \sum , \sum _ { x } | T ( x , y ) | \qquad ( T ( x , y ) > T )
$$

$$
T ( x , y ) = \sqrt { G _ { x } ^ { 2 } ( x , y ) + G _ { y } ^ { 2 } ( x , y ) }
$$

其中 $T$ 是给定的边缘检测阈值， $G _ { x }$ 和 $G _ { y }$ 分别是像素点 $\left( x , y \right)$ 处Sobel水平和垂直方向边缘检测算子的卷积。

Laplacian梯度函数 $D _ { L } ( f )$ 定义如下：

$$
D _ { L } ( f ) = \sum , \sum _ { x } \bigl | L ( x , y ) \bigr | \qquad ( L ( x , y ) > T )
$$

其中 $L ( x , y )$ 是像素点 $\left( x , y \right)$ 处Laplacian 算子的卷积。

灰度方差函数 $D _ { s } ( f )$ 定义如下：

$$
D _ { s } ( f ) = \sum , \sum _ { \boldsymbol { x } } \biggl ( \biggl | f ( x , \boldsymbol { y } ) - f ( x , \boldsymbol { y } - 1 ) \biggr | + \biggl )
$$

能量梯度函数 $D _ { \scriptscriptstyle E } ( f )$ 定义如下：

$$
D _ { E } ( f ) = \sum , \sum _ { x } ( \overset { \ v } { \underset { { \mid f ( x , y + 1 ) - f ( x , y )  } ^ { 2 } } { | f ( x + 1 , y ) - f ( x , y ) | } ^ { 2 } } + )
$$

对图3和4的拼接结果分别进行清晰度指标计算并进行线性归一化处理，实验结果如表2、3所示。可以看出：本文算法几乎在所有评价指标上都比其他方法具有更高的数值，这意味着所提出的方法可以获得更加清晰的拼接图像。

Tab.2Comparison of clarity test results in figure 3   
表3图4的清晰度测试结果比较  

<html><body><table><tr><td>不同拼接 算法</td><td>Brenner 梯度函数</td><td>Tenengrad 梯度函数</td><td>Laplacian 梯度函数</td><td>灰度 方差</td><td>能量 梯度</td></tr><tr><td>APAP</td><td>0.7660</td><td>0.5467</td><td>0.9291</td><td>0.8143</td><td>0</td></tr><tr><td>SPHP</td><td>0.4057</td><td>1</td><td>0</td><td>0</td><td>1</td></tr><tr><td>AANAP</td><td>0.7912</td><td>0.7606</td><td>1</td><td>1</td><td>0.0762</td></tr><tr><td>ELA</td><td>0</td><td>0.8999</td><td>0.4348</td><td>0.4596</td><td>0.7053</td></tr><tr><td>SPW</td><td>0.0785</td><td>0</td><td>0.4446</td><td>0.1534</td><td>0.1071</td></tr><tr><td>QEB-U</td><td>1</td><td>0.9536</td><td>0.8148</td><td>0.8519</td><td>0.2018</td></tr></table></body></html>

表2图3的清晰度测试结果比较  
Tab.3Comparison of clarity test results in figure 4   

<html><body><table><tr><td>不同拼接 算法</td><td>Brenner 梯度函数</td><td>Tenengrad 梯度函数</td><td>Laplacian 梯度函数</td><td>灰度 方差</td><td>能量 梯度</td></tr><tr><td>APAP</td><td>0.7148</td><td>0.6929</td><td>0.7668</td><td>0.7299</td><td>0.7025</td></tr><tr><td>SPHP</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>AANAP</td><td>0.0490</td><td>0.0530</td><td>0.0256</td><td>0.0396</td><td>0.0334</td></tr><tr><td>ELA</td><td>0.5079</td><td>0.5936</td><td>0.2595</td><td>0.4095</td><td>1</td></tr><tr><td>SPW</td><td>0.7052</td><td>0.7285</td><td>0.6466</td><td>0.6828</td><td>0.9182</td></tr><tr><td>QEB-U</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0.9415</td></tr></table></body></html>

# 3 结束语

本文针对无人机航拍图像拼接提出一种基于质量评价寻找最佳拼接缝的策略，不仅可以解决大视差无人机航拍图像拼接中错位伪影的问题，而且得到的拼接缝在内容复杂的无人机航拍图像中优先穿过道路、林地等区域。实验表明，所提方法适合于无人机航拍图像拼接，拼接结果更符合人类视觉感知。

# 参考文献：

[1]李德仁，李明．无人机遥感系统的研究进展与应用前景[J].武汉大 学学报：信息科学版，2014,39(5):505-513.(Li Deren,Li Ming. ResearchAdvance and ApplicationProspectofUnmannedAerial Vehicle Remote Sensing System[J].Wuhan University Journal:Geomatics and Information Science,2014,39 (5):505-513.)   
[2]Yuan Y,Fang F, Zhang G. Superpixel-based seamless image stitching for UAV images [J].IEEE Trans on Geoscience and Remote Sensing,2020, 59 (2): 1565-1576.   
[3]Zaragoza J, Chin TJ,Brown MS,et al.As-projective-as-possible image stitching with moving DLT[C]//Proceedings of the IEEE conference on computer vision and pattern recognition.2013:2339-2346.   
[4]Zhang F,Liu F.Parallax-tolerant image stitching[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.2014: 3262-3269.   
[5]Chang CH, Sato Y, Chuang YY. Shape-preserving half-projective warps for image stitching [C]// Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.2014:3254-3261.   
[6]Lin C C,Pankanti S U,Natesan Ramamurthy K,et al.Adaptive asnatural-as-possible image stitching [C]// Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.2O15:1155- 1163.   
[7]Chen Y S,Chuang YY.Natural image stitching with the global similarity prior [C]// European conference on computer vision. Springer, Cham, 2016:186-201.   
[8] Gao J,Li Y,Chin T J,et al.Seam-driven image stitching[C]// Eurographics (Short Papers).2013: 45-48.   
[9]Li K,Jiang N,Cheong LF,et al. Seagul: Seam-guided localalignment for parallax-tolerant image stitching [C]// European conference on computer vision. Springer,Cham,2016: 370-385.   
[10] LiN,Liao T, Wang C.Perception-based seam cutting for image stitching [J].Signal, Image and Video Processing,2018,12 (5): 967-974.   
[11] Liao T, Chen J,Xu Y. Quality evaluation-based iterative seam estimation for image stitching [J]. Signal,Image and Video Processing,2019,13 (6): 1199-1206.   
[12] Fang F, Wang T,Fang Y,et al. Fast color blending for seamless image stitching[J].IEEE Geoscience and Remote Sensing Leters,2019,16 (7): 1115-1119.   
[13] Zhao Y,Liu G,Xu S,etal.Fast georeferencedaerial image stitching with absolute rotation averaging and planar-restricted pose graph [J]. IEEE Trans on Geoscience and Remote Sensing,2020,59 (4): 3502-3517.   
[14] Pham NT,Park S,Park C S.Fast and Eficient Method for Large-Scale Aerial Image Stitching [J].IEEE Access,2021,9:127852-127865.   
[15] Ren M,Li J,Song L,et al.MLP-based Efficient Stitching Method for UAV Images [J]. IEEE Geoscience and Remote Sensing Leters, 2022.   
[16] Guo D,Chen J,Luo L,et al.UAV Image Stitching Using ShapePreserving Warp Combined With Global Alignment [J]．IEEE Geoscience and Remote Sensing Letters,2021,9:1-5.   
[17] Mo Y,Kang X,Duan P,et al.A Robust UAV Hyperspectral Image Stitching Method Based on Deep Feature Matching [J]. IEEE Trans on Geoscience and Remote Sensing,2021,60:1-14.   
[18] Pérez P,Gangnet M,Blake A.Poisson image editing [M]/ ACM SIGGRAPH 2003 Papers.2003:313-318.   
[19] Kwatra V, Schodl A,Essa I,et al. Graphcut textures: Image and video synthesis using graph cuts [J].Acm Trans on Graphics (tog),2003,22 (3): 277-286.   
[20] Boykov Y,Kolmogorov V.An experimental comparison of min-cut/maxflow algorithms for energy minimization in vision [J].IEEE Trans on Pattern Analysis and Machine Intelligence,2004,26 (9):1124-1137.   
[21] Wang Z,Bovik AC,Sheikh HR,et al. Image quality assessment: from eror visibility to structural similarity[J].IEEE Trans on Image Processing,2004,13 (4): 600-612.   
[22] GuptaRK,ChiaAY S,Rajan D,et al. Image colorization using similar images [C]// Proceedings of the 2Oth ACM international conference on Multimedia.2012: 369-378.   
[23] Manjunath B S,Ma W Y. Texture features for browsing and retrieval of image data [J].IEEE Trans on Pattern Analysis and Machine Intelligence, 1996,18 (8): 837-842.   
[24] https://github.com/YuhuaXu/UAV-image-mosaicing-dataset   
[25] Li J,Wang Z,Lai S,et al.Parallax-tolerant image stitching based on robust elastic warping [J].IEEE Trans on Multimedia,2017,20(7): 1672-1687.   
[26]Liao T,LiN.Single-perspectivewarps innaturalimage stiching[J]. IEEE Trans on Image Processing,2019,29:724-735.   
[27] Hejazifar H, Khotanlou H. Fast and robust seam estimation to seamless image stitching [J]. Signal, Image and Video Processing,2018,12 (5): 885-893.