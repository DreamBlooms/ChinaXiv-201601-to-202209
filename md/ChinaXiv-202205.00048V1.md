# 面向实时事件流的复杂事件处理方法

邱涛¹，谢沛良‘，邓国鹏²，郗红梅²，郑智²，夏秀峰‘(1.沈阳航空航天大学 计算机学院，沈阳 110136;2.沈阳飞机工业(集团)有限公司 试飞站/试飞实验室，沈阳110034)

摘要：复杂事件处理是一种动态环境下对事件流进行分析的技术。复杂事件处理技术通常基于有限状态自动机实现，匹配过程中会在事件流上产生大量且重叠的部分匹配，有限状态自动机需维护大量的重复匹配状态，导致基于该技术的方法都会出现冗余计算的问题。为了提高复杂事件处理的匹配效率，提出了使用复杂事件实例覆盖技术来实现复杂事件处理的方法。通过设计临时匹配链式分区存储结构以及基于此结构的匹配算法，来利用复杂事件实例覆盖减少冗余计算，从而实现匹配效率的提升。在模拟数据集和真实数据集上进行了实验测试与分析，与两种常用的复杂事件处理技术进行比较。实验表明，提出的方法能够在保证匹配正确性的同时有效地减少匹配过程中的冗余计算，提高整体匹配效率。

关键词：复杂事件处理；查询优化；有限状态自动机；分区存储 中图分类号：TP315 doi:10.19734/j.issn.1001-3695.2021.12.0707

Complex event processing method over real-time event streams

Qiu Taol, Xie Peiliangl†, Deng Guopeng², Xi Hongmei², Zheng $Z \mathrm { { h i } } ^ { 2 }$ , Xia Xiufeng1 (1.Dept.of Computer,Schol of Shenyang Aerospace UniversityShenyang 110136,China;2.Flight Test Stationof Shenyang Aircraft Industry (Group) Co.LTD,Shenyang110034,China)

Abstract: Complex event processing is atechnology foranalyzingthe event streams ina dynamic environment.Complex event procesing technologyis usually implemented based on finite state automaton.During the matching process,a large numberof overlapping partial matches willbe generated bythe event tream.The finite state automaton neds to maintaina large numberofrepeated matching states,which leads to the problemofredundant calculation inthe methods based on this technology. In order to improve the matching effciencyofcomplex event processing, tis paper proposes a method ofusing complex eventinstance coverage technology to realize complex event processng.Bydesigning atemporary matching chain partition storage structure and matching algorithms based on this structure,redundant calculations can be reduced using complex event instance coverage,therebyachieving an improvement in matching eficiency.Experiments are performed on simulatedandrealdatasets,andcompared with twocommonlyusedcomplex eventprocesing technologies.Theexperimental results show thatthe proposed method can effectively reduce the redundant computation inthe matching process while ensuring the correctness of the matching,and improve the overall matching efficiency.

Key words: complex event processng; query optimization; nondeterministic finite automaton; partition storage

# 0 引言

随着信息社会的进一步发展，越来越多的行业采用复杂事件处理(complex event processing,CEP)技术来对海量的事件流进行实时的分析。复杂事件处理通过分析事件中的关系，通过关联、聚合、过滤等技术，根据事件间的时序关系和聚合关系制定查询规则，持续地从事件流中获取符合要求的事件序列。该技术在金融交易分析[1,2]、传感器网络[3]、物联网[4-6]、交通[7领域都有着广泛的应用。

目前，基于有限状态自动机(nondeterministicfiniteautomaton,NFA)的处理模型是最流行的复杂事件处理技术实现方式，例如SASE[8,9]、Cayuga[10,11]和Siddhi[12]。通过NFA的方式来实现的复杂事件处理技术，在事件流上进行匹配的过程中都会产生临时匹配，所产生的临时匹配能够被后续的事件使用，并且生成新的临时匹配以及最终的匹配结果。所以匹配过程中会在事件流上产生大量且重叠的部分匹配，有限状态自动机需维护大量的重复匹配状态，导致基于该技术的方法都会出现冗余计算的问题。尤其当复杂事件查询的时间窗口跨度大时，冗余计算将会给处理器和存储器等硬件资源带来巨大的额外开销。

为了减少基于有限状态自动机的复杂事件处理技术中的冗余计算，提高匹配效率，本文利用链式分区存储的结构来管理临时匹配，利用复杂事件实例覆盖来减少临时匹配的冗余产生和冗余拷贝，从而提高复杂事件匹配的效率。

综上所述，本文的主要贡献如下：

1）提出了复杂事件实例覆盖的概念，通过复杂事件实例覆盖，可以建立临时匹配之间的关联关系，基于此关系来减少临时匹配的冗余产生和冗余复制。

2）设计了一个临时匹配链式分区存储结构，通过该结构避免了临时匹配的集中式存储及使用，同时该结构也作为复杂事件实例覆盖的载体，构建了临时匹配之间的关联。

3）提出了基于临时匹配链式分区存储结构的复杂事件匹配算法CoverMatch和CombineMatch。通过这两个算法，能够在减少临时匹配数量和复制的情况下保证复杂事件处理匹配结果的正确性和完整性。

4)通过在模拟数据集和真实数据集上对优化方法的性能进行对比实验和分析，验证了所提方法和算法的有效性和高效性。

# 1 相关工作

复杂事件处理是从事件驱动业务出发的，将系统中产生的每一条数据记录都看成是一个事件，实时输入的数据流即为实时事件流，复杂事件执行引擎会根据事先制定好的复杂事件描述规则，来对事件流进行相应的判断、过滤、关联等操作，然后给用户输出一系列的更高层次的复合事件。其中复杂事件描述规则一般包含用户感兴趣的事件语义，或者是专业领域中某种既定的标准和规范。也就是说，复杂事件处理能够在实时事件流中识别某一个人为定义的复合事件，并且为用户反馈识别的结果。

目前复杂事件处理技术已经有了很多的研究成果，复杂事件处理技术一般采用非确定性有限状态自动机的变体模型来处理复杂事件的识别。

Diao 等人提出的SASE是一种复杂事件处理引擎，同时还提出了一种能够定义复合事件的事件描述语言CEL[13,14],这种语言具有类似SQL的高级结构，可定义事件序列、匹配策略、事件约束和事件窗口约束等。通过SASE引擎可将事件描述语言所定义的复合事件转变为非确定性有限状态自动机，从而实现在事件流上的事件获取和计算。Diao等还在SASE+[15]中对 SASE 进行了扩展，引入了对克林闭包、否定和聚合操作的支持。SASE/SASE $^ +$ 主要的缺陷在于，在NFA进行匹配的过程中，需要产生匹配结果的临时匹配，同时为了保证结果的准确性，不允许在时间窗口约束内将临时匹配丢弃，这种机制导致了临时匹配的堆积，从而影响了自动机的处理效率。

康奈尔大学开发的Cayuga也采用NFA作为计算模型来处理事件的识别，但是它对于事件的描述能力相对较差。Cayuga支持发布-订阅技术，并且提供了良好的可扩展性，此外还运用了查询优化技术，可将多个拥有相同时间戳的具有等价状态的事件一同进行处理。但是由于它的内核是单线程的，并没有有效地从这些优化技术中获益。

FlinkCEP[16]在设计思想上和SASE很接近，同样使用事件约束作为NFA节点状态转变的条件。从事件描述语言的角度来看，FlinkCEP与SASE的一个最大的区别是FlinkCEP没有支持定义复合事件的语言。为了替代事件描述语言，FlinkCEP需要用户使用Java或者Scala编写事件描述，这种定义方式可读性差且编写时易出错。

除了基于NFA模型实现的复杂事件处理技术之外，另外一种使用树来作为计算模型的实现复杂事件处理的技术也得到了广泛的研究和应用。

Mei等人提出的ZStream[17]是CEP领域基于树实现复杂事件处理技术的典型研究成果。ZStream 的事件描述语言与SASE非常相似，所遵循的语法大多数都相同。ZStream将事件存储在叶子节点，内部节点对应于操作符。在进行事件流处理时，它不会立刻判断到达事件的约束条件，而是先把事件进行收集到一定量，进而对其进行批处理。树结构和批处理的结合允许ZStream 根据期望成本和条件约束来执行各种复杂事件处理任务。例如，对于给定的复杂事件序列 $< A , B >$ =SASE将会为每一个出现的 $A$ 事件新建一个临时匹配，即使$B$ 事件的出现概率很低，而ZStream则可以遵循另一个匹配规则，一直等待 $B$ 事件的到达，再去批量检查先前到达的 $A$ 事件。但是ZStream仍然不能避免大量的未处理事件的堆积，这和NFA产生临时匹配的堆积本质上是一样的。

基于以上的研究可以发现，无论是基于NFA还是基于树的方法来实现复杂事件处理技术，为了复杂事件匹配结果的正确性和完整性，都需要存储至少一个时间窗口范围内的临时匹配。假设时间窗口跨度很大，复杂事件的处理将对处理器计算能力和存储器等硬件资源都带来了不小的负荷。

# 2 预备工作

复杂事件处理是一种面向事件流的查询分析技术，其目标是从大量的基本事件构成的事件流中，找出满足复杂事件描述语义的更高层次的复杂事件。本章节将详细介绍复杂事件处理涉及的预备知识。

定义1事件流。事件流 $S ( s _ { I } , s _ { 2 } , \cdots , s _ { n } )$ 由一系列的基本事件实例构成，其中 $s _ { i }$ 为事件实例，它包含了事件的类型、事件的属性和事件发生时的时间戳等信息。

事件流往往是由多个数据源的数据构成的，在使用海量数据的很多研究应用领域里，例如气象预测[18]、海上航行[19]和交通数据研究[20]，数据源可以是采集设备或者是传感器，因此需要先对数据使用融合技术[21,22]进行融合以得到包含多事件类型的事件流。

图1展示的是船只在航行中产生事件流的示例。其中事件流包含了 $A$ 、 $B$ 、 $C$ 三种事件类型， $A$ 表示低速启动， $B$ 表示船头左转 $9 0 ^ { \circ }$ ， $C$ 表示低速停靠。每个事件实例都包含时间戳以及属性值，此处使用相应的小写英文字母表示事件实例。例如， $b _ { I }$ 为 $B$ 事件类型的第一个事件实例，其时间戳为2，此外还包括行驶速度、行驶方向以及倾斜角度等属性。

事件实例 a1 b1 b2 b3 b4 C1 a2M时间戳 1 3 5 6 9 12 18

通过观察图1所示的事件流可以得知，在时间窗口1\~12内，船只先是低速开始启动，之后在航行过程中转了一个圈，最后低速停靠。

复杂事件是由事件流 $S ( s _ { I } , s _ { 2 } , . . . , s _ { n } )$ 上的若干事件实例构成的一个复合事件，表示为 $R ( r _ { I } , r _ { 2 } , . . . , r _ { n } )$ ， $\forall r _ { i } \in S , ( 0 \leq i \leq n )$ 。复杂事件表示在事件流上发生的客观存在的具体事件，其语义通常通过复杂事件描述语言所定义的查询来进行表示。

定义2复杂事件查询。复杂事件查询 $\varrho$ 是由一组定义在基本事件上的约束条件构成，用以定义和表示更高层次的复杂事件的属性特征。

当前的研究工作中已提出多种形式的复杂事件描述语言用以定义复杂事件查询，其中SASE提出了最具有代表性的复杂事件描述语言。其具备简洁的语法规则，灵活的表达能力，所以本文将使用SASE复杂事件描述语言来定义复杂事件查询。SASE事件描述语言是一种声明式语言，总体结构如下：

PATTERN <sequence pattern> [WHERE <qualification>] [AND <other qualifications>] [WITHIN <time window>]

使用上述的结构可以编写复杂事件查询。默认情况下，查询将读取事件流中实时到达的事件，从而进行复杂事件处理，最后将匹配成功的复杂事件反馈给用户。

为了解释SASE 事件描述语言结构的含义，现在使用一个基于道路交通场景构造的例子来说明。在这个例子中，事件类型TrafficInfo为道路地点所收集到的该地点的交通数据报告，一个报告对应一个事件实例。假设报告内容包含该地点的位置，以及某一时刻的车流量、平均车速等。所构造的查询如 $Q _ { I }$ 所示。

$\mathrm { \sf { Q } } _ { 1 }$ ：   
PATTERN SEQ(TrafficInfoa,TrafficInfc $^ { 1 + }$ b[)   
WHERE skip-till-any-match   
AND a.pos $\ c =$ tollA   
AND b.pos $>$ a.pos $+ 5$ miles   
AND b[i].count $>$ b[i - 1].count   
WITHIN 1 hour

上述查询定义了一个复杂事件：距离A收费站5英里远的某地点，其车流量在1小时的时间范围内逐渐增大，其中事件之间的默认时间戳约束为a.timestamp $ b .$ .timestamp、b[i].timestamp<b[i+1].timestamp。其中PATTERN部分定义了复杂事件的事件序列，使用SEQ结构来指定两个事件类型构成事件序列。可以看到两个事件类型都是TrafficInfo，后者使用了克林闭包，使用 $^ { 6 6 } + \stackrel { , , } { }$ 来表示一个或者多个指定类型的事件，同时需要结合"[]"来申明。除了定义顺序序列和闭包序列，PATTERN部分还可以定义否定操作，只需要在事件类型前面加上“！”，例如 $S E Q ( A a , / B b , C$ $^ c )$ 表示在a.timestamp ${ \mathit { \Sigma } } _ { \ll c }$ .timestamp的条件下， $A$ 类型的事件实例和 $C$ 类型的事件实例之间不允许出现 $B$ 类型的事件实例。

WHERE部分指定了当前查询所用到的匹配策略，skiptill-any-match表示将在事件流中匹配所有的结果，本文将只讨论该策略下的复杂事件匹配，其他策略匹配出的结果都是skip-till-any-match策略所匹配结果的子集，故不做另外讨论。AND部分定义了事件约束，是作为WHERE约束的延伸。WITHIN则定义了时间窗口约束，将所要匹配的结果事件跨度限制在一定范围内。

通过以上事件描述语言的语法规则写成的一个复杂事件查询Q,将通过复杂事件处理引擎在事件流上进行查询分析，并得到查询结果。

# 3 查询优化技术

本章将对本文提出的复杂事件查询优化技术进行详细的介绍。首先对于基于有限状态自动机的复杂事件匹配技术进行分析，通过设计并实现一个临时匹配链式分区存储结构以及查询优化算法，来优化基于有限状态自动机的复杂事件匹配方法的技术，提升查询匹配的效率。

# 3.1基于有限状态自动机的匹配方法

基于有限状态自动机的匹配方式是目前使用最广泛并且有效的复杂事件匹配技术。以SASE为例，处理一个复杂事件查询的步骤有：(1）将查询解析为一个有限状态自动机；(2)读取事件流；(3）进行复杂事件匹配，产生临时匹配结果或成功匹配结果。

本节通过构造一个查询 $\boldsymbol { Q } _ { 2 }$ 及其匹配过程来详细介绍基于有限状态自动机的匹配方法。

$\mathbf { Q } _ { 2 }$ ：  
PATTERN SEQ(A a, $\mathbf { B } +$ b[], C c)  
WHERE skip-till-any-match  
AND b[i].val $\scriptstyle > = \mathbf { b } [ \mathrm { i } + 1 ]$ .val  
WITHIN 50

$\boldsymbol { Q } _ { 2 }$ 包含了一个 $B$ 事件类型的克林闭包，表示匹配一个或者多个 $B$ 类型的事件实例，并且在 $B$ 事件的约束条件下， $\boldsymbol { Q } _ { 2 }$ 只会匹配属性值val递减的 $B$ 事件序列，所以 $Q _ { 2 }$ 匹配的复杂事件是以 $A$ 事件类型的事件实例开头，然后是 $B$ 事件类型的val递减事件实例序列，最后以 $C$ 事件类型的事件实例作为结尾。将 $Q _ { 2 }$ 以文本的形式作为SASE的输入， $\boldsymbol { Q } _ { 2 }$ 经过编译后，在SASE内部得到一个对应的有限状态自动机，如图2所示。

![](images/034a1235ab4ed3765cfc1b656dff4991c1f9d0fc0c6c433329ea731fa3b78768.jpg)  
图2Q2对应的有限状态自动机 Fig.2The NFA ofQ2

在图2展示的有限状态自动机中，begin 表示在当前状态下获取一个符合条件的事件实例并保存，从而转移到下一个状态。ignore表示当遇到不符合条件的事件实例，就保持当前状态不变。take 和 proceed 是闭包节点独有的动作，take表示获取相同类型并且符合条件的事件实例，并保持当前状态。而proceed 可以将NFA从闭包节点状态跳出到下一个状态，并且take和proceed 动作是同时发生的。也就是说在b[i节点，状态机的状态既可以转换为 $\scriptstyle { \begin{array} { l } { c } \end{array} }$ ，也可以保持b[i的状态不变。

在SASE中是通过NFA来处理事件流的，例如当数据流中来了一个 $A$ 事件类型的实例，则图2中的NFA则会初始化一个包含该实例的临时匹配，这个临时匹配会一直存在，直到事件流当前的时间戳与该临时匹配的时间跨度超过了查询的时间窗口，才会把其移除。此外，当NFA在该临时匹配的基础上与当前事件流中的事件能够发生状态变化时，将会对临时匹配进行拷贝，然后把新的事件添加到新拷贝的临时匹配上，而原来的临时匹配继续保留。这样做的目的为的是保留NFA的上一个状态以及其中的匹配序列。

为清晰说明基于有限状态自动机的匹配过程，假设 $Q _ { 2 }$ 在一段特定事件流 $S ( a _ { l } , b _ { l } , b _ { 2 } , b _ { 3 } , c _ { l } )$ 上进行查询，事件流S的时间戳和属性值如图3所示。

事件实例 a1 b1 b2 b3 C4M时间戳 1 3 5 6 9Val 0 6 7 9 1

$Q _ { 2 }$ 在 $S$ 上的匹配过程，可以通过图4来展示。

![](images/6b5c7a9b7b012605d62ba0b362fea69076eb855515f2ce169e19acc1e4c97037.jpg)  
图3事件流S示意图  
Fig.3The details of events stream S   
图4查询Q2在事件流S上的匹配过程  
Fig.4The matching process ofQ2 on the event stream S

由图4可知，在SASE中通过有限状态自动机来处理事件流，当 $a _ { I }$ 事件到达时，验证成功，初始化一个包含 $a _ { I }$ 事件实例的临时匹配 $( a \ j , - \ d )$ ，该临时匹配的存在表示着图2中NFA的 $^ { * } a ^ { . }$ ”节点状态的匹配存在。当 $b _ { I }$ 事件实例到达并且验证成功后，系统将会把 $( a _ { l } , - )$ 备份，然后将原有的临时匹配进行更新，更新为 $( a _ { l } , b _ { l } , - )$ ，所以系统中出现了两个临时匹配，等到下一个到达的事件并且验证成功后，就需要对两个临时匹配进行拷贝和更新，于是就出现了4个临时匹配。

通过这个方法显然可以将事件流中的正确匹配结果都找出来，但是缺点也是显而易见的，在匹配的过程中产生了很多的临时匹配用以表示临时匹配序列，同时用以保存NFA的匹配状态。所以随着匹配的进行，最坏的情况下系统中的临时匹配数量呈现指数增长趋势，系统的计算开销和存储开销也将越来越大。

# 3.2减少冗余计算

针对基于NFA的复杂事件处理中产生的大量临时匹配和拷贝而导致的冗余计算，本文提出了“事件实例覆盖”和“复杂事件实例覆盖”的概念，同时设计了一个临时匹配链式分区存储结构和基于此结构的匹配算法CoverMatch来减少冗余计算从而提高基于NFA的复杂事件处理的性能，另外设计了匹配结果联结算法CombineMatch来完善匹配结果的生成。

定义3事件实例覆盖。当事件实例 $s _ { i }$ 与事件流中相邻的前一个事件实例 $s _ { i - I }$ 同属一个事件类型，并且都能够被当前的NFA验证成功且作用在NFA的同一个状态节点，则称$s _ { i }$ 是 $s _ { i - l }$ 的一个事件实例覆盖。

定义4复杂事件实例覆盖。对于两个匹配结果 $M _ { I }$ 和$M _ { 2 }$ 来说，如果 $M _ { I }$ 中的每一个事件实例，都相等于 $M _ { 2 }$ 中对应的事件实例或是 $M _ { 2 }$ 中对应事件实例的事件实例覆盖，则称$M _ { I }$ 是 $M _ { 2 }$ 的一个复杂事件实例覆盖。

事件实例覆盖是可传递的，例如在图3的事件流 $s$ 中的三个事件实例 $b _ { I } , b _ { 2 } , b _ { 3 }$ ，事件类型都是相同的，并且能够被$\boldsymbol { Q _ { 2 } }$ 对应的 NFA验证成功且作用在同一个状态节点，所以 $b _ { 2 }$ 是 $b _ { I }$ 的事件实例覆盖， $b _ { 3 }$ 是 $b _ { 2 }$ 的事件实例覆盖，则 $b _ { 3 }$ 也是$b _ { I }$ 的事件实例覆盖。同理，复杂事件实例覆盖也是可传递的。例如在图3中的事件流上，进行 $S E Q ( A a , B b , C c )$ 的匹配，则会得到的匹配结果是 $m _ { I } ( a _ { I } , b _ { I } , c _ { 4 } )$ 、 $m _ { 2 } ( a _ { l } , b _ { 2 } , c _ { 4 } )$ 、 $m _ { 3 } ( a _ { l } , b _ { 3 } ,$ $\cdot \cdot \cdot$ 。按照定义4， $m _ { 2 }$ 是 $m _ { I }$ 的复杂事件实例覆盖， $m _ { 3 }$ 是 $m _ { 2 }$ 的复杂事件实例覆盖，且可传递，则 $m _ { 3 }$ 也是 $m _ { I }$ 的一个复杂事件实例覆盖。

很多场景都能够应用复杂事件实例覆盖，因为复杂事件实例覆盖能运用在匹配距离当前事件最近的复杂事件上，例如在股票事件流上寻找某一只股票最近的一次价格反弹事件、在交通数据事件流上寻找某地点最新的拥堵事件等等。

在复杂事件匹配的过程中，如果只去匹配复杂事件实例覆盖的话，在出现连续的相同事件类型实例的情况下，可以以更快的效率完成匹配任务。同时，相对于SASE中的基于NFA下的skip-till-any-match 利用大量临时匹配计算所有结果的策略，使用本文提出的方法可以在匹配复杂事件实例覆盖的同时，利用结果联结算法，可以得到所有的匹配结果，过程高效并且不产生额外临时匹配，从而达到减少冗余计算的目的。

# 3.2.1临时匹配链式分区存储结构

为了让有限状态自动机支持本文提出的优化方法达到减少冗余计算的目的，本文对NFA进行了增强，为其设计了一个临时匹配的链式分区存储结构，用以替代原来的集中式的临时匹配存储方式。集中式的临时匹配存储方式的缺陷上面已经提到过了，每次新的事件到来时都需要对所有的临时匹配进行遍历验证，这将严重消耗计算资源。而临时匹配链式分区存储结构则借助事件实例覆盖和复杂事件实例覆盖的概念来设计，规避了集中式临时匹配存储的缺点。

假设当前存在查询 $Q _ { 4 }$ ： $S E Q ( A ~ a , B ~ b , C ~ c )$ ，以及事件流$S _ { t } ( a _ { I } , a _ { 2 } , b _ { I } , b _ { 2 } , a _ { 3 } , b _ { 3 } , c _ { I } , c _ { 2 } )$ 。为了简明易懂， $Q _ { 4 }$ 的事件约束条件将置为空，且设置其时间窗口大于事件流 $S _ { t }$ 的时间范围。当查询 $Q _ { 4 }$ 在事件流 $S _ { t }$ 上进行复杂事件实例覆盖匹配时，临时匹配链式分区存储结构示意图如图5所示。

![](images/3265fc6006f7e9722f8370ec08ae4859574b3cb0bec327afba204d2befcb4f37.jpg)  
图5临时匹配链式分区存储结构  
Fig.5Temporary matching chain partition storage structure

在 $Q _ { 4 }$ 被编译成NFA之后，存在三个主要状态(状态 $F$ 为终止状态)，这三个状态将分别产生三个分区，简称为 $A$ 分区、$B$ 分区和 $C$ 分区。事件流 $S _ { t }$ 中的事件实例 $a _ { I }$ 和 $a _ { 2 }$ 到达后处理系统之后，将分别产生临时匹配并存储在 $A$ 分区，同时分别打包成链表节点 $< a _ { l } >$ 和 $< a _ { 2 } >$ 。由于 $a _ { 2 }$ 是 $a _ { I }$ 的事件实例覆盖，所以 $< a _ { 2 } >$ 将作为 ${ < a _ { I } > }$ 的后继节点，并且暴露给下一个 $B$ 分区。在一个分区中所有的链表都仅将链表尾节点暴露给下一个分区。当事件实例 $b _ { I }$ 到达，首先会在上一个 $A$ 分区中寻找暴露节点并拷贝下来，也就是 $< a _ { 2 } >$ 节点，然后进行更新成为 $< a _ { 2 }$ ， $b _ { I } >$ 节点，并作为链表头存储在 $B$ 分区并暴露给 $C$ 分区。随后事件实例 $b _ { 2 }$ 到达， $b _ { 2 }$ 也会找到 $A$ 分区的暴露节点$< a _ { 2 } >$ ，会产生一个节点 $< a _ { 2 } , b _ { 2 } >$ ，由于 $< a _ { 2 }$ + $b _ { 2 } >$ 是 $< a _ { 2 } , b _ { I } >$ 的复杂事件实例覆盖，所以 $< a _ { 2 } , b _ { 2 } >$ 会成为 $< a _ { 2 } , b _ { I } >$ 的后继节点，并且替代 $< a _ { 2 }$ ， $b _ { I } >$ 暴露给 $C$ 分区。同理，当事件流 $S _ { t }$ 中的事件都到达并被处理之后，最终会得到3个复杂事件实例覆盖 $< a _ { 2 }$ b2, $c _ { 2 } >$ 、 $< a _ { 2 }$ 5 $b _ { 3 }$ 5 $c _ { 2 } >$ 、 $< a _ { 3 }$ $b _ { 3 }$ 5 $c _ { 2 } >$ 。该匹配过程见算法1。

算法1基于链式分区存储结构的匹配算法CoverMatch输入：事件流 $S _ { e }$ ，查询 $Q _ { \ l }$   
输出：复杂事件实例覆盖集 $R _ { s }$ 。  
a） $e {  } { \mathsf { n u l 1 } }$ ·  
b） $R _ { s } {  } \emptyset$ ：  
c）nfa $$ parse(Q);  
d) while( $e {  } S _ { e }$ .nextEvent()&&e!=null）do  
e) if !nfa.verfy(e）do  
f) continue;  
g） tempMatchList $$ buildTempMatch(e);  
h) checkTimeWindow(tempMatchList);  
i) if tempMatchList.isEmpty(）do  
j) continue;  
k) region←nfa.getRegion(e.eventType);  
1) for each tempMatch in tempMatchList do  
m) node $$ getDominateMatch(tempMathch,region.getCandidates());  
n) if node!=null do  
0） node.next $\mathbf { \tau } = \mathbf { \tau }$ tempMatch;  
p) else  
q) region.setCandidate(tempMatch);  
r）for each $r$ in nfa.getLastRegion().getCandidates dos) $R _ { s }$ .add(r.prev);  
t）return $R _ { s }$ :  
在算法1中，第 $g$ 行的buildTempMatch方法表示了使用

事件 $e$ 在上一个分区中遍历暴露的匹配节点，将能够进行更新的节点拷贝，进行更新，然后再进入到当前分区进行复杂事件实例覆盖的检查，如果不是某个节点的复杂事件实例覆盖，就单独成链(第 $q$ 行)，否则成为某个链的链尾节点(第 $\mid o \mid$ 行)。最后返回最终的复杂事件实例覆盖。由于采用的数据结构是双向环形链式结构，所以第 $s$ 行使用prev可以直接定位到链尾节点从而得到最终复杂事件实例覆盖。

现在对算法1的时间复杂度和空间复杂度进行分析。若系统正在对事件 $\mathbf { \Delta } _ { e }$ 进行处理，假设待处理的事件流 $s$ 中，在两倍的时间窗口内单一事件类型的实例数量最多为 $K$ 个，则$e$ 事件所属分区中的链式结构实例数量最大值为 $K$ ，设事件 $\mathbf { \Psi } _ { e }$ 在所属分区中产生的临时匹配数量为 $\mathbf { \nabla } _ { m }$ ，由于临时匹配的产生只根据上一个分区中每一个链结构的链尾节点来产生的，所以 $\mathbf { \nabla } _ { m }$ 的最大值也为 $K$ ，则处理 $e$ 事件匹配的时间复杂度为$O ( K ^ { 2 } )$ ，算法1的时间复杂度为 $O ( | S | K ^ { 2 } )$ ，其中|S为事件流 $s$ 中的事件个数。由于在事件 $\mathbf { \Delta } _ { e }$ 所在的分区的临时匹配链式结构中，只有尾节点会参与构建新的临时匹配节点，因此通过事件 $\mathbf { \Psi } _ { e }$ 得到新的临时匹配节点的空间复杂度为 $O ( K ^ { 2 } )$ 。

在复杂事件处理中，临时匹配的拷贝处理需要使用深拷贝来实现。完成一次临时匹配的深拷贝需要在内存中产生一个新的临时匹配实例，并且将原临时匹配实例中的全部属性值以及实例中存在的引用，复制到新的临时匹配实例中。传统方法中临时匹配的拷贝是在遍历所有临时匹配的过程中进行的，这将不利于为复杂事件处理提供良好的系统吞吐能力，系统的计算开销也将增大。同时，所有临时匹配都被找出并显式地在内存中以实例的形式存在，将增加内存的开销。以查询 $Q _ { 4 }$ 在事件流 $S _ { t }$ 上进行匹配的过程为例，使用基于有限状态自动机的传统匹配方法进行匹配，需要产生24个临时匹配以及21次临时匹配的拷贝，而通过临时匹配链式分区存储结构以及上述匹配算法，只产生13个临时匹配以及10次临时匹配的拷贝。临时匹配的数量和拷贝次数以及遍历操作的减少将提高系统的吞吐能力，并减少内存的开销。

临时匹配链式分区存储结构是基于复杂事件实例覆盖的概念提出的。借助分区存储的特点，处理复杂事件时并不需要遍历系统中所有的临时匹配，在实现减少临时匹配数量和拷贝的同时，并不会对最后的正确匹配结果有所影响。

当用户仅需要距离当前时间最近的一个复杂事件实例，通过指定系统保存 $< a _ { 3 }$ ， $b _ { 3 }$ ， $\phantom { + } c _ { 2 } \phantom { > }$ 即可。假设用户需要的是像skip-till-any-match策略那样将所有的结果全部匹配出来，则需要使用到所有最终的复杂事件实例覆盖，利用其所在链表上的其他节点信息来进行结果联结，从而得到所有的匹配结果。

# 3.2.2匹配结果联结

本文进一步地完善了匹配结果的生成。当用户指定需要获取全部匹配结果时，则需要使用算法1所得到的结果来进行反向的匹配结果联结。继续使用查询 $Q _ { 4 }$ ： $S E Q ( A ~ a , B ~ b , C$ $\overrightarrow { c } , \overrightarrow { \mathbf { \nabla } }$ ，以及事件流 $S _ { t } ( a _ { I } , a _ { 2 } , b _ { I } , b _ { 2 } , a _ { 3 } , b _ { 3 } , c _ { I } , c _ { 2 } )$ 来举例，在图5所示的匹配过程及结果中， $Q _ { 4 }$ 的查询结果是 $< a _ { 2 } , b _ { 2 } , c _ { 2 } > _ { \ast } < a _ { 2 } , b _ { 3 } ,$ $c _ { 2 } >$ 、 $< a _ { 3 } , b _ { 3 } , c _ { 2 } >$ ，将通过该结果以及链式分区结构来得到全部的匹配结果。

由于采用的是双向环形链式结构，可以从最底端的复杂事件实例覆盖出发，反向遍历所在的链表。通过收集每个分区的该链表节点的最后一个事件实例，最后利用递归实现各个分区事件实例的联结，该过程如算法2所示。对于 $Q _ { 4 }$ 来说，只需要将 $< a _ { 2 }$ ，b2, $c _ { 2 } >$ 、 $< a _ { 2 }$ $b _ { 3 }$ $c _ { 2 } >$ 、 $< _ { a 3 , }$ $b _ { 3 }$ ， $c _ { 2 } >$ 三个节点分别传入到算法2中，就能得到 $Q _ { 4 }$ 所有的匹配结果。

算法2匹配结果联结算法CombineMatch输入：复杂事件实例覆盖 $R$ 。输出：所有匹配结果 $M ,$

a） $\scriptstyle { M  0 }$ ：  
b） $\iota i s t {  } 0$ ：  
c） while true do  
d) List.add(R.getLastEvent());  
e) $R {  } R$ .prev;  
f) if R.isHead(）do  
g） R←getPrevBlockNode(R);  
h) break;  
i）return M←doCombine(List，CombineMatch(R));

在算法2第 $g$ 行的方法 getPrevBlockNode 中，通过传入链表顶点 $R$ ，能够获取上一个分区中 $R$ 的传递节点。第 $i$ 行使用了递归的形式来获取最终的联结结果，其中doCombine方法进行了联结操作。

现在对算法2的时间复杂度和空间复杂度进行分析。假设当前分区数为 $n$ ，假设在多复杂事件查询中所定义的最长的复杂事件序列长度为 $N$ ，则 $n$ 的最大值即为 $N$ ，且通过递归调用函数次数最多为 $N$ 次，若每个分区中与复杂事件实例覆盖S关联的临时匹配链平均长度为 $\mathrm { ~ m ~ }$ ，则算法2的空间复杂度为 $O ( N m )$ 。由于每次递归函数体中的执行操作复杂度为$O ( m )$ ，因此算法2的时间复杂度为 $O ( N m )$ 。

利用临时匹配链上的节点信息进行结果联结，可在算法1的基础上得到全部的匹配结果。联结过程中无须进行临时匹配的构建和拷贝工作，并不会增大系统中临时匹配的规模，因此节省了系统的内存开销。

使用图5中最左侧的链表来举例，首先拿到 $C$ 分区的节点 $< a _ { 2 }$ ，b2， $\mathrm { \Delta } c _ { I } { > }$ ，在 $C$ 分区通过获取每个节点的最后一个事件实例从而得到 $[ c _ { I } , c _ { 2 } ]$ ，然后在 $B$ 分区对应的链表获得了 $[ b _ { I }$ $b _ { 2 } ]$ ，继而在 $A$ 分区获得了 $[ a _ { l } , a _ { 2 } ]$ ，通过递归doCombine方法将三者联结，得到八个匹配结果 $( a _ { l } , b _ { l } , c _ { l } ) ( a _ { l } , b _ { l } , c _ { 2 } ) ( a _ { l } , b _ { 2 } ,$ （204$c _ { I } ) ( a _ { I } , b _ { 2 } , c _ { 2 } ) ( a _ { 2 } , b _ { I } , c _ { I } ) ( a _ { 2 } , b _ { I } , c _ { 2 } ) ( a _ { 2 } , b _ { 2 } , c _ { I } ) ( a _ { 2 } , b _ { 2 } , c _ { 2 } )$ ，同理，使用 $C$ 分区的另外两个复杂事件实例覆盖也能得到其对应的所有匹配，最终通过此方式得到所有的匹配结果以实现skiptill-any-match策略的匹配效果，且避免了大量临时匹配的生成和拷贝。

# 4 实验

本章通过实验对比来对本文提出的基于临时匹配链式分区存储结构的匹配优化方法的有效性进行了分析和验证。实验采用Java实现了优化方法的编写。本章将从多个维度对实验结果进行分析说明，并通过性能对比证明其有效性。

# 4.1实验设置

本文在两个数据集上进行了实验，其中第一个数据集是通过事件流生成器所生成的模拟数据流，第二个数据集是真实数据集。

第一个数据集是ABC类型事件流，该数据集通过把事件类型简写为大写英文字母方式来定义事件的类型。其中每个事件都带有时间戳以及各自的属性值。生成事件流之前可在事件流生成器中自定义事件类型的数量、属性个数以及属性值的范围，流中的每个事件都是随机生成的。实验中该数据集包含了100000个原始事件。

第二个数据集包含了车辆交通数据，该数据由传感器收集，来自于丹麦奥胡斯市[23]。该数据集是通过传感器在449个观测点位收集了4个月的数据而得到的，总共包含13577132个原始事件。每个事件代表一个观察点的交通情况，一个事件的属性包括ID、该点平均车速以及过去5分钟内观察到的车辆总数。

本文优化方法将与目前比较流行的基于有限状态自动机的 SASE方法和 Siddhi方法进行对比实验。其中本文提出的基于临时匹配链式分区存储结构的匹配优化方法记为LinkedCEP，实验在IntelCore2.60GHzCPUi7和16G内存的Linux 系统上进行。

# 4.2实验分析

首先实验比较的是本文的LinkedCEP与SASE、Siddhi在不同数据集上的匹配性能和临时匹配产生的数量。由于本文提出的CoverMatch算法只会匹配事件流中的复杂事件实例覆盖，并不会产生所有的匹配结果，为了公平地进行匹配性能的比较，在LinkedCEP中将包含匹配结果联结算法CombineMatch以支持产生所有的匹配结果。

由于两个数据集的原始事件、事件属性存在差异，为了更好地在两个数据集上执行匹配，针对两个数据集分别合成了不同的查询，并在两个数据集上分别使用LinkedCEP、SASE、Siddhi来执行对应的查询。以下将设计两组实验进行对比分析。

实验一：对两个数据集各合成了5组查询，每组查询包含10个基本复杂事件查询，这些复杂事件查询的序列长度为3，由于时间窗口对匹配时间的影响很大，所以时间窗口统一为50s，对应的值则是该组查询的平均匹配时间。

图6与7所展示的是分别在ABC事件流和交通事件流上匹配性能的对比结果。在查询序列长度和事件窗口一致的情况下，无论在任一组查询上，LinkedCEP的匹配效率都要优于其余两种方法。例如，对于图6中 $\varrho _ { 3 }$ 查询组的匹配结果来说，LinkedCEP花费的时间为 $2 2 0 \mathrm { { m s } }$ ，而SASE、Siddhi所花费的时间分别为 $3 8 5 \mathrm { m s }$ 和 $2 9 0 \mathrm { m s }$ 。同样在图7中，在处理交通事件流的查询匹配上，LinkedCEP的匹配效率同样优于SASE 和 Siddhi，例如对于 $\boldsymbol { { Q } _ { 2 } }$ 查询组的匹配结果来说，LinkedCEP花费的时间为 $1 3 0 \mathrm { m s }$ ，而SASE、Siddhi花费的时间分别为 $2 4 0 \mathrm { m s }$ 和 $1 6 0 \mathrm { { m s } }$ 。

![](images/023953ad72611d71b2751328a541fb487380b4911029f9fb25bcaf03423e64a4.jpg)  
图6在ABC 数据集上处理5组查询的性能对比 Fig.6Performance comparison of processing 5 groups of queries or the ABC data set

![](images/04d3106eeae62f53dd035b219594e20cb22c37213822d42f448c567e7d53d3aa.jpg)  
图7在交通数据集上处理5组查询的性能对比 Fig.7Performance comparison of processing 5 groups of queries on the traffic data set

实验二：测试在不同时间窗口下的匹配性能。使用查询一中的查询组，更改查询的时间窗口为 50s、100s、150s、200s、300s，对应的值为该组查询的平均匹配时间。

如图8和9所示，在不同的时间窗口下，LinkedCEP的处理性能优于其余两个方法。例如图8的实验对比结果中，当时间窗口为200s时，LinkedCEP的处理性能比SASE提升了 $34 \%$ ，比Siddhi提升了 $1 9 \%$ 。并且通过图8和9可以发现，随着时间窗口的增大，LinkedCEP对比另外两个方法的性能提升更大，这是因为时间窗口的大小会影响临时匹配的数量，当时间窗口很大，堆积的临时匹配就多，对性能的影响也越大。

![](images/f92ae219171052d58f8a17442fa14988b9a4e7e8b94c8f6a16d4fe1b3c60b52f.jpg)  
图9在交通数据集上时间窗口约束的大小对性能影响的实验对比Fig.9Experimental comparison of the effect of the size of the timewindow constraint on the performance on the traffic data set

![](images/bc10bda6dda65c85ee58e3bf7a766a376645d65d4a780fe6f7e84a04d06bca07.jpg)  
图8在ABC数据集上时间窗口约束的大小对性能影响的实验对比Fig.8Experimental comparison of the effect of the size of the timewindow constraint on the performance on the ABC data set

实验三：测试在处理不同的查询规模时的事件吞吐量。事件吞吐量指的是方法每秒处理的事件个数，吞吐量越大，说明方法的计算效率越高。实验中为ABC数据集和交通数据集分别生成了五组查询，其中每组查询中的查询数量依次为50、100、150、200、250，每个查询的时间窗口都固定为50s。实验对SASE、Siddhi、CoverMatch以及LinkedCEP分别展开了测试。

![](images/cfb1b13b4526b4dca9527919c78a83f186499abc9de0dc6277237bb83bb71769.jpg)  
图10在ABC 数据集上查询规模对吞吐量影响的实验对比 Fig.10Experimental comparison of the impact of query size on throughput on the ABC dataset

如图10与11所示，在两个数据集上，LinkedCEP的吞吐量比SASE和Siddhi更大，而CoverMatch由于只匹配了复杂事件实例覆盖，LinkedCEP是在CoverMatch的基础上进行匹配结果联结得到全部的匹配结果，所以CoverMatch的吞吐量要比LinkedCEP更大。通过实验结果可以观察到，在交通数据集上进行复杂事件处理的吞吐量比在ABC 数据集上进行相同工作时的吞吐量要小，这是由于ABC数据集在通过事件流生成器生成时采用了相同事件类型在一定概率上相邻的策略，以此来模拟出现复杂事件实例覆盖的场景，将会存在更多的匹配结果，而交通数据集中匹配结果较少，致使临时匹配由于无法产生最终匹配而在系统中一直停留，直到起始时间戳超出当前时间窗口范围才被淘汰，由此导致吞吐量降低。

![](images/550685848080aa206f84af4656ee1f61e8d688df8b6cefdfbb7ff6bfdedb967e.jpg)  
图11在交通数据集上查询规模对吞吐量影响的实验对比Fig.llExperimental comparison of the impact of query size onthroughput on the traffic dataset

在图11中，由于交通数据集中复杂事件实例匹配数量的减少，CoverMatch方法和LinkedCEP方法的吞吐量大小接近。在ABC数据集中，CoverMatch和LinkedCEP方法的吞吐量在五种查询规模的情况下都在SASE 和Siddhi之上，并且比在交通数据集上提升更显著，这说明了当数据流中出现类型相同的事件相邻的情况时，本文提出的方法性能提升更加显著。

上述实验表明，本文提出的方法能够有效地提升基于有限状态自动机的复杂事件处理技术的匹配效率，无论是在查询序列长度较多还是查询时间窗口较大的情况下都能够通过减少冗余计算来获得效能的提升。

# 5 结束语

本文研究了基于有限状态自动机的复杂事件匹配优化问题。为了解决匹配过程中出现大量临时匹配所造成的低效匹配的问题，提出了复杂事件实例覆盖的概念。同时设计了一种基于临时匹配的链式分区存储结构，以及在该结构上进行高效匹配的方法，来利用复杂事件实例覆盖减少匹配过程中的冗余计算。实验结果表明了利用复杂事件实例覆盖的匹配技术所进行的匹配能够有效提升复杂事件匹配性能。

复杂事件处理技术具有广阔的应用空间，未来的研究工作将主要围绕多个复杂事件之间进行查询优化来展开。首先在多个查询上，设计一种算法来利用本文提出的临时匹配链式分区存储结构来共享复杂事件实例覆盖链，并探索并设计出一种适用于多查询进行结果共享的监测模型。最后进行模型的共享能力分析并通过实验来分析其处理性能。

# 参考文献：

[1]Demers A，Gehrke J，HongM, etal.Towards expressive publish/subscribe systems [C]//International Conference on Extending Database Technology. Springer,Berlin,Heidelberg,20o6:627-644.   
[2]产院东，郭乔进，梁中岩，等．规则引擎发展综述[J].信息化研究， 2021,47(2):6.(Chan Yuandong,Gou Qiaojin,Liang Zhongyan,et al.A Survey ofRule Engine [J].Informatization Research,2021,47(2): 6.)   
[3]Hill M,Campbell M,Chang Y C,et al.Event detection in sensor networks for modern oil fields [C]// Proceedings of the second   
[4]Zhou Q,Simmhan Y,Prasanna V. Incorporating semantic knowledge into dynamic data processing for smart power grids [C]// International Semantic Web Conference.Springer,Berlin,Heidelberg,2012: 257-273.   
[5] 赵会群，李会峰，刘金塞.RFID 物联网复杂事件模式聚类算法研究 [J].计算机应用研究,2018,35(2):3.(Zhao Huiqun,Li Huifeng,Liu Jinluan.Study on RFID complex event pattern clustering algorithm of Intermet ofthings [J].Application Research of Computers,2018,35 (2): 3.）   
[6]Rahmani AM,Babaei Z, Souri A.Event-driven IoTarchitecture for data analysisof reliable healthcare application using complexevent processing [J]. Cluster Computing,2021,24 (2):1347-1360.   
[7] 乔雅正，程良伦，王涛，等．地铁列车环境中多依赖复杂事件处理研 究[J].计算机应用研究，2019,036(008):2355-2358,2367.(Qiao Yazheng, Cheng Lianglun, Wang Tao,et al. Study on multi-dependency complex event processing in subway train environment [J].Application Research of Computers,2019,036 (008): 2355-2358,2367.)   
[8]Agrawal J, Diao Y, Gyllstrom D,et al. Efficient pattern matching over event streams [C]// Proceedings of the 2008 ACM SIGMOD international conference on Management of data. 20o8: 147-160.   
[9] Zhang H,Diao Y, Immerman N. On complexity and optimization of expensive queries in complex event processing [Cl// Proceedings of the 2014 ACM SIGMOD international conference on Management of data. 2014: 217-228.   
[10] Demers AJ, Gehrke J,Panda B,et al. Cayuga: A General Purpose Event Monitoring System [C]// Cidr.2007,7: 412-422.   
[11] Brenna L,Demers A,Gehrke J,et al.Cayuga:a high-performance event processing engine [Cl// Proceedings of the 2007 ACM SIGMOD international conference on Management of data.20o7:1100-1102.   
[12] Suhothayan S,Gajasinghe K,Loku Narangoda I, et al. Siddhi: A second look at complex event processing architectures [C]// Proceedings of the 2011 ACM workshop on Gateway computing environments.2011: 43-50.   
[13] Noh W F. CEL:A time-dependent, two-space-dimensional,coupled Eulerian-Lagrange code [R]. Lawrence Radiation Lab.，Univ.of California,Livermore,1963.   
[14]王亦雄，廖湖声，孔祥翱，等.CEStream:一种复杂事件流处理语言 [J].计算机科学,2017,4(4):5.(Wang Yixiong,LiaoHusheng,Kong Xiangxuan, et al. CEStream: A Complex Event Stream Processing Language [J]. Computer Science, 2017, 44 (4): 5.)   
[15] Diao Y, Immerman N, Gyllstrom D.Sase+: An agile language for kleene closure over event streams [J]. UMass Technical Report,2007.   
[16] Online Apache flinkcep [EB/OL].[2020-12-04].https://ci.apache. org/projects/flink/flink-docs-stable/dev/libs/cep.html.   
[17] Mei Y, Madden S. Zstream: a cost-based query processor for adaptively detecting composite events [Cl// Proceedings of the 2009 ACM SIGMOD International Conference on Management of data. 2009:193- 206.   
[18] Fairoz Q. Kareem,Adnan Mohsin Abdulazeez,Dathar A.Hasan. Predicting Weather Forecasting State Based on Data Mining Classification Algorithms[J]. Asian Journal of Research in Computer Science,2021.   
[19] Patroumpas K,Alevizos E,Artikis A,et al. Online event recognition from moving vessl trajectories [J]. GeoInformatica,2017,21 (2): 389- 427.   
[20] Huang Qiuyang,Yang Yongjian, Xu Yuanbo,et al. Citywide roadnetwork trafic monitoring using large-scale mobile signaling data [J]. Neurocomputing, 2021, 444.   
[21] Zhang J.Multi-source remote sensing data fusion: status and trends [J]. International Journal ofImage andData Fusion,2010,1(1):5-24.   
[22]卢莉萍，张晓倩．复杂环境下多传感器目标识别的数据融合方法 [J]．西安电子科技大学学报，2020,47(4):8.(LuLiping，Zhang Xiaoqian. Datafusion method of multi-sensor target recognition in

complex enviroment [J].Journal of Xidian University,2020,47 (4): 8.) [23] Ali M I,Gao F,Mileo A.Citybench:A configurable benchmark to evaluate rsp engines using smart city datasets [C]// International Semantic Web Conference. Springer, Cham,2015:374-389.