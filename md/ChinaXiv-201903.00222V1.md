# 人类镜像系统参与音乐情绪的自动加工：来自EEG的证据

赵怀阳¹,江俊²，周临舒²，蒋存梅(上海师范大学教育学院；上海师范大学音乐学院，上海200234)

摘要人类镜像系统被认为是社会认知的重要组成部分。大脑中线电极诱发的 $\mu$ 抑制波(包括 $\mathfrak { a }$ 和 $\beta$ 频段)是人类镜像系统活动的电生理指标。尽管音乐情绪表现被认为是通过模仿个体的心理状态来实现的，但是尚未有研究对此进行探究。本研究通过EEG 技术，采用跨通道情绪启动范式，探究人类镜像系统是否涉及和弦情绪的自动加工。愉悦或不愉悦的和弦启动情绪一致与不一致的目标面孔。行为结果显示，被试对情绪一致面孔的反应显著快于情绪不一致面孔的反应。EEG结果显示，在听觉刺激出现后的 $5 0 0 { \sim } 6 5 0 ~ \mathrm { m s }$ 之间，与情绪一致条件相比，情绪不一致条件诱发了 $\beta$ 频段的去同步化。在听觉刺激出现后的 $3 0 0 { \sim } 4 5 0 \ \mathrm { m s }$ ，无论是情绪一致，还是不一致条件，都诱发了 $\mathrm { ~ \bf ~ a ~ }$ 频段的去同步化。源分析结果显示， $\mu$ 抑制波主要出现在人类镜像系统的核心脑区，即顶下小叶和额下回或前运动皮层。这些结果表明，音乐情绪的自动加工与人类镜像系统的活动密切相关。

关键词 和弦情绪； $\mu$ 抑制波； $\mathfrak { a }$ 频段； $\beta$ 频段；人类镜像系统

# 1前言

人类镜像系统(human mirror system)涉及一个核心的顶额网络，主要包括顶下小叶(inferior parietal lobule)和额下回(inferior frontal gyrus)或前运动皮层(premotor cortex)(Hobson& Bishop,2017; Iacoboni & Dapreto,2006；Molenberghs,Cunnington，& Matingley，2012;Rizzolatti &Craighero,2004)。研究表明，动作模仿会激活人类镜像系统(Hobson& Bishop,2017; Iacoboni & Dapretto,2006; Molenberghs et al.,2012; Rizzolati & Craighero,2004)。不仅如此，动作观察和执行(Caspers,Ziles,Laird,& Eickhoff,2010; Iacoboni et al.,1999; Sakreidaet al.,2018; Simos et al.,2017)，以及运动想象(Hetu et al.,2013; Lui et al.,2008; Simos et al.,2017)都会激活人类镜像系统。此外，聆听言语(Jardri etal.,2007; Tettmanti et al.,2005,2008)、与动作有关的声音，比如撕纸声、踢球声等(Di Cesare,Fasano,Errante,Marchi,& Rizzolatti,2016; Gazzola,Aziz-Zadeh,& Keysers,2006;Ricciardi et al.,2009)也会激活人类镜像系统。

在脑电(Electroencephalogram，EEG)研究中，大脑中线电极出现的 $\mu$ 抑制波(mu rhythmsuppression)被认为是人类镜像系统活动的电生理指标(Fox et al.，2016；Hobson& Bishop,2016)。这一论断主要基于以下方面：首先， $\mu$ 节律活动与人类镜像系统脑区的激活具有相同的功能。研究发现，当人们进行相同动作的观察和执行时， $\mu$ 抑制波的活动均增强，且脑电波的活动模式与人类镜像系统的激活模式相似(Debnath，Salo,Buzzell,Yoo,& Fox,2019;Liao,Acar,Makeig,&Deak,2015)。近期的元分析结果也表明， $\mu$ 抑制波在动作观察和动作执行时的激活具有较高的稳定性(Foxetal.,2016)。除此之外，后续研究进一步验证了 $\mu$ 抑制波具有人类镜像系统的其他功能，比如， $\mu$ 抑制波也参与语言加工(Bechtold,Ghio,Lange，&Bellebaum, 2018; van Elk, van Schie, Zwaan,& Bekkering, 2010)。

第二， $\mu$ 抑制波出现在人类镜像系统脑区。EEG 和功能核磁共振成像(functional magneticresonance imaging,fMRI)的同步研究发现，无论在动作观察(Armstein,Cui,Keysers,Maurits,&Gazzola,2011; Braadbaart,Wiliams,& Waiter,2013)，还是在动作执行(Arnstein et al.,2011;Mizuhara，2012)时，人类镜像系统脑区血氧水平依赖(blood oxygenation level dependent,BOLD)信号的增加都与 $\mathfrak { a }$ 和 $\beta$ 频段的抑制具有显著相关。脑磁图(Magnetoencephalography,MEG)研究也验证了该结果，即 $\mu$ 抑制波源定位在人类镜像系统脑区(Muthukumaraswamy&Singh, 2008)。

第三， $\mu$ 抑制波活动与人类镜像系统脑区激活之间存在因果联系。先前研究采用经颅磁刺激(transcranial magnetic stimulation)技术对此进行探究，研究结果发现， $\mu$ 抑制波活动与人类镜像系统脑区之间的因果联系(Berntsen,Cooper,&Romei,2017; Keuken et al.,2011)。无论是对额下回(Keuken et al.,2011)，还是顶下小叶(Berntsen et al.,2017)施加抑制的磁刺激，研究者均发现，在抑制条件下， $\mu$ 抑制波活动显著减弱或消失。这些结果说明， $\mu$ 抑制波的活动与人类镜像系统的激活具有因果关系。

事实上， $\mu$ 抑制波包括 $\alpha$ 频段 $( 8 \mathord { \sim } 1 3 \ \mathrm { H z } )$ 和 $\beta$ 频段( $1 5 { \sim } 2 5 \ \mathrm { H z } ,$ (Hobson& Bishop,2017)。其中 $\beta$ 频段的抑制与运动准备或计划有关(Chen etal.，2016；Stancak,Riml,& Pfurtscheller,1997; Tzagarakis, Ince,Leuthold,& Pellizzer,201O; Zhang, Chen, Bressler,& Ding,2008)。比如,当人们在做食指伸展运动时，若在食指上施加负重，则需要准备肌肉收缩程度增强，在这种情况下，运动准备将使 $\beta$ 频段抑制增加(Stancak et al.,1997)。与 $\beta$ 频段不同， $\mathfrak { a }$ 频段活动与运动或动作执行相关(Désy& Lepage,2013;Fox etal.,2016;Frenkel-Toledo,Bentin,Perry,

Liebermann,& Soroker,2013)。比如，在Frenkel-Toledo 等人(2013)的研究中，被试被要求用一只手挤压一个球。结果显示，与静息状态相比，被试在执行动作时， $\mathfrak { a }$ 频段抑制较强。

尽管前脑岛或前扣带回区域不是人类镜像系统的核心脑区，但是已有研究发现，观看和模仿高兴、悲伤、愤怒、害怕和惊奇(Carr,Iacoboni,Dubeau,Mazziotta,& Lenzi,2003)以及厌恶(Phillips et al.,1997;Wicker et al.,2003)的面部表情，或感受他人的疼痛(Lamm,Decety,&Singer,2011; Singer et al.,2004)也会使这些脑区激活。这些研究暗示，人类镜像系统可能与情绪加工存在联系。与人类镜像系统相似，研究发现， $\mu$ 抑制波与疼痛移情(Peled-Avron,Goldstein， Yelinek，Weissman-Fogel，& Shamay-Tsoory， 2018； Yang，Decety，Lee,Chen，&Cheng，2009)和面孔情绪加工(Moore，Gorodnitsky，& Pineda,2012；Moore & Franz，2017;Rayson, Bonaiuto, Ferrari,& Murray, 2O16)相关。

音乐被认为是一种模仿的艺术：通过模仿某种对象，传达音乐信息(Leman,2007)。在情绪模仿方面，音乐情绪主要借助声学要素变化及其与动作或运动的相关(Sievers，Polansky，Casey,&Wheatley,2013)，模仿人类心理活动的变化(Koelsch,2013)。研究发现，当处于高兴的状态时，人们走得快、说话声音大、语调轮廓向上，且变化幅度较大；当处于悲伤的状态时，人们走得慢、说话声音小、语调轮廓变化向下，且变化幅度较小(Johnson-Laird& Oatley,2008)。的确，高兴音乐与大调式、协和的和声、快速、音量大、音高上行等特点相关，悲伤音乐与小调式、轻度不协和、慢速、音量小、音高下行等特点相关(Juslin& Sloboda,2013)。另一方面，从情绪知觉层面说，情绪性人声判断也能激活人类镜像系统(Warren etal.,2006)。音乐被认为是对人类面部表情、语调表情和姿态表情的模仿(Davies，1994；Koelsch，2013;Leman，2007)。研究发现，音乐情绪理解也会自动地诱发相应的面部表情动作(Chan,Livingstone,&Russo,2013)。Molnar-Szakacs 和Overy (2006)预测，人类镜像系统可能参与音乐情绪的加工。然而，目前尚未有研究探讨这个问题。

基于此，本研究采用刺激呈现异步性(Stimulus onset asynchrony,SOA)为 $2 0 0 ~ \mathrm { { m s } }$ 的跨通道情绪启动范式，探究人类镜像系统是否参与音乐情绪的自动加工。本研究假设主要基于以下两个方面。

本研究的实验逻辑如下：(1)本研究之所以采用跨通道情绪启动范式，是因为该范式可以考察和弦情绪的加工。按照激活扩散理论(Collins &Loftus,1975),在和弦情绪启动范式中，对和弦情绪的加工可以自动地激活与之相关的情绪表征，从而促进对目标刺激情绪表征的加工，产生情绪启动效应(Steinbeis＆ Koelsch,2008,2011)。因此，以和弦作为启动刺激诱发的情绪启动效应可以反映听者对和弦情绪的加工。该范式已被广泛运用到音乐情绪研究中(Goerlich et al.,2012; Logeswaran & Bhattacharya,2009; Solberge,Rebe,& Eckstein,2003)。(2)情绪启动范式可以排除刺激本身感知觉加工的影响。在本研究中，启动刺激是表现愉悦和不愉悦情绪的和弦，目标刺激是表达愉悦(高兴)和不愉悦(愤怒和恐惧)情绪的面孔图片。由于启动刺激和目标刺激在情绪一致和不一致条件下是相同的，其区别仅体现在启动刺激和目标刺激的关系上，因此，通过对比情绪一致和不一致条件可以排除刺激本身感知觉加工的影响。(3)为了探究和弦情绪的自动加工，本研究采用 $2 0 0 ~ \mathrm { { m s } }$ 的 SOA。研究显示，SOA为 $2 0 0 ~ \mathrm { { m s } }$ 的时候，体现出对和弦情绪的自动加工(Steinbeis & Koelsch,2008,2011)。这是因为，当 SOA时间过长，被试就会形成意识反应策略，这种策略将影响随后的反应(Musch&Klauer,2003)。另外，与先前研究一致(Steinbeis ＆Koelsch,2008,2011)，在本研究中，被试的任务是判断目标刺激的情绪类型，并不要求他们有意识地对和弦刺激进行加工，由此揭示和弦情绪的自动加工机制。基于以上论述，本研究预期，和弦情绪自动加工将激活大脑中线的 $\mu$ 抑制波。具体来说，如果 $\beta$ 频段与运动计划相关(Chen et al.,2016; Tzagarakis et al.,2010)，那么我们预期，情绪一致与不一致条件下 $\beta$ 频段能量将会存在差异；如果 $\mathfrak { a }$ 频段与动作执行相关(Désy&Lepage,2013;Fox etal.,2016)，那么我们预期，音乐聆听阶段会出 $\mathfrak { a }$ 频段的抑制。

# 2方法

# 2.1被试

为了确保足够的统计检验力,我们事先使用G\*Power 3.1.9.4软件(Faul,Erdfelder,Lang,&Buchner,2007)确定样本量。根据已有同类研究(Steinbeis&Koelsch,2011)，情绪一致性的效应量很大 $( F ( 1 , 1 9 ) = 1 0 . 8 2 , d = 1 . 5 1 )$ ，我们预测本实验也将有一个大的效应量。根据软件计算，如果实验要在0.05 的显著性水平上达到 $9 9 \%$ 的统计检验力，样本量至少为11。因此，我们招募了18名被试。但是，由于3名被试身体动作较大，导致采集到的信号较差，有效试次较少，因此数据分析不包含他们的数据。这样，本实验最终只有15 名被试(男性4名)。被试年龄在 20\~25 岁 $M = 2 3 . 1 7$ $S D = 2 . 3 7 _ { . }$ )之间，均为右利手，视力或矫正视力正常，无任何精神病或神经病史，没有受过专业音乐训练。在实验前，被试都填写了知情同意书，完成实验后被支付适当的报酬。

# 2.2 实验刺激

本实验采用跨通道情绪启动范式。启动刺激包含2 类和弦：一类是由一个原位和弦(C-E-G-C)和它的第二转位和弦(G-C-E-G)组成，这类和弦是协和的，表达愉悦的情绪(Blood,Zatorre,Bermudez,& Evans,1999; Koelsch,Fritz, Cramon, Muller,& Friederici,2006)；另一类由两个非三度叠置的和弦组成：一个是增四度、纯四度和小二度音程叠置而成(C-F#-B-C)，另一个是小二度、纯四度和增四度音程叠置而成(C-C#-F#-C)。这两个非三度叠置和弦是不协和的，表达不愉悦的情绪(Crowder, Reznick,& Rosenkrantz,1991; Johnson-Laird, Kang,&Leong,2012)。这4个和弦分别在12个调上呈现一次，因此，启动刺激共有 48个和弦。每个和弦时长为 $8 0 0 ~ \mathrm { { m s } }$ 。这些和弦都是使用 Sibelius 7.5 软件制作的，并通过Cubase 5.1软件(Steinberg Media Technologies GmbH),将其音色改为大钢琴音色输出。和弦的采样率为 44100Hz、采样位数为16 bit、比特率为1411 kbps。最后,我们使用 Adobe Audition CS6软件(AdobeSystemsInc.)将所有和弦标准化到 $- 3 \mathrm { d B }$ 。

为了验证协和与不协和和弦在情绪愉悦度上的确存在差异，8名未受过音乐训练的被试(没有参加正式试验)在7点量表上对每个和弦的愉悦度( $1 =$ 非常不愉悦、 $7 =$ 非常愉悦)和唤醒度( $1 =$ 非常安静、 $7 \ : = \ :$ 非常激动)进行评定。我们对此分别进行配对样本 $t$ 检验，结果显示，协和和弦的愉悦度( $M = 4 . 7 7$ ， $S D = 1 . 4 9 _ { , } ^ { \cdot }$ 显著高于不协和和弦的愉悦度 $\mathbf { \mathcal { M } } = 3 . 8 8$ ， $S D =$ 1.63), $t ( 7 ) = 3 . 4 5$ ， $p = 0 . 0 1 1$ ，但是，协和和弦( $M = 4 . 9 9$ ， $S D = 0 . 7 7$ )与不协和和弦( $\cdot M = 4 . 8 8$ ，SD$= 0 . 8 5 )$ 的唤醒度不存在差异， $t ( 7 ) = 0 . 5 4$ ， $p = 0 . 6 0 6$ 。

目标刺激是从《中国面孔表情图片系统》(龚栩，黄宇霞，王妍，罗跃嘉，2011)中挑选的96 张面孔表情图片，48 张为愉悦情绪(高兴)的表情图片，48 张为不愉悦情绪(愤怒和恐惧)的表情图片；男性和女性图片各占一半。如图1所示，每个和弦分别与一张愉悦和一张不愉悦的表情图片配对，由此形成了96个试次：一半是情绪一致的配对，另一半是情绪不一致的配对。尽管悲伤和愤怒情绪在唤醒度上存在差异，但是，本研究基于和弦效价的差异，考察听者对和弦愉悦性的加工，这主要基于愉悦/不愉悦是人类的一个基本的、普遍的情绪体验(Lindquist,Satpute,Wager,Weber,&Barrett,2016)；与之相反，唤醒维度概念很模糊，它在不同研究中具有不同的测量指标，比如，有研究以注意力的提高、行为接触、情感体验的强度、生理激活或激活的主观感受作为唤醒度的指标(见Lindquist etal.,2016 综述)。

![](images/2dc6e602e4d91162774c7f5c647bf7c4f876245b147e3584a9327a46940e3fdf.jpg)  
图1实验刺激样例

# 2.3 实验程序

当电极帽戴好后，被试开始进行练习。练习开始前，被试先听一个非正式实验的启动刺激，并根据自己的聆听偏好将Philips SHM1900 耳机音量调到舒适水平。练习包含8个试次，目的在于让被试熟悉实验程序，因此不提供反馈。练习结束后，正式实验开始。实验试次通过 E-prime 2.0 软件(Psychology Software Tools Inc.)进行呈现。首先，在灰色背景下，电脑屏幕中心出现一个 $5 0 0 \mathrm { m s }$ 的红色注视点“ $^ +$ ”，表示启动刺激(和弦)即将出现。目标刺激(面孔表情图片)在启动刺激呈现 $2 0 0 \mathrm { m s }$ 后出现。这时，被试需要尽可能快而准确地判断面孔表情是愉悦还是不愉悦的，并做出按键反应。按键反应在被试间进行平衡。在被试做出按键反应后，出现 $1 5 0 0 \mathrm { m s }$ 的掩蔽刺激—一字符串“XXXXX”。实验试次以伪随机方式呈现，伪随机原则如下：(1)情绪一致或不一致配对连续出现次数不超过3次；(2)启动刺激为相同情绪类型的试次最多连续出现3次；(3)目标刺激为相同情绪类型的试次最多连续出现3次；(4)相邻试次和弦的调不同；(5)目标刺激相同性别图片连续出现不超过3次。

# 2.4数据记录

实验使用 NeuroScan Synamps 2 系统(Compumedics NeuroScan Inc.)记录 EEG 信号。在被试执行任务前，给被试戴上国际通用的10\~20的64 导 $\mathrm { \ A g / A g C l }$ 电极帽。记录水平眼电的电极放置于左右外眼角 $1 \mathrm { c m }$ 处，记录垂直眼电的电极位于左眼框上下 $1 \mathrm { c m }$ 处。左侧乳突为参

考电极，右侧乳突为记录电极，接地点在 $\mathrm { F z }$ 与 $\mathbf { C } \mathbf { z }$ 连线的中点。信号经过AC放大器放大，滤波带通为 $0 . 0 5 { \sim } 1 0 0 \mathrm { H z }$ ，采样率为 ${ 5 0 0 } \mathrm { H z }$ 。所有电极的电阻保持在 $5 \mathrm { k } \Omega$ 以下。

# 2.5数据分析

# 2.5.1频率分析

在数据离线分析时，我们使用NeuroScan 4.5软件对数据进行预处理。首先，将原始的EEG 数据转换为双侧乳突电极的平均参考。然后，使用软件的回归程序对眼电伪迹进行自动矫正。在采用FIR数字滤波器进行 $3 0 \mathrm { H z }$ (24 dB/oct slope)的无相移低通数字滤波后，对目标刺激呈现前的 $2 0 0 \mathrm { m s }$ 到呈现后 $1 0 0 0 \mathrm { { m s } }$ 的脑电进行分段。之后，以目标刺激呈现前的200ms 作为基线进行校正。最后，波幅在 $\pm 7 5 \mu \mathrm { V }$ 之外的试次被视为伪迹，并被自动剔除。

在预处理后，我们使用基于 Matlab R2016a 软件(MathWorks Inc,Natick,MA,USA)运行的 Brainstorm工具包(http://neuroimage.usc.edu/brainstorm)进行进一步处理。首先，以1 Hz为高通、 $3 5 \mathrm { H z }$ 为低通对数据进行滤波。其次，对启动刺激呈现前的 $5 0 0 \mathrm { m s }$ 到呈现后 $1 2 0 0 \mathrm { m s }$ 的脑电进行分段。我们采用小波转换对数据进行时频分析，其参数高斯核的半高宽(full widthhalf maximum)为 $3 \mathrm { ~ s ~ }$ ，中心频率为 $1 \mathrm { H z }$ 。第三，对每个试次的时频进行叠加平均，同时，以启动刺激出现前 $4 5 0 { \sim } 5 0 ~ \mathrm { \ m s }$ 为基线，通过事件相关同步/去同步化(event-relatedsynchronization/desynchronization,ERS/ERD)方法对分段进行校正。我们以ERS/ERD 的百分值作为频段能量的观测值：ERS/ERD $\% =$ (基线后能量 －基线的平均能量)／基线的平均能量 $\times 1 0 0 \%$ 。

在本研究中，根据已有研究结果(Steinbeis&Koelsch,2008,2011)，并结合目测，我们确定频率分析的时间窗和电极点。已有研究表明， $\mathfrak { a }$ 频段大约在刺激呈现后 $3 0 0 ~ \mathrm { { m s } }$ 出现，主要出现在大脑中线的电极(Fu&Franz,2014); $\beta$ 频段在刺激呈现后 $2 0 0 { \sim } 6 0 0 ~ \mathrm { m s }$ 出现于中线电极(Chen et al.,2016)。通过对本研究结果的观察，我们将 $\alpha$ 频段的时间窗口确定为听觉刺激呈现后 $3 0 0 { \sim } 4 5 0 ~ \mathrm { m s }$ 之间，而 $\beta$ 频段时间窗口确定为听觉刺激呈现后 $5 0 0 { \sim } 6 5 0 ~ \mathrm { m s }$ 之间(即图片刺激呈现后 $3 0 0 { \sim } 4 5 0 ~ \mathrm { m s }$ 之间)。我们选取中线上的 $\mathrm { F z }$ 、 $\mathbf { C } \mathbf { z }$ 和 $\mathrm { P z }$ 电极进行分析。

# 2.5.2源分析

为了确定 $\alpha$ 和 $\beta$ 频段的来源，我们使用Brainstorm工具包进行源分析。由于缺少被试的

MRI 结构像，首先，我们采用默认的MNI模板作为大脑结构像的模板。我们调用OpenMEEG函数(Gramfort,Papadopoulo,Olivi,& Clerc,2010)，计算对称边界元模型，并以此作为 EEG正向模型(forwardmodel)(采用默认设置参数)。其次，根据启动刺激前 $4 5 0 { \sim } 5 0 ~ \mathrm { m s }$ 的数据计算出噪声协方差矩阵，以此估计电极的噪声水平。第三，采用加权最小范数估计(minimumnorm estimates)方法，把每个试次的数据投射到 $3 { \times } 5 0 0 5$ 个基本电流偶极子上，进行无约束的源定位(Lin etal.,2006)。最后，采用小波转换方法进行频率分析，并将每种条件下的试次结果进行平均，并以启动刺激呈现前 $4 5 0 { \sim } 5 0 \ \mathrm { m s }$ 为基线对数据进行Z分数转换。同时，根据以上时频分析结果，选取听觉刺激呈现后 $3 0 0 { \sim } 4 5 0 \ \mathrm { \ m s }$ 的 $\mathfrak { a }$ 频段，以及听觉刺激呈现后$5 0 0 { \sim } 6 5 0 ~ \mathrm { m s }$ 的 $\beta$ 频段数据进行叠加分析。

# 3结果

# 3.1行为结果

本实验以情绪一致性(一致条件、不一致条件)为被试内变量，对正确率和反应时进行了$t$ 检验。就正确率来说，被试在情绪一致条件 $M = 9 8 \%$ $S D = 2 . 4 \%$ )与不一致条件下 $( M = 9 7 \%$ $S D = 2 . 5 \%$ 的差异不存在显著， $t ( 1 4 ) = 1 . 0 3$ $p = 0 . 3 2 0$ ， $d = 0 . 3 2$ 。就反应时而言，被试在情绪一致条件下的反应 $( M = 5 7 5 . 1 7 \mathrm { m s }$ ， $S D = 7 5 . 3 4 )$ 快于不一致条件下 $( M = 6 0 5 . 3 8 ~ \mathrm { m s }$ ， $S D = 8 7 . 7 4 _ { . }$ 0的反应, $t ( 1 4 ) = - 2 . 1 9 , p = 0 . 0 4 6 , d = 0 . 5 7 ,$ 0

# 3.2EEG结果

# 3.2.1频率分析结果

β频段如图2-a、b所示，在听觉刺激呈现后的 $5 0 0 { \sim } 6 5 0 ~ \mathrm { m s }$ 之间，情绪一致条件下诱发的 $\beta$ 频段能量高于情绪不一致条件下的 $\beta$ 频段能量。以情绪一致性(一致条件、不一致条件)和电极点 $( \operatorname { F } _ { \mathbf { Z } } , \ \mathbf { C } _ { \mathbf { Z } } , \ \mathbf { P } _ { \mathbf { Z } } )$ 为被试内因素的重复测量方差分析结果验证了以上目测结果。方差分析结果显示，情绪一致性的主效应不显著， $F ( 1 , 1 4 ) = 1 . 8 3 , p = 0 . 1 9 7 , \eta _ { \mathrm { p } } ^ { 2 } = 0 . 1 2$ ，表明情绪一致条件与不一致条件下的 $\beta$ 频段能量没有显著差异。电极点的主效应显著, $F ( 2 , 2 8 ) = 1 2 . 1 7 , p$ $< 0 . 0 0 1$ ， $\boldsymbol { \eta _ { \mathrm { p } } } ^ { 2 } = 0 . 4 7$ ，表明 $\beta$ 频段能量在 $\mathrm { F } _ { \mathrm { Z } }$ 点最低。情绪一致性与电极点的交互效应也显著, $F ( 2 ,$ $2 8 ) = 8 . 4 4$ $p = 0 . 0 0 1$ $\eta _ { \mathrm { p } } { } ^ { 2 } = 0 . 3 8$ 。简单效应分析表明，在 $\mathrm { F z }$ 点，情绪一致条件下 $\beta$ 频段能量高于不一致条件的 $\beta$ 频段能量, $F ( 1 , 1 4 ) = 3 0 . 0 4 , p < 0 . 0 0 1$ $\eta _ { \mathrm { p } } ^ { \ 2 } = 0 . 6 8$ ；在 $\mathbf { C } \mathbf { z }$ 点 $( F ( 1 , 1 4 ) = 2 . 1 3$ $p = 0 . 1 6 7$ ${ \mathfrak { \eta } } _ { \mathfrak { p } } { } ^ { 2 } = 0 . 1 3 )$ 和 $\mathrm { P z }$ 点 $( F ( 1 , 1 4 ) = 0 . 0 6$ $p = 0 . 8 1 5$ $\mathfrak { \eta } _ { \mathfrak { p } } { } ^ { 2 } < 0 . 0 1 \rangle$ ，两种条件下的 $\beta$ 频段能量的差异不显著。

![](images/41b6b17d84504153b182249cfaa5ad9444a2893a984a755413af0a40fc5eb09c.jpg)  
图 $2 \ : \mathrm { F z }$ 电极点 $\beta$ 和 $\mathfrak { a }$ 频段的频率分析结果图。其中(a)为情绪不一致条件、(b)为情绪一致条件，黑色虚线框内是本实验分析的频段和时间。

$\mathfrak { a }$ 频段如图2-a、b所示，与启动刺激呈现后的 $4 5 0 { \sim } 6 0 0 \ \mathrm { m s }$ 相比，听觉刺激呈现后的$3 0 0 { \sim } 4 5 0 \ \mathrm { m s }$ 出现明显的 $\mathfrak { a }$ 频段的去同步化。由于在情绪一致与不一致条件下都出现 $\alpha$ 频段的去同步化，为了验证该频段的抑制，我们以相邻时间窗口 $4 5 0 { \sim } 6 0 0 ~ \mathrm { m s } )$ 作为对比条件，并将时间窗口作为一个因素，由此形成以时间( $3 0 0 { \sim } 4 5 0 \ \mathrm { m s }$ 、 $4 5 0 { \sim } 6 0 0 \ \mathrm { m s } ,$ ）、电极点 $\left( \mathrm { F z } , \mathrm { C z } \right)$ $\mathrm { P z }$ 和情绪一致性(一致条件、不一致条件)为被试内因素的重复测量方差分析。方差分析结果显示，只有时间的主效应显著, $F ( 2 , 2 8 ) = 1 9 . 9 7 , p < 0 . 0 0 1 , \eta _ { \mathrm { p } } ^ { \mathrm { ~ 2 } } = 0 . 5 ^ { \mathrm { ~ 6 ~ } }$ ，表明在启动刺激呈现后的 $3 0 0 { \sim } 4 5 0 ~ \mathrm { m s }$ ， $\alpha$ 频段能量显著更低。其他主效应和交互作用均不显著 $( F ( 2 , 2 8 ) < 1 . 3 3 , p >$ 0.270, $\mathfrak { \eta _ { \mathfrak { p } } } ^ { 2 } < 0 . 0 9 \}$ 。

![](images/851bf48150910c71c3332a95c089e3e1ef4d151b3e61459b5453b22a53a8dba5.jpg)  
图 $3 \beta$ 频段(a)和 $\mathfrak { a }$ 频段(b)源分析结果图

# 3.2.2源分析结果

为了进一步确定 $\beta$ 和 $\mathbf {  { a } }$ 频段能量的来源，我们进行了源分析。就 $\beta$ 频段而言，非参数簇t检验的结果显示，情绪一致和不一致条件在额顶叶存在显著差异 $( p \ < \ 0 . 0 5 )$ (见图3-a)。就 $\mathfrak { a }$ 頻段而言，非参数簇 $t$ 检验的结果显示，情绪一致和不一致条件下 $\alpha$ 频段的信号主要来源于大脑中前部，包含人类镜像系统中的额下回、前运动皮层、顶上小叶和顶下小叶等脑区(见图3-b)。

# 4讨论

本研究通过情绪启动范式探究音乐情绪自动加工的电生理机制。行为结果表明，与情绪不一致条件相比，被试对情绪一致面孔的反应时更短。EEG 时频分析结果显示，在听觉刺激出现后 $5 0 0 { \sim } 6 5 0 \ \mathrm { m s }$ ，与情绪一致条件相比，情绪不一致条件诱发 $\beta$ 频段的去同步化。在听觉刺激出现后的 $3 0 0 { \sim } 4 5 0 \ \mathrm { m s }$ ，无论是情绪一致，还是不一致条件，都诱发了 $\mathrm { ~ \bf ~ a ~ }$ 频段的去同步化。同时，这些效应主要出现在人类镜像系统的核心脑区，即顶下小叶、额下回和前运动皮层等。本研究结果表明，人类镜像系统参与了音乐情绪的自动加工。

在行为层面，本研究结果显示，被试对情绪一致面孔的反应较快。根据激活扩散理论(Collins &Loftus,1975)，概念是以节点的方式储存在联结网络之中，对启动刺激概念表征的加工可以在概念水平上预先激活与之概念一致的其他节点的表征，从而促进对相关表征的加工。本研究结果表明，被试对情绪和弦的知觉自动激活了情绪表征，从而促进了与和弦情绪相一致的情绪图片的加工，产生了启动效应。这些研究结果与先前研究结果一致(Steinbeis&Koelsch,2008,2011)，表明听者能够对音乐情绪进行自动化加工。

在神经生理层面上，本研究发现，在听觉刺激呈现后500\~650ms之间，与情绪一致条件相比，情绪不一致条件诱发 $\beta$ 频段的去同步化。该频段的抑制效应并不缘于图片情绪的加工差异，这是因为，在一致与不一致两种条件下，目标刺激(情绪面孔)都是相同的，因此，一致和不一致条件相减得出的 $\beta$ 频段去同步化应该归因于和弦刺激的作用：它是促进，还是抑制了目标图片的加工。的确，在已有的情绪启动研究中，研究者也发现，无论对于情绪面孔，还是情感韵律声音，只要情绪不一致，被试的加工都会诱发 $\beta$ 频段的去同步化(Chen et al.,2016)。 $\beta$ 频段的去同步化与运动准备有关(Stancak et al.,1997; Tzagarakis et al.,2010; Zhang etal.,2008)。与以上研究相似，本研究出现的β频段去同步化也与运动准备有关。具体来说，当和弦情绪与面孔情绪一致时，被试无需再次进行相应的动作准备；相反，当和弦情绪与面孔情绪不一致时，被试需要再次进行相应的动作准备，由此体现为 $\beta$ 频段能量的抑制。

本研究还发现，在听觉刺激呈现后 $3 0 0 { \sim } 4 5 0 \ \mathrm { m s }$ ，无论情绪一致条件，还是情绪不一致条件，均诱发 $\alpha$ 频段的去同步化。尽管在该时间段内，和弦和面孔图片同时出现，但是该结果归因于对和弦情绪的加工，而不是对面孔情绪的加工。这是因为，面孔情绪加工所诱发的$\mathfrak { a }$ 频段能量变化一般出现在情绪面孔呈现后的 $5 0 0 ~ \mathrm { { m s } }$ 左右(Moore et al.,2012)，因此，这个时间窗口内 $\alpha$ 频段能量的变化不可能源于对面孔情绪的加工。另一方面，该结果也不是缘于和弦情绪和情绪面孔图片的整合。这是因为，跨通道信息的整合加工主要体现在γ频段能量的变化上(Lense,Gordon，Key，& Dykens，2014； Schneider,Debener, Oostenveld,& Engel,2008)。

已有研究发现， $\mathfrak { a }$ 频段的抑制与动作执行或模仿相关(Désy&Lepage,2013;Fox et al.,2016;Frenkel-Toledo etal.,2013)。与此相似，本研究发现的 $\alpha$ 频段的抑制与和弦情绪的模仿相关。的确，在本研究中，无论是在情绪一致还是不一致条件下，听者都需要对和弦情绪进行模仿，由此导致 $\alpha$ 频段的能量降低。由于 $\alpha$ 频段能量变化主要产生于大脑中央沟(包含人类镜像系统)(Kuhlman,1978;Wolpaw,McFarland,Neat,& Formeris,1991)，因此本研究结果表明音乐情绪的自动加工涉及人类镜像系统。

虽然跨通道情绪启动范式可能涉及情绪冲突加工，但是本实验结果与情绪冲突加工无关，主要原因如下：一方面，本实验的 SOA为 $2 0 0 \mathrm { m s }$ ，这种较短的 SOA与情绪的自动化加工相关。的确，已有研究发现，较短的 SOA只能易化情绪加工，不可能产生情绪加工的冲突，这是因为，冲突主要体现为意识层面的加工(de Groot,1984;Neely,1977)。另一方面，如果本实验结果是由于情绪冲突加工引起的，那么，我们应该观察到位于额中线的0频段活动。这是因为，大量脑电结果表明，冲突加工与额中线的θ 频段活动有关(比如，Cohen &Ridderinkhof,2013; Nigbur, Cohen,Ridderinkhof,& Stirmer,2012; Tang,Hu,& Chen,2013)，但是，在本研究中，我们并未发现该频段活动的变化。

为了进一步验证镜像系统是否参与音乐情绪的自动加工，本研究进一步对 $\mu$ 抑制波产生源进行了定位。与以往μ抑制波的源分析结果一致(Moore＆Franz,2017)，本研究发现，α和 $\beta$ 频段抑制主要出现在大脑中前部，比如顶下小叶、额下回和前运动皮层，这些脑区都属于人类镜像系统(Iacoboni & Dapret,2006; Molenberghs et al.,2012; Rizzolatti & Craighero,2004)。可见，本研究中的u抑制波的确体现的是人类镜像系统的活动。然而，应该指出的是，EEG 源定位发现的脑区只能代表大规模振荡活动的区域。未来的脑磁图研究需要对此进行进一步的验证。

# 5结论

本研究发现，和弦情绪的自动加工会诱发 $\mu$ 抑制波 $\mathfrak { a }$ 与 $\beta$ 频段能量的变化，且这些频段的抑制效应都出现在人类镜像系统脑区。该研究结果也验证了 $\mu$ 抑制波作为人类镜像系统活动的电生理指标的可靠性。已有研究表明，人类镜像系统的激活不仅与动作或运动相关(比如,Sakreida et al.,2018; Simos et al.,2017; Tettamanti et al.,2008)，而且也与情绪模仿/体验等相关(Carr et al.,2003;Lamm et al.,2011; Wicker et al.,2003)。尽管如此，本研究从电生理视角拓展了人类镜像系统的功能，首次提出人类镜像系统参与到音乐情绪的自动加工。

# 参考文献

Arnstein, D., Cui, F., Keysers, C., Maurits,N. M.,& Gazzola, V. (2011). $\mu$ -suppression during action observation and execution correlates with BOLD in dorsal premotor, inferior parietal,and SI cortices. The Journal of Neuroscience,31(40),14243-14249.   
Bechtold,L., Ghio, M.,Lange,J.,& Bellebaum, C. (2O18). Event-related desynchronization of mu and beta oscillations during the processing of novel tool names. Brain and Language, 177-178, 44-55.   
Berntsen,M.B., Cooper,N.R.,& Romei, V.(2O17).Transcranial alternating current stimulation to the inferior parietal lobe decreases mu suppression to egocentric，but not allocentric hand movements.Neuroscience,344,124-132.   
Blood,A. J., Zatorre,R.J.,Bermudez, P.,& Evans,A. C.(1999). Emotional responses to pleasant and unpleasant music correlate with activity in paralimbic brain regions. Nature Neuroscience, 2(4), 382-387.   
Braadbaart,L., Williams,J. H. G.,& Waiter, G. D.(2O13). Do mirror neuron areas mediate mu rhythm suppression during imitationandactionobservation? International Journalof Psychophysiology, 89(1), 99-105.   
Carr,L., Iacoboni, M., Dubeau, M.-C., Mazziotta,J. C.,& Lenzi, G.L. (20o3). Neural mechanisms of empathy in humans: A relay from neural systems for imitation to limbic areas. Proceedings of the National Academy of Sciences of the United States of America, 100(9),5497-5502.   
Caspers, S., Zilles, K., Laird, A.R., & Eickhoff, S.B. (201O). ALE meta-analysis of action observation and imitation in the human brain. NeuroImage, 50(3),1148-1167.   
Chan,L. P.,Livingstone,S.R.,& Ruso,F. A. (2013). Facial mimicry in response to song. Music Perception, 30(4),361-367.   
Chen, X., Pan, Z., Wang, P., Yang, X.,Liu,P., You, X.,& Yuan, J. (2016). The integration of facial and vocal cues during emotional change perception: EEG markers. Social Cognitive and Affective Neuroscience,11(7), 1152-1161.   
Cohen,M. X.，& Ridderinkhof, K. R. (2013).EEG source reconstruction reveals frontal-parietal dynamicsofspatialconflictprocessing.PLoSONE，8(2)，e57293. doi:10.1371/journal.pone.0057293   
Colins，A. M.，& Loftus，E. F. (1975). A spreading-activation theory of semantic processing. Psychological Review, 82(6), 407-428.   
Crowder, R. G.,Reznick, J. S.,& Rosenkrantz, S.L. (1991). Perception of the major/minor distinction: V.Preferences among infants. Bulletin of the Psychonomic Society, 29(3),187-188.   
Davies, S. (1994). Musical meaning and expression. New York, NY: Cornell University Press.   
de Groot, A. M. B. (1984). Primed lexical decision: Combined efects of the proportion of related prime-target pairs and the stimulus-onset asynchrony of prime and target. The Quarterly Journal of Experimental Psychology Section A, 36(2), 253-280.   
Debnath，R.，Salo，V. C.，Buzzell,G.A.，Yoo，K.H.，& Fox，N．A.(2019).Mu rhythm desynchronization isspecific to action execution and observation: Evidence from time-frequency and connectivity analysis. NeuroImage, 184, 496-507.   
Désy,M.-C., & Lepage, J.-F. (2013). Skin color has no impact on motor resonance: Evidence from mu rhythm suppression and imitation. Neuroscience Research, 77(1),58-63.   
Di Cesare, G.,Fasano,F.,Errante,A., Marchi, M.,&Rizzolatti, G. (2O16). Understanding the internal states of others by listening to action verbs. Neuropsychologia,89,172-179.   
Faul,F.,Erdfelder, E., Lang,A.-G.,& Buchner,A. (2007). $\mathbf { G } ^ { * }$ Power 3: A flexible statistical power analysis program for the social, behavioral,and biomedical sciences. Behavior Research Methods,39(2),175-191.   
Fox, N. A., Bakermans-Kranenburg, M. J., Yoo, K. H., Bowman, L. C., Cannon, E. N., Vanderwert,R. E.,.. . van Ijzendoorn, M. H. (2016). Assessing human mirror activity with EEG mu rhythm: A meta-analysis. Psychological Bulletin, 142(3),291-313.   
Frenkel-Toledo, S. Bentin, S., Perry,A.,Liebermann,D.G.,& Soroker,N. (2013). Dynamics of the EEG power in the frequency and spatial domains during observation and execution of manual movements. Brain Research, 1509, 43-57.   
Fu, Y.,& Franz, E. A. (2014). Viewer perspective in the miroring of actions. Experimental Brain Research, 232(11),3665-3674.   
Gazzola, V.，Aziz-Zadeh,L.，& Keysers, C. (2O06). Empathy and the somatotopic auditory mirror system in humans. Current Biology, 16(18),1824-1829.   
Goerlich, K. S., Witteman,J., Schiller,N.O., Van Heuven, V.J.,Aleman,A.,& Martens,S. (2012).The nature of affective priming in music and speech. Journal of Cognitive Neuroscience, 24(8), 1725-1741.   
Gong Y., Huang Y. X., Wang Y.,& Luo Y. J. (2O11). Revision of the Chinese facial affective picture system. Chinese Mental Health Journal, 25(1),40-46.   
[龚栩，黄宇霞，王妍，罗跃嘉.(2011).中国面孔表情图片系统的修订．中国心理卫生杂志,25(1), 40-46.]   
Gramfort, A.,Papadopoulo, T., Olivi, E.,& Clerc,M. (2010). OpenMEEG: Opensource software for quasistaticbioelectromagnetics.BioMedicalEngineeringOnLine,9(1)，45. doi:10.1186/1475-925X-9-45   
Hetu, S., Grégoire,M., Saimpont,A., Coll, M.-P.,Eugene,F.,Michon,P.-E.,& Jackson,P.L. (2013). The neural network of motor imagery: An ALE meta-analysis. Neuroscience & Biobehavioral Reviews, 37(5),930-949.   
Hobson, H. M.,& Bishop,D. V. M. (2016). Mu suppression - A good measure of the human mirror neuron system? Cortex, 82,290-310.   
Hobson, H. M.,& Bishop,D. V. M. (2017). The interpretation of mu suppresson as an index of mirror neuron activity: Past， present and future. Royal Society Open Science， 4(3). doi:10.1098/rsos.160662   
Iacoboni，M.，& Dapretto，M.(2O06).The mirror neuron system and the consequences of its dysfunction. Nature Reviews Neuroscience, 7(12), 942-951.   
Iacoboni, M., Woods,R.P.,Brass,M.,Bekkering,H., Mazziotta,J. C.,& Rizzolatti, G. (1999). Cortical mechanisms of human imitation. Science,286(5449), 2526-2528.   
Jardri,R.,Pins,D.,Bubrovszky,M.,Despretz,P.,Pruvo,J.-P.,Steinling,M.,& Thomas,P.(2007). Self awareness and speech processing: An fMRI study. NeuroImage, 35(4), 1645-1653.   
Johnson-Laird,P.N.，& Oatley，K.(2Oo8).Emotions,music,and literature.In M. Lewis,J.M. Haviland-Jones,& L. F. Barrett(Eds.), Handbook of emotions (3rd ed., pp.102-113). New York, NY: The Guilford Press.   
Johnson-Laird, P. N., Kang, O. E.,& Leong, Y. C. (2012). On musical dissonance. Music Perception, 30(1), 19-35.   
Juslin,P.N.,& Sloboda, J.A. (2013). Music and emotion. In D.Deutsch (Ed.)， The psychology of music (pp. 583-645). San Diego, CA: Academic Press.   
Keuken, M. C., Hardie,A., Dorn, B. T., Dev, S., Paulus, M.P., Jonas, K.J.,.. .Pineda, J. A. (2011). The role of the left inferior frontal gyrus in social perception: An rTMS study. Brain Research, 1383,196-205.   
Koelsch, S. (2013). Brain and music. West Sussex, UK: John Wiley & Sons.   
Koelsch, S.,Fritz, T.,v. Cramon, D.Y., Muller, K.,& Friederici, A. D.(2006). Investigating emotion with music: An fMRI study. Human Brain Mapping,27(3),239-250.   
Kuhlman, W. N. (1978). Functional topography of the human mu rhythm. Electroencephalography and Clinical Neurophysiology, 44(1), 83-93.   
Lamm, C., Decety,J.，& Singer, T. (2011). Meta-analytic evidence for common and distinct neural networks associated with directly experienced pain and empathy for pain. NeuroImage, 54(3), 2492-2502.   
Leman, M. (2007). Embodied music cognition and mediation technology. Cambridge, MA: The MIT Press.   
Lense,M. D., Gordon,R. L. Key, A. P.F.,& Dykens, E. M. (2014). Neural correlates of cross-modal affective priming by music in Williams syndrome. Social Cognitive and Affctive Neuroscience, 9(4), 529-537.   
Liao,Y.，Acar, Z. A.， Makeig, S.，& Deak, G. (2015). EEG imaging of toddlers during dyadic turn-taking: Mu-rhythm modulation while producing or observing social actions. NeuroImage, 112, 52-60.   
Lin,F. H., Witzel,T.,Ahlfors,S.P., Stufflebeam, S.M.,Belliveau,J. W.,& Hamalainen,M. S. (2006). Assessing and improving the spatial accuracy in MEG source localization by depth-weighted minimum-norm estimates. Neurolmage,31(1),160-171.   
Lindquist, K.A., Satpute, A. B., Wager, T. D., Weber,J.,& Barret,L. F. (2016). The brain basis of positive and negative afect: Evidence from a meta-analysis of the human neuroimaging literature. Cerebral Cortex,26(5),1910-1922.   
Logeswaran, N.,& Bhattacharya, J. (2Oo9). Crossmodal transfer of emotion by music. Neuroscience Letters, 455(2), 129-133.   
Lui,F.,Buccino,G., Duzzi,D.,Benuzzi,F.,Crisi,G., Baraldi,P.,...Rizzolatti, G. (2OO8). Neural substrates for observing and imagining non-object-directed actions. Social Neuroscience, 3(3-4), 261-275.   
Mizuhara,H. (2012). Cortical dynamics of human scalp EEG origins in a visually guided motor execution. Neurolmage, 62(3),1884-1895.   
Molenberghs,P. Cunnington, R.，& Mattingley, J. B.(2012). Brain regions with mirror properties: A meta-analysis of 125 human fMRI studies. Neuroscience & Biobehavioral Reviews, 36(1), 341-349.   
Molnar-Szakacs, I.,& Overy, K.(2oo6). Music and mirror neurons: From motion to 'e'motion. Social Cognitive and Affective Neuroscience, 1(3),235-241.   
Moore,A., Gorodnitsky,I.,& Pineda,J. (2012).EEG mu component responses to viewing emotional faces. Behavioural Brain Research, 226(1),309-316.   
Moore,M. R.,& Franz, E.A.(2017). Mu rhythm suppression is associated with the classification of emotion in faces. Cognitive, Affective, & Behavioral Neuroscience,17(1), 224-234.   
Musch, J.，& Klauer, K. C. (Eds.). (2003). The psychology of evaluation: Affective processes in Cognition and emotion. Mahwah, NJ: Lawrence Erlbaum Associates.   
Muthukumaraswamy, S.D.,& Singh,K.D.(2Oo8). Modulation of the human mirror neuron system during cognitive activity. Psychophysiology, 45(6), 896-905.   
Neely,J. H. (1977). Semantic priming and retrieval from lexical memory: Roles of inhibitionless spreading activation and limited-capacity atention. Journal of Experimental Psychology: General, 106(3),226-254.   
Nigbur,R.， Cohen，M. X.，Ridderinkhof,K.R.，& Sturmer，B.(2012). Theta dynamics reveal domain-specific control over stimulus and response conflict. Journal of Cognitive Neuroscience, 24(5), 1264-1274.   
Peled-Avron,L., Goldstein,P.，Yellinek,S.，Weissman-Fogel, I.，& Shamay-Tsoory， S.G.(2018). Empathy during consoling touch ismodulated bymu-rhythm: An EEGstudy. Neuropsychologia, 116,68-74   
Philips, M. L., Young, A. W., Senior, C., Brammer, M., Andrew, C., Calder, A. J.,.. . David, A. S. (1997).A specific neural substrate for perceiving facial expressions of disgust. Nature, 389(6650), 495-498.   
Pratt C. C. (1948). Music as a language of emotion. Buletin of the American Musicological Society, 11-13, 67-68.   
Rayson,H.，Bonaiuto，J.J.，Ferrari，P.F.，& Murray,L.(2O16). Mu desynchronization during observation and execution of facial expressions in 3O-month-old children. Developmental Cognitive Neuroscience, 19, 279-287.   
Ricciardi,E.,Bonino,D.,Sani,L., Vecchi,T., Guazzeli,M.,Haxby,J.V.,Pietrini,P.(2O9).Do we really need vision? How blind people “see” the actions of others. The Journal of Neuroscience, 29(31),9719-9724.   
Rizzolatti, G.,& Craighero,L. (2O04). The mirror-neuron system. Annual Review of Neuroscience, 27, 169-192.   
Sakreida, K.， Higuchi, S., Di Dio, C., Ziesser, M., Turgeon,M.， Roberts,N.，& Vogt, S. (2018). Cognitive control structures in the imitation learning of spatial sequences and rhythms—An fMRI study. Cerebral Cortex, 28(3), 907-923.   
Schneider, T. R., Debener, S.， Oostenveld,R.，& Engel,A.K. (2008). Enhanced EEG gamma-band activity reflects multisensory semantic matching in visual-to-auditory object priming. NeuroImage, 42(3), 1244-1254.   
Sievers,B. Polansky,L., Casey, M.，& Wheatley, T. (2013). Music and movement share a dynamic structure that supports universal expressions of emotion. Proceedings of the National Academy of Sciences of the United States of America, 1l0(1),70-75.   
Simos,P. G., Kavroulakis,E.,Maris,T.,Papadaki,E.,Boursianis,T., Kalaitzakis,G.,& Savaki, H.E. (2017). Neural foundations of overt and covert actions. NeuroImage, 152, 482-496.   
Singer,T.,Seymour,B.,Doherty,J., Kaube,H., Dolan,R.J.,& Frith, C.D.(2004).Empathy for pain involves the affective but not sensory components of pain. Science,303(5661), 1157-1162.   
Sollerge,B.，Rebe,R.,& Eckstein, D. (2O03). Musical chords as affective priming context in a word-evaluation task. Music Perception, 20(3),263-282.   
Stancak,A.，Riml, A., & Pfurtscheller, G. (1997). The effects of external load on movement-related changes of the sensorimotor EEG rhythms. Electroencephalography and Clinical Neurophysiology, 102(6), 495-504.   
Steinbeis, N.,& Koelsch, S. (2008). Comparing the processing of music and language meaning using EEG and fMRI provides evidence for similar and distinct neural representations. PLoS ONE, 3(5), e2226. doi:10.1371/journal.pone.0002226   
Steinbeis,N.,& Koelsch, S. (2011). Affective priming effects of musical sounds on the processing of word meaning. Journal of Cognitive Neuroscience, 23(3), 604-621.   
Tang,D., Hu,L.,& Chen, A. (2O13). The neural oscillations of conflict adaptation in the human frontal region. Biological Psychology, 93(3),364-372.   
Tettamanti, M.，Buccino, G., Saccuman,M. C., Gallese,V., Danna, M., Scifo,P. Perani, D.(2005). Listening to action-related sentences activates fronto-parietal motor circuits. Journal of Cognitive Neuroscience, 17(2), 273-281.   
Tettamanti,M., Manenti,R., Della Rosa,P.A.,Falini, A.,Perani,D., Cappa, S.F.,& Moro,A. (2008). Negation in the brain: Modulating action representations. NeuroImage, 43(2), 358-367.   
Tzagarakis, C., Ince,N. F., Leuthold, A. C.,& Pellizzer, G. (201O). Beta-band activity during motor planning reflects response uncertainty. The Journal of Neuroscience,30(34),11270-11277.   
van Elk,M., van Schie,H.T., Zwaan,R.A.,& Bekkering, H. (2O1O). The functional role of motor activation in language processing: Motor cortical oscillations support lexical-semantic retrieval. NeuroImage, 50(2), 665-677.   
Warren,J.E., Sauter, D.A.,Eisner,F.,Wiland,J.,Dresner,M.A., Wise,R.J., Scott, S.K.(2006). Positive emotions preferentially engage an auditory-motor “mirror” system. The Journal of Neuroscience,26(50),13067-13075.   
Wicker,B.，Keysers,C.，Plailly,J.，Royet,J.-P.， Gallese，V.,& Rizzolati,G.(2O03).Both of us disgusted in My insula: The common neural basis of seeing and feeling disgust. Neuron, 40(3), 655-664.   
Wolpaw, J.R., McFarland, D.J., Neat, G.W.,&Forneris, C.A. (1991). An EEG-based brain-computer interface for cursor control. Electroencephalography and Clinical Neurophysiology， 78(3), 252-259.   
Yang,C.-Y., Decety,J.,Lee,S., Chen, C.,& Cheng, Y. (2O09). Gender differences in the mu rhythm during empathy for pain: An electroencephalographic study. Brain Research, 1251, 176-184.   
Zhang,Y., Chen, Y., Bressler, S.L.,& Ding,M. (2Oo8). Response preparation and inhibition: The role of the cortical sensorimotor beta rhythm. Neuroscience, 156(1),238-246.

ZHAO Huaiyang1; JIANG Jun²; ZHOU Linshu²; JIANG Cunmei² ( Department of Psychology, College of Education, Shanghai Normal University, Shanghai 200234, China) (2 Music Collge, Shanghai Normal University, Shanghai 200234, China)

# Abstract

The human mirror system (HMS) consists of a core parietofrontal network of regions in the inferior parietal lobule and inferior frontal gyrus/premotor cortex，which can be activated by action observation and execution. Mu rhythm suppression is considered an electrophysiological indicator of the HMS given their similarity in reaction to action observation and execution. Mu rhythm comprises $\mathfrak { a }$ （204号 $( 8 - 1 3 \ \mathrm { H z } )$ and $\beta$ （ $1 5 \mathrm { - } 2 5 ~ \mathrm { H z }$ ）frequency bands,which are typically measured at the power change of midline electrode sites.The $\beta$ frequency band is related to the movement preparation,whereas the $\mathfrak { a }$ frequency band is suppressed during the execution of movement.

Consistent with the role of the HMS in social cognition,such as emotion understanding, theory of mind,and empathy,mu rhythm suppresson is modulated by the processing of social information, such as facial emotional information. Emotion is an important component of social communication.In addition to the emotional facial expression, music is an effective means of expressing emotions through imitation, and for most of people, the main purpose of listening to music is to process musical emotions. However, information on whether mu rhythm suppression is involved in the processing of musical emotions is limited.

The aims of the present study were to examine whether mu rhythm suppression is modulated by the processing of musical emotions using Electroencephalogram (EEG). Given that the HMS is involved in the automatic processing of musical emotions, the present study focused on this point by using a cross-modal affective priming paradigm with an SOA of $2 0 0 ~ \mathrm { { m s } }$ . Fifteen musically untrained normal individuals participated in the experiment. Target faces with pleasant and unpleasant emotions were primed by affectively congruous or incongruous chords. Forty-eight congruous and 48 incongruous trials were included in the present study. The participants were instructed to decide as fast and accurately as possible whether the emotion of the face was pleasant or unpleasant.

Behavioral results showed that the affectively congruous target faces ( $M = 5 7 5 . 1 7 ~ \mathrm { m s }$ ， $S D =$ 75.34) were judged faster than affectively incongruous target faces $\mathbf { \left( M = 6 0 5 . 3 8 ~ m s \right. }$ ， $S D = 8 7 . 7 4 _ { . }$ ）

However, no difference was observed in the percentages of correct responses to the affectively congruous $( M = 9 8 \%$ ， $S D = 2 . 4 \%$ ）and incongruous $M = 9 7 \%$ ， $S D = 2 . 5 \%$ ） target faces. Electrophysiological results revealed that the $\beta$ frequency band ( $\cdot 1 8 { - } 2 4 ~ \mathrm { H z } ,$ ）oscillations were less strong for incongruous than for congruous target faces at a time window of 5Oo-65O ms after the onset of chords.A significant desynchronization of the $\mathfrak { a }$ frequency band was observed for both the congruous and incongruous target stimuli at a time window of 3OO-45O ms after the onset of chords.Moreover, source analysis exhibited three sources responsible for the EEG waves of interest.The three sources were located in the inferior parietal lobule, inferior frontal gyrus,and premotor cortex.

Overall, the present study showed that mu rhythm suppression was involved in the automatic processing of chord emotions,as shown in the $\mathfrak { a }$ and $\beta$ frequency bands. The results extend the role of the mu rhythm and provide electrophysiological support for the role of the HMS in the processing of musical emotions.

Key words chord emotion; $\mu$ rhythm; $\mathfrak { a }$ frequency band; $\beta$ frequency band; human mirror system